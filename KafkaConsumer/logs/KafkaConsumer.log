main  INFO [2017-10-19 14:01:19,810] streams.StreamsConfig - StreamsConfig values: 
	key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	state.dir = /tmp/kafka-streams
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	state.cleanup.delay.ms = 60000
	timestamp.extractor = class org.apache.kafka.streams.processor.ConsumerRecordTimestampExtractor
	buffered.records.per.partition = 1000
	application.id = CEStreamConsumer
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	zookeeper.connect = 
	num.stream.threads = 1
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	metric.reporters = []
	client.id = 
	commit.interval.ms = 30000
	replication.factor = 1
	poll.ms = 100
	metrics.num.samples = 2

main  INFO [2017-10-19 14:01:19,835] internals.StreamThread - Creating producer client for stream thread [StreamThread-1]
main  INFO [2017-10-19 14:01:19,848] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-producer
	max.request.size = 1048576
	acks = 1
	linger.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-19 14:01:20,227] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:01:20,230] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:01:20,231] kerberos.KerberosLogin - TGT valid starting at: 2017-10-19T14:01:20.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:01:20,232] kerberos.KerberosLogin - TGT expires: 2017-10-20T14:01:20.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:01:20,232] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-20T09:29:44.711-0400
main  INFO [2017-10-19 14:01:20,247] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-producer
	max.request.size = 1048576
	acks = 1
	linger.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-19 14:01:20,251] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-19 14:01:20,251] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-19 14:01:20,252] internals.StreamThread - Creating consumer client for stream thread [StreamThread-1]
main  INFO [2017-10-19 14:01:20,259] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = CEStreamConsumer
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:01:20,269] internals.StreamPartitionAssignor - Config 'zookeeper.connect' isn't supplied and hence no internal topics will be created.
main  INFO [2017-10-19 14:01:20,270] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = CEStreamConsumer
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  WARN [2017-10-19 14:01:20,294] consumer.ConsumerConfig - The configuration num.standby.replicas = 0 was supplied but isn't a known config.
main  WARN [2017-10-19 14:01:20,294] consumer.ConsumerConfig - The configuration replication.factor = 1 was supplied but isn't a known config.
main  WARN [2017-10-19 14:01:20,294] consumer.ConsumerConfig - The configuration __stream.thread.instance__ = Thread[StreamThread-1,5,main] was supplied but isn't a known config.
main  INFO [2017-10-19 14:01:20,295] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-19 14:01:20,295] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-19 14:01:20,295] internals.StreamThread - Creating restore consumer client for stream thread [StreamThread-1]
main  INFO [2017-10-19 14:01:20,295] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-restore-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = 
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:01:20,299] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-restore-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = 
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:01:20,302] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-19 14:01:20,302] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-19 14:48:45,008] streams.StreamsConfig - StreamsConfig values: 
	key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	state.dir = /tmp/kafka-streams
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	state.cleanup.delay.ms = 60000
	timestamp.extractor = class org.apache.kafka.streams.processor.ConsumerRecordTimestampExtractor
	buffered.records.per.partition = 1000
	application.id = CEStreamConsumer
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	zookeeper.connect = 
	num.stream.threads = 1
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	metric.reporters = []
	client.id = 
	commit.interval.ms = 30000
	replication.factor = 1
	poll.ms = 100
	metrics.num.samples = 2

main  INFO [2017-10-19 14:48:45,033] internals.StreamThread - Creating producer client for stream thread [StreamThread-1]
main  INFO [2017-10-19 14:48:45,046] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-producer
	max.request.size = 1048576
	acks = 1
	linger.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-19 14:48:45,427] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:48:45,430] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:48:45,431] kerberos.KerberosLogin - TGT valid starting at: 2017-10-19T14:48:45.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:48:45,432] kerberos.KerberosLogin - TGT expires: 2017-10-20T14:48:45.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:48:45,432] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-20T10:39:49.351-0400
main  INFO [2017-10-19 14:48:45,447] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-producer
	max.request.size = 1048576
	acks = 1
	linger.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-19 14:48:45,451] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-19 14:48:45,451] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-19 14:48:45,451] internals.StreamThread - Creating consumer client for stream thread [StreamThread-1]
main  INFO [2017-10-19 14:48:45,458] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = CEStreamConsumer
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:48:45,468] internals.StreamPartitionAssignor - Config 'zookeeper.connect' isn't supplied and hence no internal topics will be created.
main  INFO [2017-10-19 14:48:45,469] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = CEStreamConsumer
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  WARN [2017-10-19 14:48:45,493] consumer.ConsumerConfig - The configuration num.standby.replicas = 0 was supplied but isn't a known config.
main  WARN [2017-10-19 14:48:45,493] consumer.ConsumerConfig - The configuration replication.factor = 1 was supplied but isn't a known config.
main  WARN [2017-10-19 14:48:45,493] consumer.ConsumerConfig - The configuration __stream.thread.instance__ = Thread[StreamThread-1,5,main] was supplied but isn't a known config.
main  INFO [2017-10-19 14:48:45,493] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-19 14:48:45,493] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-19 14:48:45,493] internals.StreamThread - Creating restore consumer client for stream thread [StreamThread-1]
main  INFO [2017-10-19 14:48:45,494] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-restore-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = 
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:48:45,497] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-restore-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = 
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:48:45,501] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-19 14:48:45,501] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-19 14:48:45,503] streams.KafkaStreams - Started Kafka Stream process
StreamThread-1  INFO [2017-10-19 14:48:45,505] internals.StreamThread - Starting stream thread [StreamThread-1]
StreamThread-1  INFO [2017-10-19 14:48:45,827] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group CEStreamConsumer.
StreamThread-1  INFO [2017-10-19 14:48:45,828] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group CEStreamConsumer
StreamThread-1  INFO [2017-10-19 14:48:45,828] internals.AbstractCoordinator - (Re-)joining group CEStreamConsumer
StreamThread-1  INFO [2017-10-19 14:48:45,843] assignment.TaskAssignor - Assigning tasks to clients: {4834d8c5-7403-4e4a-982f-7be2c33b50a1=[activeTasks: ([]) assignedTasks: ([]) prevActiveTasks: ([]) prevAssignedTasks: ([]) capacity: 1.0 cost: 0.0]}, prevAssignmentBalanced: false, prevClientsUnchangeed: false, tasks: [0_0, 0_1, 0_2, 0_3, 0_4], replicas: 0
StreamThread-1  INFO [2017-10-19 14:48:45,844] assignment.TaskAssignor - Assigned with: {4834d8c5-7403-4e4a-982f-7be2c33b50a1=[activeTasks: ([0_0, 0_1, 0_2, 0_3, 0_4]) assignedTasks: ([0_0, 0_1, 0_2, 0_3, 0_4]) prevActiveTasks: ([]) prevAssignedTasks: ([]) capacity: 1.0 cost: 2.5]}
StreamThread-1  INFO [2017-10-19 14:48:45,849] internals.AbstractCoordinator - Successfully joined group CEStreamConsumer with generation 1
StreamThread-1  INFO [2017-10-19 14:48:45,850] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group CEStreamConsumer
StreamThread-1  INFO [2017-10-19 14:48:45,864] internals.StreamTask - Creating restoration consumer client for stream task #0_0
StreamThread-1  INFO [2017-10-19 14:48:45,870] internals.StreamTask - Creating restoration consumer client for stream task #0_1
StreamThread-1  INFO [2017-10-19 14:48:45,871] internals.StreamTask - Creating restoration consumer client for stream task #0_2
StreamThread-1  INFO [2017-10-19 14:48:45,871] internals.StreamTask - Creating restoration consumer client for stream task #0_3
StreamThread-1  INFO [2017-10-19 14:48:45,872] internals.StreamTask - Creating restoration consumer client for stream task #0_4
main  INFO [2017-10-19 14:49:09,451] careengine.CEKafkaProducer - Topic name is: CEmemberRun
main  INFO [2017-10-19 14:49:09,487] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvcrtkafka02.ahmcert.com:9092, nycuvcrtkafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ConsumerGroup
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:49:09,876] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:49:09,879] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:49:09,881] kerberos.KerberosLogin - TGT valid starting at: 2017-10-19T14:49:09.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:49:09,881] kerberos.KerberosLogin - TGT expires: 2017-10-20T14:49:09.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:49:09,881] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-20T10:24:00.895-0400
main  INFO [2017-10-19 14:49:09,899] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvcrtkafka02.ahmcert.com:9092, nycuvcrtkafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ConsumerGroup
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:49:09,930] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-19 14:49:09,930] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-19 14:49:10,231] internals.AbstractCoordinator - Discovered coordinator nycuvcrtkafka02.ahmcert.com:9092 (id: 2147483646 rack: null) for group ConsumerGroup.
main  INFO [2017-10-19 14:49:10,234] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ConsumerGroup
main  INFO [2017-10-19 14:49:10,235] internals.AbstractCoordinator - (Re-)joining group ConsumerGroup
main  INFO [2017-10-19 14:49:10,392] internals.AbstractCoordinator - Successfully joined group ConsumerGroup with generation 1
main  INFO [2017-10-19 14:49:10,393] internals.ConsumerCoordinator - Setting newly assigned partitions [CEmemberRun-1, CEmemberRun-2, CEmemberRun-4, CEmemberRun-3, CEmemberRun-0] for group ConsumerGroup
main  INFO [2017-10-20 10:15:22,046] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-20 10:15:22,081] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ConsumerGroup
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:15:22,457] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:15:22,460] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:15:22,462] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T10:15:22.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:15:22,462] kerberos.KerberosLogin - TGT expires: 2017-10-21T10:15:22.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:15:22,463] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T06:24:04.247-0400
main  INFO [2017-10-20 10:15:22,480] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ConsumerGroup
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:15:22,509] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 10:15:22,509] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 10:15:22,808] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group ConsumerGroup.
main  INFO [2017-10-20 10:15:22,809] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ConsumerGroup
main  INFO [2017-10-20 10:15:22,810] internals.AbstractCoordinator - (Re-)joining group ConsumerGroup
main  INFO [2017-10-20 10:15:22,823] internals.AbstractCoordinator - Successfully joined group ConsumerGroup with generation 1
main  INFO [2017-10-20 10:15:22,824] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group ConsumerGroup
main  INFO [2017-10-20 10:19:10,063] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-20 10:19:10,098] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:19:10,485] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:19:10,488] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:19:10,489] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T10:19:10.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:19:10,490] kerberos.KerberosLogin - TGT expires: 2017-10-21T10:19:10.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:19:10,490] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T05:40:18.093-0400
main  INFO [2017-10-20 10:19:10,508] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:19:10,538] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 10:19:10,539] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 10:19:10,847] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-20 10:19:10,848] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:19:10,849] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:19:10,863] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-20 10:19:10,864] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:22:22,115] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-20 10:22:22,149] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:22:22,546] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:22:22,549] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:22:22,550] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T10:22:22.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:22:22,551] kerberos.KerberosLogin - TGT expires: 2017-10-21T10:22:22.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:22:22,551] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T06:21:20.137-0400
main  INFO [2017-10-20 10:22:22,569] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:22:22,598] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 10:22:22,598] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 10:22:22,903] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-20 10:22:22,905] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:22:22,905] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:22:22,919] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-20 10:22:22,920] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:37:38,740] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-20 10:37:38,774] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:37:39,154] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:37:39,157] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:37:39,159] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T10:37:39.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:37:39,159] kerberos.KerberosLogin - TGT expires: 2017-10-21T10:37:39.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:37:39,159] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T06:39:58.287-0400
main  INFO [2017-10-20 10:37:39,178] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:37:39,207] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 10:37:39,207] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 10:37:39,517] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-20 10:37:39,519] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:37:39,519] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:37:39,532] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-20 10:37:39,533] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:24:15,699] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-20 11:24:15,733] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:24:16,119] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:24:16,122] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:24:16,124] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T11:24:15.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:24:16,124] kerberos.KerberosLogin - TGT expires: 2017-10-21T11:24:15.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:24:16,125] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T07:05:51.110-0400
main  INFO [2017-10-20 11:24:16,142] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:24:16,171] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 11:24:16,172] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 11:24:16,477] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-20 11:24:16,479] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:24:16,479] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:24:27,971] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 2
main  INFO [2017-10-20 11:24:27,973] internals.ConsumerCoordinator - Setting newly assigned partitions [MemberDataNewEvents-0, MemberDataNewEvents-1, MemberDataNewEvents-4, MemberDataNewEvents-3, MemberDataNewEvents-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:26:41,820] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-20 11:26:41,855] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:26:42,239] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:42,241] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:42,243] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T11:26:42.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:42,244] kerberos.KerberosLogin - TGT expires: 2017-10-21T11:26:42.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:42,244] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T07:34:26.393-0400
main  INFO [2017-10-20 11:26:42,262] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:26:42,292] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 11:26:42,292] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 11:26:42,598] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-20 11:26:42,599] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:26:42,600] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:26:42,613] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-20 11:26:42,614] internals.ConsumerCoordinator - Setting newly assigned partitions [MemberDataNewEvents-0, MemberDataNewEvents-1, MemberDataNewEvents-4, MemberDataNewEvents-3, MemberDataNewEvents-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:26:56,886] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-20 11:26:56,923] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = all
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-20 11:26:57,319] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:57,322] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:57,323] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T11:26:57.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:57,323] kerberos.KerberosLogin - TGT expires: 2017-10-21T11:26:57.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:57,323] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T06:53:11.349-0400
main  INFO [2017-10-20 11:26:57,340] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = all
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-20 11:26:57,344] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 11:26:57,344] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 11:27:11,681] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-20 11:27:11,690] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-20 11:36:42,261] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-20 11:36:42,303] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-20 11:36:42,720] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:42,723] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:42,725] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T11:36:42.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:42,725] kerberos.KerberosLogin - TGT expires: 2017-10-21T11:36:42.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:42,726] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T07:05:46.351-0400
main  INFO [2017-10-20 11:36:42,743] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-20 11:36:42,748] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 11:36:42,749] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 11:36:46,679] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-20 11:36:46,714] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:36:47,087] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:47,090] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:47,091] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T11:36:46.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:47,092] kerberos.KerberosLogin - TGT expires: 2017-10-21T11:36:46.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:47,092] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T07:43:07.138-0400
main  INFO [2017-10-20 11:36:47,110] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:36:47,140] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 11:36:47,140] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 11:36:47,448] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-20 11:36:47,449] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:36:47,450] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:36:47,464] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-20 11:36:47,465] internals.ConsumerCoordinator - Setting newly assigned partitions [MemberDataNewEvents-0, MemberDataNewEvents-1, MemberDataNewEvents-4, MemberDataNewEvents-3, MemberDataNewEvents-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:36:57,080] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-20 11:36:57,088] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-20 11:45:00,901] careengine.CEKafkaProducer - Topic name is: CECommunications
main  INFO [2017-10-20 11:45:00,936] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:45:01,333] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:45:01,336] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:45:01,337] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T11:45:01.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:45:01,337] kerberos.KerberosLogin - TGT expires: 2017-10-21T11:45:01.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:45:01,338] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T07:48:45.175-0400
main  INFO [2017-10-20 11:45:01,357] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:45:01,386] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 11:45:01,386] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 11:45:01,697] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-20 11:45:01,698] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:45:01,699] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:45:01,713] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-20 11:45:01,714] internals.ConsumerCoordinator - Setting newly assigned partitions [CECommunications-1, CECommunications-3, CECommunications-2, CECommunications-4, CECommunications-0] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 16:23:19,840] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 16:23:19,877] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 16:23:20,348] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:23:20,351] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:23:20,353] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T16:23:20.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:23:20,353] kerberos.KerberosLogin - TGT expires: 2017-10-26T16:23:20.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:23:20,353] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T12:03:18.962-0400
main  INFO [2017-10-25 16:23:20,370] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 16:23:20,375] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 16:23:20,375] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 16:23:34,730] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-25 16:23:34,739] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-25 16:30:26,737] careengine.CEKafkaProducer - Topic name is: CECommunications
main  INFO [2017-10-25 16:30:26,772] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 16:30:27,168] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:27,171] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:27,173] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T16:30:26.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:27,173] kerberos.KerberosLogin - TGT expires: 2017-10-26T16:30:26.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:27,174] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T12:28:13.085-0400
main  INFO [2017-10-25 16:30:27,191] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 16:30:27,221] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 16:30:27,221] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 16:30:27,530] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-25 16:30:27,531] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 16:30:27,532] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 16:30:27,551] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-25 16:30:27,552] internals.ConsumerCoordinator - Setting newly assigned partitions [CECommunications-1, CECommunications-3, CECommunications-2, CECommunications-4, CECommunications-0] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 16:30:35,724] careengine.CEKafkaProducer - Topic name is: CECommunications
main  INFO [2017-10-25 16:30:35,761] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 16:30:36,166] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:36,169] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:36,170] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T16:30:35.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:36,170] kerberos.KerberosLogin - TGT expires: 2017-10-26T16:30:35.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:36,171] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T12:03:35.268-0400
main  INFO [2017-10-25 16:30:36,187] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 16:30:36,191] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 16:30:36,191] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 16:30:50,552] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-25 16:30:50,561] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-25 17:53:15,880] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:53:15,910] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:53:16,296] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:16,299] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:16,301] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T17:53:16.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:16,301] kerberos.KerberosLogin - TGT expires: 2017-10-26T17:53:16.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:16,301] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T13:22:16.028-0400
main  INFO [2017-10-25 17:53:16,317] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:53:16,322] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 17:53:16,322] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 17:53:30,708] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-25 17:53:30,716] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-25 17:53:37,432] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:53:37,467] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 17:53:37,869] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:37,872] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:37,873] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T17:53:37.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:37,874] kerberos.KerberosLogin - TGT expires: 2017-10-26T17:53:37.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:37,875] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T14:13:17.810-0400
main  INFO [2017-10-25 17:53:37,892] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 17:53:37,923] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 17:53:37,923] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 17:53:38,544] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-25 17:53:38,546] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:53:38,547] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:53:38,568] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-25 17:53:38,571] internals.ConsumerCoordinator - Setting newly assigned partitions [MemberDataNewEvents-0, MemberDataNewEvents-1, MemberDataNewEvents-4, MemberDataNewEvents-3, MemberDataNewEvents-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:53:47,912] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:53:47,950] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:53:48,338] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:48,341] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:48,342] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T17:53:48.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:48,343] kerberos.KerberosLogin - TGT expires: 2017-10-26T17:53:48.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:48,343] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T14:15:02.510-0400
main  INFO [2017-10-25 17:53:48,359] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:53:48,364] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 17:53:48,364] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 17:54:02,702] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-25 17:54:02,708] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-25 17:54:29,721] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:54:29,757] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 17:54:30,430] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:30,433] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:30,435] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T17:54:30.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:30,435] kerberos.KerberosLogin - TGT expires: 2017-10-26T17:54:30.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:30,435] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T13:23:10.313-0400
main  INFO [2017-10-25 17:54:30,453] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 17:54:30,484] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 17:54:30,484] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 17:54:30,789] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-25 17:54:30,790] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:54:30,790] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:54:35,606] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:54:35,643] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:54:36,038] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:36,040] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:36,042] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T17:54:35.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:36,042] kerberos.KerberosLogin - TGT expires: 2017-10-26T17:54:35.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:36,043] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T13:41:18.084-0400
main  INFO [2017-10-25 17:54:36,059] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:54:36,065] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 17:54:36,065] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 17:54:50,419] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-25 17:54:50,428] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-25 17:54:55,588] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 2
main  INFO [2017-10-25 17:54:55,590] internals.ConsumerCoordinator - Setting newly assigned partitions [MemberDataNewEvents-0, MemberDataNewEvents-1, MemberDataNewEvents-4, MemberDataNewEvents-3, MemberDataNewEvents-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:55:40,150] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:55:40,187] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [vqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  WARN [2017-10-25 17:55:40,212] clients.ClientUtils - Removing server from bootstrap.servers as DNS resolution failed: vqa1kafka01.ahmcert.com:9092
main  INFO [2017-10-25 17:55:40,212] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 0 ms.
main  INFO [2017-10-25 17:56:23,210] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:56:23,245] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 17:56:23,957] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:23,960] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:23,961] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T17:56:23.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:23,962] kerberos.KerberosLogin - TGT expires: 2017-10-26T17:56:23.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:23,963] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T14:18:09.495-0400
main  INFO [2017-10-25 17:56:23,980] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 17:56:24,010] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 17:56:24,010] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 17:56:24,330] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-25 17:56:24,333] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:56:24,333] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:56:27,761] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:56:27,798] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:56:28,208] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:28,210] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:28,212] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T17:56:28.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:28,212] kerberos.KerberosLogin - TGT expires: 2017-10-26T17:56:28.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:28,212] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T14:12:45.193-0400
main  INFO [2017-10-25 17:56:28,229] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:56:28,233] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 17:56:28,233] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 18:00:13,695] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 18:00:13,732] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 18:00:14,140] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:00:14,142] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:00:14,144] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T18:00:13.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:00:14,144] kerberos.KerberosLogin - TGT expires: 2017-10-26T18:00:13.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:00:14,144] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T14:08:14.762-0400
main  INFO [2017-10-25 18:00:14,161] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 18:00:14,165] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 18:00:14,165] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 18:01:51,103] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 18:01:51,139] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 20000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 18:01:51,608] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:01:51,611] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:01:51,613] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T18:01:51.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:01:51,613] kerberos.KerberosLogin - TGT expires: 2017-10-26T18:01:51.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:01:51,614] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T13:18:42.220-0400
main  INFO [2017-10-25 18:01:51,630] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 20000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 18:01:51,634] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 18:01:51,634] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 18:02:35,895] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 18:02:35,932] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 18:02:37,928] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:02:37,931] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:02:37,932] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T18:02:37.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:02:37,933] kerberos.KerberosLogin - TGT expires: 2017-10-26T18:02:37.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:02:37,933] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T13:49:16.381-0400
main  INFO [2017-10-25 18:02:37,949] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 18:02:37,953] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 18:02:37,953] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-26 09:52:49,907] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-26 09:52:49,942] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-26 09:52:50,327] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:52:50,329] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:52:50,330] kerberos.KerberosLogin - TGT valid starting at: 2017-10-26T09:52:50.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:52:50,331] kerberos.KerberosLogin - TGT expires: 2017-10-27T09:52:50.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:52:50,331] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-27T05:17:22.015-0400
main  INFO [2017-10-26 09:52:50,349] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-26 09:52:50,380] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-26 09:52:50,380] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-26 09:52:50,682] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-26 09:52:50,685] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 09:52:50,686] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 09:52:50,704] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-26 09:52:50,705] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 09:53:18,913] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-26 09:53:18,950] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 09:53:19,340] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:53:19,343] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:53:19,345] kerberos.KerberosLogin - TGT valid starting at: 2017-10-26T09:53:19.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:53:19,345] kerberos.KerberosLogin - TGT expires: 2017-10-27T09:53:19.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:53:19,345] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-27T05:34:02.544-0400
main  INFO [2017-10-26 09:53:19,362] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 09:53:19,366] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-26 09:53:19,366] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-26 09:53:33,711] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-26 09:53:33,719] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-26 09:55:05,475] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-26 09:55:05,513] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 09:55:05,901] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:55:05,904] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:55:05,906] kerberos.KerberosLogin - TGT valid starting at: 2017-10-26T09:55:05.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:55:05,906] kerberos.KerberosLogin - TGT expires: 2017-10-27T09:55:05.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:55:05,906] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-27T06:04:43.051-0400
main  INFO [2017-10-26 09:55:05,923] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 09:55:05,927] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-26 09:55:05,927] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-26 09:55:20,264] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-26 09:55:20,273] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-26 10:22:42,610] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-26 10:22:42,647] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 10:22:43,035] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-26 10:22:43,037] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-26 10:22:43,039] kerberos.KerberosLogin - TGT valid starting at: 2017-10-26T10:22:42.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 10:22:43,040] kerberos.KerberosLogin - TGT expires: 2017-10-27T10:22:42.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 10:22:43,040] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-27T06:23:07.286-0400
main  INFO [2017-10-26 10:22:43,056] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 10:22:43,060] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-26 10:22:43,060] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-26 10:22:50,388] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-26 10:22:50,397] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-26 11:17:06,945] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-26 11:17:06,981] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 11:17:07,366] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-26 11:17:07,369] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-26 11:17:07,370] kerberos.KerberosLogin - TGT valid starting at: 2017-10-26T11:17:07.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 11:17:07,371] kerberos.KerberosLogin - TGT expires: 2017-10-27T11:17:07.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 11:17:07,371] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-27T06:41:54.956-0400
main  INFO [2017-10-26 11:17:07,387] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 11:17:07,393] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-26 11:17:07,393] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-26 11:17:14,723] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-26 11:17:14,732] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main ERROR [2017-10-26 11:29:12,198] internals.ConsumerCoordinator - Group nycupdevceapp02.activehealth.locTD failed to commit partition CEMarkers-4 at offset 30365: This server does not host this topic-partition.
main  WARN [2017-10-26 11:29:12,198] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Unexpected error in commit: This server does not host this topic-partition.
main ERROR [2017-10-26 11:29:12,499] internals.ConsumerCoordinator - Group nycupdevceapp02.activehealth.locTD failed to commit partition CEMarkers-4 at offset 30365: This server does not host this topic-partition.
main  WARN [2017-10-26 11:29:12,499] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Unexpected error in commit: This server does not host this topic-partition.
main  WARN [2017-10-26 11:29:12,502] clients.NetworkClient - Error while fetching metadata with correlation id 25095 : {CEMarkers=UNKNOWN_TOPIC_OR_PARTITION}
main ERROR [2017-10-26 11:29:12,504] internals.ConsumerCoordinator - Group nycupdevceapp02.activehealth.locTD failed to commit partition CEMarkers-4 at offset 30365: This server does not host this topic-partition.
main  WARN [2017-10-26 11:29:12,504] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Unexpected error in commit: This server does not host this topic-partition.
main  INFO [2017-10-26 11:29:12,505] internals.ConsumerCoordinator - Revoking previously assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 11:29:12,506] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 11:29:12,511] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 2
main  INFO [2017-10-26 11:29:12,511] internals.ConsumerCoordinator - Setting newly assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 11:34:12,503] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 11:34:12,504] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 11:34:12,508] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 3
main  INFO [2017-10-26 11:34:12,508] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 11:34:12,512] internals.Fetcher - Fetch offset 30365 is out of range for partition CEMarkers-4, resetting offset
main  INFO [2017-10-26 11:34:12,512] internals.Fetcher - Fetch offset 30420 is out of range for partition CEMarkers-3, resetting offset
main  INFO [2017-10-26 11:34:12,512] internals.Fetcher - Fetch offset 30397 is out of range for partition CEMarkers-1, resetting offset
main  INFO [2017-10-26 11:34:12,513] internals.Fetcher - Fetch offset 30391 is out of range for partition CEMarkers-0, resetting offset
main  INFO [2017-10-26 11:34:12,513] internals.Fetcher - Fetch offset 30366 is out of range for partition CEMarkers-2, resetting offset
main  INFO [2017-10-26 12:42:36,577] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-26 12:42:36,612] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-26 12:42:37,027] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-26 12:42:37,030] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-26 12:42:37,032] kerberos.KerberosLogin - TGT valid starting at: 2017-10-26T12:42:36.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 12:42:37,032] kerberos.KerberosLogin - TGT expires: 2017-10-27T12:42:36.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 12:42:37,033] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-27T07:58:05.907-0400
main  INFO [2017-10-26 12:42:37,051] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-26 12:42:37,080] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-26 12:42:37,080] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-26 12:42:37,388] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-26 12:42:37,390] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 12:42:37,390] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 12:42:37,404] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-26 12:42:37,405] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 13:53:12,246] internals.AbstractCoordinator - Marking the coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) dead for group nycupdevceapp02.activehealth.locTD
main  WARN [2017-10-26 13:53:42,204] clients.NetworkClient - Error while fetching metadata with correlation id 18424 : {CEMarkers=UNKNOWN_TOPIC_OR_PARTITION}
main  WARN [2017-10-26 13:53:42,360] clients.NetworkClient - Error while fetching metadata with correlation id 18425 : {CEMarkers=UNKNOWN_TOPIC_OR_PARTITION}
main  WARN [2017-10-26 13:53:42,463] clients.NetworkClient - Error while fetching metadata with correlation id 18426 : {CEMarkers=UNKNOWN_TOPIC_OR_PARTITION}
main  WARN [2017-10-26 13:53:42,576] clients.NetworkClient - Error while fetching metadata with correlation id 18427 : {CEMarkers=UNKNOWN_TOPIC_OR_PARTITION}
main  INFO [2017-10-26 13:53:42,795] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-26 13:53:43,063] internals.AbstractCoordinator - Marking the coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) dead for group nycupdevceapp02.activehealth.locTD
main  WARN [2017-10-26 13:53:43,064] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Commit offsets failed with retriable exception. You should retry committing offsets.
main  WARN [2017-10-26 13:53:43,091] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Commit offsets failed with retriable exception. You should retry committing offsets.
main  INFO [2017-10-26 13:53:43,116] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-26 13:53:43,801] internals.AbstractCoordinator - Marking the coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) dead for group nycupdevceapp02.activehealth.locTD
main  WARN [2017-10-26 13:53:43,801] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Commit offsets failed with retriable exception. You should retry committing offsets.
main  INFO [2017-10-26 13:53:43,810] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-26 13:53:43,875] internals.AbstractCoordinator - Marking the coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) dead for group nycupdevceapp02.activehealth.locTD
main  WARN [2017-10-26 13:53:43,875] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Commit offsets failed with retriable exception. You should retry committing offsets.
main  INFO [2017-10-26 13:53:43,886] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-26 13:53:44,802] internals.AbstractCoordinator - Marking the coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) dead for group nycupdevceapp02.activehealth.locTD
main  WARN [2017-10-26 13:53:44,802] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Commit offsets failed with retriable exception. You should retry committing offsets.
main  INFO [2017-10-26 13:53:44,959] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-11-02 12:52:04,229] careengine.CEKafkaProducer - Topic name is: CEmemberRun
main  INFO [2017-11-02 12:52:04,265] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvig1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-11-02 12:52:04,647] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:04,649] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:04,651] kerberos.KerberosLogin - TGT valid starting at: 2017-11-02T12:52:04.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:04,651] kerberos.KerberosLogin - TGT expires: 2017-11-03T12:52:04.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:04,652] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-11-03T09:09:55.934-0400
main  INFO [2017-11-02 12:52:04,670] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvig1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-11-02 12:52:04,701] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-11-02 12:52:04,701] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-11-02 12:52:05,009] internals.AbstractCoordinator - Discovered coordinator nycuvig1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-11-02 12:52:05,011] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-11-02 12:52:05,011] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-11-02 12:52:05,041] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-11-02 12:52:05,042] internals.ConsumerCoordinator - Setting newly assigned partitions [CEmemberRun-1, CEmemberRun-0] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-11-02 12:52:29,081] careengine.CEKafkaProducer - Topic name is: CEmemberRun
main  INFO [2017-11-02 12:52:29,119] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvig1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-11-02 12:52:29,508] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:29,511] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:29,513] kerberos.KerberosLogin - TGT valid starting at: 2017-11-02T12:52:29.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:29,513] kerberos.KerberosLogin - TGT expires: 2017-11-03T12:52:29.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:29,514] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-11-03T08:20:23.269-0400
main  INFO [2017-11-02 12:52:29,530] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvig1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-11-02 12:52:29,534] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-11-02 12:52:29,535] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-11-02 12:52:29,852] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-11-02 12:52:29,859] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-11-02 12:52:48,471] careengine.CEKafkaProducer - Topic name is: CEmemberRun
main  INFO [2017-11-02 12:52:48,508] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvig1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-11-02 12:52:48,899] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:48,902] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:48,903] kerberos.KerberosLogin - TGT valid starting at: 2017-11-02T12:52:48.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:48,904] kerberos.KerberosLogin - TGT expires: 2017-11-03T12:52:48.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:48,904] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-11-03T09:09:36.331-0400
main  INFO [2017-11-02 12:52:48,920] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvig1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-11-02 12:52:48,924] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-11-02 12:52:48,924] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-11-02 12:52:56,260] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-11-02 12:52:56,264] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
kafka-kerberos-refresh-thread  INFO [2017-11-03 09:09:55,937] kerberos.KerberosLogin - Initiating logout for careengineuser@AHMCERT.COM
kafka-kerberos-refresh-thread  INFO [2017-11-03 09:09:55,939] kerberos.KerberosLogin - Initiating re-login for careengineuser@AHMCERT.COM
kafka-kerberos-refresh-thread  INFO [2017-11-03 09:09:56,073] kerberos.KerberosLogin - TGT valid starting at: 2017-11-03T09:09:56.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-03 09:09:56,074] kerberos.KerberosLogin - TGT expires: 2017-11-04T09:09:56.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-03 09:09:56,074] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-11-04T05:22:38.065-0400
main  INFO [2018-05-23 14:16:12,793] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-23 14:16:12,823] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-23 14:16:13,553] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-05-23 14:16:13,553] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-05-23 14:16:13,553] kerberos.KerberosLogin - TGT valid starting at: 2018-05-23T14:16:13.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 14:16:13,553] kerberos.KerberosLogin - TGT expires: 2018-05-24T14:16:13.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 14:16:13,553] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-24T09:33:34.512-0400
main  INFO [2018-05-23 14:16:13,581] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-23 14:16:13,606] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-23 14:16:13,606] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-05-23 15:00:32,469] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-23 15:00:32,499] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-23 15:00:32,972] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:00:32,972] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:00:32,972] kerberos.KerberosLogin - TGT valid starting at: 2018-05-23T15:00:32.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:00:32,972] kerberos.KerberosLogin - TGT expires: 2018-05-24T15:00:32.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:00:32,972] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-24T10:57:39.839-0400
main  INFO [2018-05-23 15:00:33,004] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-23 15:00:33,040] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-23 15:00:33,040] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-05-23 15:17:03,635] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-23 15:17:03,665] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-23 15:17:04,227] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:17:04,227] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:17:04,227] kerberos.KerberosLogin - TGT valid starting at: 2018-05-23T15:17:04.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:17:04,227] kerberos.KerberosLogin - TGT expires: 2018-05-24T15:17:04.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:17:04,227] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-24T10:37:05.326-0400
main  INFO [2018-05-23 15:17:04,246] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-23 15:17:04,277] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-23 15:17:04,277] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-05-23 15:17:59,209] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-23 15:17:59,239] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-23 15:17:59,609] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:17:59,609] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:17:59,609] kerberos.KerberosLogin - TGT valid starting at: 2018-05-23T15:17:59.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:17:59,609] kerberos.KerberosLogin - TGT expires: 2018-05-24T15:17:59.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:17:59,609] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-24T10:37:36.092-0400
main  INFO [2018-05-23 15:17:59,623] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-23 15:17:59,652] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-23 15:17:59,652] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-05-23 15:18:42,229] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-23 15:18:42,259] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-23 15:18:42,669] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:18:42,669] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:18:42,669] kerberos.KerberosLogin - TGT valid starting at: 2018-05-23T15:18:42.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:18:42,669] kerberos.KerberosLogin - TGT expires: 2018-05-24T15:18:42.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:18:42,669] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-24T10:45:55.331-0400
main  INFO [2018-05-23 15:18:42,675] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-23 15:18:42,703] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-23 15:18:42,703] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-05-23 15:23:03,052] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-23 15:23:03,072] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-23 15:23:03,502] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:23:03,502] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:23:03,502] kerberos.KerberosLogin - TGT valid starting at: 2018-05-23T15:23:03.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:23:03,502] kerberos.KerberosLogin - TGT expires: 2018-05-24T15:23:03.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 15:23:03,502] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-24T11:46:29.911-0400
main  INFO [2018-05-23 15:23:03,519] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-23 15:23:03,543] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-23 15:23:03,543] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-05-23 16:00:57,253] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-23 16:00:57,283] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-23 16:00:57,693] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-05-23 16:00:57,693] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-05-23 16:00:57,693] kerberos.KerberosLogin - TGT valid starting at: 2018-05-23T16:00:57.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 16:00:57,693] kerberos.KerberosLogin - TGT expires: 2018-05-24T16:00:57.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 16:00:57,693] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-24T11:53:04.215-0400
main  INFO [2018-05-23 16:00:57,713] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-23 16:00:57,727] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-23 16:00:57,727] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-05-23 16:01:37,763] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-23 16:01:37,793] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-23 16:01:37,793] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-23 16:01:37,803] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null), azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null)], partitions = [])
main  INFO [2018-05-23 16:01:38,213] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-23 16:01:38,213] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-23 16:01:38,214] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-23 16:01:38,214] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-23 16:01:38,214] kerberos.KerberosLogin - TGT valid starting at: 2018-05-23T16:01:38.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 16:01:38,214] kerberos.KerberosLogin - TGT expires: 2018-05-24T16:01:38.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 16:01:38,214] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-24T11:35:03.848-0400
main DEBUG [2018-05-23 16:01:38,221] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-23 16:01:38,222] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-23 16:01:38,223] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-23 16:01:38,223] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-23 16:01:38,224] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-23 16:01:38,225] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-23 16:01:38,225] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-23 16:01:38,235] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-23 16:01:38,251] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-23 16:01:38,252] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-23 16:01:38,252] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-23 16:01:38,256] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-23 16:01:38,265] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-23 16:01:38,265] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-23 16:01:38,266] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-23 16:01:38,266] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-23 16:01:38,266] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-23 16:01:38,269] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-23 16:01:38,269] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-23 16:01:38,270] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-23 16:01:38,270] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-23 16:01:38,271] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null)
main DEBUG [2018-05-23 16:01:38,286] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:38,293] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:38,296] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:38,309] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 16:01:38,309] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:38,309] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:38,309] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:38,343] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-05-23 16:01:38,344] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-05-23 16:01:38,344] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-05-23 16:01:38,359] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:38,359] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 16:01:38,369] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-23 16:01:38,369] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-23 16:01:38,370] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-23 16:01:38,370] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:38,370] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 16:01:38,426] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:38,566] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:38,591] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 16:01:38,592] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@35080a9e, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527105698284, sendTimeMs=0) with correlation id 0 due to node -2 being disconnected
main DEBUG [2018-05-23 16:01:38,592] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:38,692] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:38,698] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 16:01:38,698] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 16:01:38,699] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:38,700] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:38,700] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:38,742] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:38,743] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 16:01:38,785] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:38,888] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:38,892] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 16:01:38,893] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 16:01:38,893] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:38,893] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:38,893] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:38,943] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:38,943] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 16:01:38,994] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:39,123] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:39,126] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 16:01:39,126] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 16:01:39,127] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:39,127] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:39,128] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:39,170] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:39,170] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 16:01:39,213] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:39,312] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:39,314] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 16:01:39,315] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:39,315] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 16:01:39,315] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:39,316] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:39,316] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:39,366] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:39,366] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 16:01:39,415] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:39,416] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:39,553] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:39,559] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 16:01:39,560] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:39,560] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 16:01:39,561] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:39,562] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:39,562] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:39,618] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:39,618] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 16:01:39,660] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:39,677] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:39,813] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:39,817] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 16:01:39,818] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:39,818] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 16:01:39,819] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:39,820] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:39,820] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:39,880] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:39,881] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 16:01:39,918] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:39,943] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:40,036] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:40,039] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 16:01:40,039] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:40,040] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 16:01:40,040] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:40,040] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:40,041] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:40,101] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:40,101] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 16:01:40,139] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:40,158] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:40,282] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:40,284] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 16:01:40,284] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:40,284] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 16:01:40,284] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:40,285] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:40,285] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:40,347] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:40,347] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 16:01:40,385] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:40,408] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:40,500] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:40,507] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 16:01:40,508] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:40,508] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 16:01:40,508] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:40,509] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:40,510] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:40,552] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:40,552] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 16:01:40,595] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:40,701] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:40,704] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 16:01:40,704] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:40,704] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 16:01:40,704] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:40,721] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:40,721] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:40,755] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:40,755] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 16:01:40,804] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:40,805] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:40,925] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:40,929] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 16:01:40,929] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:40,929] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 16:01:40,929] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:40,930] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:40,930] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:40,972] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:40,973] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 16:01:41,015] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:41,109] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:41,110] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 16:01:41,110] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:41,110] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 16:01:41,110] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:41,111] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:41,111] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:41,160] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:41,161] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 16:01:41,210] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:41,211] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:41,339] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:41,347] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 16:01:41,347] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:41,347] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 16:01:41,348] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:41,361] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:41,361] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:41,417] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:41,418] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 16:01:41,447] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:41,476] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:41,604] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:41,610] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 16:01:41,611] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:41,611] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 16:01:41,612] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:41,613] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:41,613] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:41,672] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:41,672] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 16:01:41,711] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:41,731] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:41,830] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:41,834] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 16:01:41,835] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:41,835] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 16:01:41,835] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:41,836] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:41,836] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:41,893] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:41,894] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 16:01:41,935] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:41,949] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:42,073] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:42,079] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 16:01:42,079] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:42,079] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 16:01:42,080] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:42,081] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:42,082] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:42,141] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:42,141] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 16:01:42,179] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:42,201] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:42,302] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:42,312] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 16:01:42,312] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:42,312] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 16:01:42,313] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:42,313] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:42,314] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 16:01:42,356] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 16:01:42,357] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 16:01:42,399] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 16:01:42,501] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-23 16:01:42,506] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 16:01:42,507] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 16:01:42,507] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 16:01:42,507] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 16:01:42,507] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 16:01:42,507] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main  INFO [2018-05-23 18:54:58,194] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-23 18:54:58,225] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-23 18:54:58,226] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-23 18:54:58,354] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null), azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)], partitions = [])
main  INFO [2018-05-23 18:54:58,950] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-23 18:54:58,950] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-23 18:54:58,953] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-23 18:54:58,953] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-23 18:54:58,956] kerberos.KerberosLogin - TGT valid starting at: 2018-05-23T18:54:58.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 18:54:58,957] kerberos.KerberosLogin - TGT expires: 2018-05-24T18:54:58.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 18:54:58,957] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-24T15:02:55.378-0400
main DEBUG [2018-05-23 18:54:58,980] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-23 18:54:58,981] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-23 18:54:58,982] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-23 18:54:58,982] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-23 18:54:58,983] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-23 18:54:58,983] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-23 18:54:58,984] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-23 18:54:58,992] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-23 18:54:59,006] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-23 18:54:59,006] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-23 18:54:59,007] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-23 18:54:59,010] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-23 18:54:59,016] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-23 18:54:59,016] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-23 18:54:59,016] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-23 18:54:59,017] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-23 18:54:59,017] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-23 18:54:59,019] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-23 18:54:59,019] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-23 18:54:59,020] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-23 18:54:59,021] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-23 18:54:59,021] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null)
main DEBUG [2018-05-23 18:54:59,038] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:54:59,043] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:54:59,045] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:54:59,175] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:54:59,176] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:54:59,177] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:54:59,178] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:54:59,314] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-23 18:54:59,315] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-23 18:54:59,316] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-23 18:54:59,335] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:54:59,335] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-05-23 18:54:59,336] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-05-23 18:54:59,336] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-05-23 18:54:59,337] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:54:59,337] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:54:59,337] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:54:59,397] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:54:59,557] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:54:59,559] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:54:59,693] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:54:59,693] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:54:59,699] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:54:59,748] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:54:59,750] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:54:59,751] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@1e36c1da, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527116099035, sendTimeMs=0) with correlation id 0 due to node -2 being disconnected
main DEBUG [2018-05-23 18:54:59,793] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:54:59,793] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:54:59,794] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:54:59,794] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:54:59,844] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:54:59,844] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:54:59,893] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:54:59,895] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:54:59,946] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:54:59,948] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:54:59,995] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:54:59,995] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:54:59,996] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:54:59,996] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:55:00,009] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:00,052] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:55:00,052] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:55:00,107] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:55:00,109] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:55:00,109] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:00,167] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:55:00,168] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:55:00,197] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:55:00,197] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:55:00,197] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:55:00,197] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:55:00,209] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:00,257] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:55:00,257] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:55:00,309] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:00,316] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:55:00,318] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:55:00,380] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:55:00,382] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:55:00,398] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:55:00,398] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:55:00,399] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:55:00,400] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:55:00,409] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:00,455] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:55:00,455] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:55:00,509] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:00,512] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:55:00,519] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:55:00,576] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:55:00,576] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:55:00,603] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:55:00,603] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:55:00,604] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:55:00,604] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:55:00,609] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:00,666] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:55:00,667] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:55:00,709] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:00,725] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:55:00,727] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:55:00,787] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:55:00,787] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:55:00,812] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:00,812] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:55:00,812] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:55:00,813] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:55:00,813] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:55:00,855] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:55:00,855] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:55:00,898] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:55:00,901] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:55:00,912] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:00,944] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:55:00,944] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:55:01,013] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:01,013] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:55:01,013] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:55:01,014] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:55:01,015] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:55:01,016] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:55:01,016] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:55:01,016] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:55:01,016] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:55:01,066] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:55:01,066] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:55:01,070] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:55:01,070] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:55:01,113] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:01,116] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:55:01,117] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:55:01,126] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:55:01,128] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:55:01,168] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:55:01,169] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:55:01,187] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:55:01,188] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:55:01,213] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:01,225] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:55:01,225] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:55:01,225] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:55:01,226] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:55:01,285] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:55:01,285] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:55:01,313] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:01,345] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:55:01,347] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:55:01,407] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:55:01,408] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:55:01,413] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:01,426] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:55:01,426] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:55:01,427] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:55:01,427] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:55:01,470] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:55:01,470] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:55:01,514] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:55:01,519] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:55:01,520] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:01,562] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:55:01,563] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:55:01,620] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:01,654] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:55:01,655] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:55:01,657] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:55:01,657] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:55:01,661] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:55:01,662] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:55:01,663] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:55:01,664] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:55:01,706] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:55:01,706] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:55:01,706] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:55:01,706] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:55:01,720] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:01,758] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:55:01,759] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:55:01,760] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:55:01,761] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:55:01,802] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:55:01,802] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:55:01,811] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:55:01,812] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:55:01,820] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:55:01,866] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:55:01,866] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:55:01,866] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:55:01,866] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:55:01,867] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:55:01,867] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:55:01,867] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:55:01,868] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main  INFO [2018-05-23 18:57:21,274] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-23 18:57:21,299] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-23 18:57:21,300] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-23 18:57:21,311] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null), azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)], partitions = [])
main  INFO [2018-05-23 18:57:21,693] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-23 18:57:21,693] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-23 18:57:21,694] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-23 18:57:21,695] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-23 18:57:21,695] kerberos.KerberosLogin - TGT valid starting at: 2018-05-23T18:57:21.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 18:57:21,695] kerberos.KerberosLogin - TGT expires: 2018-05-24T18:57:21.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 18:57:21,696] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-24T14:27:35.402-0400
main DEBUG [2018-05-23 18:57:21,708] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-23 18:57:21,710] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-23 18:57:21,710] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-23 18:57:21,710] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-23 18:57:21,712] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-23 18:57:21,712] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-23 18:57:21,713] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-23 18:57:21,720] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-23 18:57:21,734] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-23 18:57:21,734] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-23 18:57:21,735] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-23 18:57:21,738] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-23 18:57:21,745] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-23 18:57:21,746] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-23 18:57:21,746] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-23 18:57:21,746] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-23 18:57:21,747] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-23 18:57:21,749] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-23 18:57:21,749] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-23 18:57:21,750] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-23 18:57:21,751] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-23 18:57:21,751] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)
main DEBUG [2018-05-23 18:57:21,770] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:21,775] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:21,777] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:21,832] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-23 18:57:21,833] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-23 18:57:21,833] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-23 18:57:21,864] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:21,864] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:57:21,926] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:22,033] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:22,094] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:22,106] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:57:22,107] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@1c7534c0, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527116241767, sendTimeMs=0) with correlation id 0 due to node -1 being disconnected
main DEBUG [2018-05-23 18:57:22,134] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:57:22,134] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:22,135] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:22,135] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:22,190] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-05-23 18:57:22,191] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-05-23 18:57:22,191] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-05-23 18:57:22,192] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:22,192] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:57:22,248] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:22,372] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:22,428] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:22,428] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:57:22,472] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:57:22,472] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:22,472] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:22,472] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:22,522] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:22,523] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:57:22,572] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:22,574] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:22,624] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:22,624] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:57:22,674] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:57:22,674] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:22,674] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:22,674] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:22,733] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:22,734] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:57:22,737] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:22,794] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:22,796] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:22,837] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:22,856] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:22,856] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:57:22,875] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:57:22,875] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:22,875] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:22,875] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:22,918] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:22,918] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:57:22,937] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:22,960] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:22,962] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:23,004] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:23,005] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:57:23,037] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:23,076] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:57:23,076] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:23,077] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:23,077] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:23,079] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:57:23,079] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:23,079] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:23,080] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:23,130] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:23,130] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:57:23,134] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:23,134] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:57:23,137] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:23,179] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:23,181] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:23,189] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:23,190] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:23,231] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:23,231] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:57:23,237] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:23,246] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:23,246] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:57:23,281] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:57:23,281] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:23,281] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:23,281] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:23,337] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:23,341] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:23,341] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:57:23,402] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:23,404] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:23,437] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:23,465] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:23,467] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:57:23,482] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:57:23,482] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:23,483] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:23,484] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:23,526] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:23,526] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:57:23,538] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:23,569] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:23,571] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:23,616] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:23,617] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:57:23,638] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:23,686] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:57:23,686] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:23,687] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:23,687] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:23,687] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:57:23,687] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:23,688] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:23,688] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:23,730] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:23,731] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:57:23,737] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:23,738] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:57:23,738] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:23,773] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:23,775] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:23,787] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:23,789] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:23,817] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:23,817] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:57:23,839] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:23,839] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:23,840] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:57:23,889] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:57:23,889] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:23,890] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:23,890] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:23,891] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:57:23,892] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:23,893] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:23,893] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:23,939] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:23,942] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:23,943] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:57:23,947] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:23,947] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:57:23,992] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:23,998] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:24,003] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:24,008] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:24,039] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:24,047] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:24,048] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:57:24,064] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:24,064] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:57:24,099] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:57:24,099] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:24,100] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:24,100] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:24,139] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:24,161] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:24,161] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:57:24,223] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:24,230] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:24,239] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:24,291] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:24,294] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:57:24,301] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:57:24,301] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:24,302] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:24,302] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:24,339] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:24,344] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:24,345] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:57:24,404] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:24,406] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:24,439] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:24,449] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:24,449] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:57:24,506] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:57:24,506] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:24,506] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:24,506] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:24,540] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:24,557] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:24,557] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:57:24,607] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:24,608] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:24,640] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:24,658] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:24,659] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:57:24,708] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:57:24,708] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:24,708] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:24,708] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:24,740] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:24,765] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:24,765] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:57:24,821] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:24,822] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:24,840] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:24,883] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:24,883] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:57:24,909] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:57:24,909] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:24,909] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:24,909] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:24,940] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:24,970] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:24,970] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:57:25,031] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:25,032] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:25,040] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:25,092] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:25,093] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:57:25,110] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:57:25,110] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:25,110] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:25,110] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:25,142] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:25,168] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:25,168] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:57:25,224] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:25,225] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:25,242] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:25,281] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:25,281] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:57:25,311] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:57:25,311] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:25,311] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:25,311] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:25,342] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:25,370] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:25,371] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:57:25,430] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:25,431] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:25,442] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:25,491] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:25,492] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:57:25,512] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:57:25,512] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:25,513] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:25,513] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:25,542] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:25,555] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:25,556] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:57:25,598] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:25,600] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:25,642] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:25,642] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:25,643] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:57:25,716] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:57:25,716] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:25,717] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:25,717] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:25,718] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:57:25,719] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:25,719] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:25,719] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:25,742] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:25,762] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:25,762] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:57:25,767] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:25,768] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:57:25,806] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:25,812] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:25,818] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:25,825] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:25,842] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:25,855] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:25,856] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:57:25,875] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:25,876] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:57:25,926] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:57:25,926] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:25,928] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:25,928] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:25,930] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 18:57:25,931] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:25,932] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:25,932] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:25,946] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:25,977] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:25,977] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 18:57:25,989] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 18:57:25,989] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 18:57:26,027] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:26,028] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:26,045] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:26,046] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 18:57:26,051] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 18:57:26,082] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:26,087] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 18:57:26,106] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 18:57:26,107] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 18:57:26,134] clients.NetworkClient - Give up sending metadata request since no node is available
main DEBUG [2018-05-23 18:57:26,145] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 18:57:26,234] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 18:57:26,234] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 18:57:26,235] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 18:57:26,235] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 18:57:26,245] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main  INFO [2018-05-23 19:01:46,106] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-23 19:01:46,136] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-23 19:01:46,137] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-23 19:01:46,150] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null), azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null)], partitions = [])
main  INFO [2018-05-23 19:01:46,561] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-23 19:01:46,562] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-23 19:01:46,563] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-23 19:01:46,563] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-23 19:01:46,564] kerberos.KerberosLogin - TGT valid starting at: 2018-05-23T19:01:46.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 19:01:46,564] kerberos.KerberosLogin - TGT expires: 2018-05-24T19:01:46.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 19:01:46,564] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-24T15:21:31.607-0400
main DEBUG [2018-05-23 19:01:46,577] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-23 19:01:46,578] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-23 19:01:46,578] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-23 19:01:46,579] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-23 19:01:46,580] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-23 19:01:46,580] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-23 19:01:46,580] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-23 19:01:46,588] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-23 19:01:46,602] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-23 19:01:46,602] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-23 19:01:46,603] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-23 19:01:46,605] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-23 19:01:46,613] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-23 19:01:46,614] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-23 19:01:46,614] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-23 19:01:46,614] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-23 19:01:46,615] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-23 19:01:46,618] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-23 19:01:46,618] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-23 19:01:46,618] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-23 19:01:46,619] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-23 19:01:46,619] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null)
main DEBUG [2018-05-23 19:01:46,640] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:01:46,645] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:01:46,647] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:01:46,658] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 19:01:46,658] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 19:01:46,658] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:01:46,658] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:01:46,684] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-05-23 19:01:46,684] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-05-23 19:01:46,684] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-05-23 19:01:46,695] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:01:46,695] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:01:46,719] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-23 19:01:46,719] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-23 19:01:46,719] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-23 19:01:46,720] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:01:46,720] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 19:01:46,743] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:01:46,866] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:01:46,867] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:01:46,968] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:01:46,969] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:01:46,980] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:01:46,982] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@64235b30, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527116506637, sendTimeMs=0) with correlation id 0 due to node -2 being disconnected
main DEBUG [2018-05-23 19:01:47,029] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:01:47,031] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 19:01:47,069] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:01:47,069] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:01:47,070] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:01:47,070] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:01:47,113] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:01:47,113] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:01:47,155] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:01:47,158] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:01:47,200] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:01:47,201] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:01:47,272] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:01:47,272] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:01:47,273] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:01:47,274] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:01:47,282] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 19:01:47,282] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 19:01:47,282] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:01:47,283] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:01:47,316] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:01:47,316] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:01:47,332] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:01:47,332] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 19:01:47,359] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:01:47,360] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:01:47,382] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:01:47,387] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:01:47,403] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:01:47,404] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:01:47,437] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:01:47,438] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 19:01:47,487] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:01:47,488] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:01:47,489] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:01:47,490] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:01:47,533] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:01:47,534] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:01:47,575] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:01:47,577] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:01:47,605] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:47,620] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:01:47,621] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:01:47,693] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:01:47,693] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:01:47,694] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:01:47,694] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:01:47,696] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 19:01:47,696] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 19:01:47,696] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:01:47,697] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:01:47,705] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:47,747] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:01:47,747] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 19:01:47,754] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:01:47,755] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:01:47,797] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:01:47,800] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:01:47,805] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:47,812] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:01:47,814] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:01:47,871] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:01:47,871] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:01:47,905] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:48,005] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:48,105] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:48,157] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:01:48,158] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 19:01:48,201] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:01:48,201] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:01:48,202] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:01:48,202] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:01:48,205] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:48,246] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:01:48,246] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:01:48,288] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:01:48,294] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:01:48,305] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:48,337] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:01:48,337] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:01:48,404] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:01:48,404] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:01:48,405] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:01:48,406] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:01:48,407] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:48,462] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:01:48,462] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:01:48,507] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:48,518] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:01:48,521] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:01:48,577] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:01:48,580] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:01:48,607] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:48,607] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 19:01:48,607] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 19:01:48,608] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:01:48,608] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:01:48,659] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:01:48,659] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 19:01:48,707] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:48,709] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:01:48,713] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:01:48,763] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:01:48,763] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 19:01:48,807] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:48,813] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:01:48,813] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:01:48,815] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:01:48,815] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:01:48,857] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:01:48,858] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:01:48,900] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:01:48,901] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:01:48,907] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:48,944] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:01:48,944] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:01:49,013] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:49,017] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:01:49,017] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:01:49,018] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:01:49,018] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:01:49,074] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:01:49,074] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:01:49,113] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:01:49,130] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:01:49,135] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:01:49,196] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:01:49,196] clients.NetworkClient - Node -2 disconnected.
main  INFO [2018-05-23 19:05:36,895] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-23 19:05:36,924] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-23 19:05:36,925] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-23 19:05:36,937] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null), azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)], partitions = [])
main DEBUG [2018-05-23 19:05:37,037] consumer.KafkaConsumer - The Kafka consumer has closed.
main  INFO [2018-05-23 19:06:20,094] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-23 19:06:20,122] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-23 19:06:20,122] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-23 19:06:20,133] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null), azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null)], partitions = [])
main  INFO [2018-05-23 19:06:20,551] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-23 19:06:20,552] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-23 19:06:20,554] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-23 19:06:20,554] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-23 19:06:20,554] kerberos.KerberosLogin - TGT valid starting at: 2018-05-23T19:06:20.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 19:06:20,555] kerberos.KerberosLogin - TGT expires: 2018-05-24T19:06:20.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 19:06:20,555] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-24T14:54:49.693-0400
main DEBUG [2018-05-23 19:06:20,566] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-23 19:06:20,567] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-23 19:06:20,568] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-23 19:06:20,568] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-23 19:06:20,569] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-23 19:06:20,570] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-23 19:06:20,570] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-23 19:06:20,579] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-23 19:06:20,593] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-23 19:06:20,593] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-23 19:06:20,594] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-23 19:06:20,597] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-23 19:06:20,604] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-23 19:06:20,605] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-23 19:06:20,605] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-23 19:06:20,605] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-23 19:06:20,605] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-23 19:06:20,608] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-23 19:06:20,608] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-23 19:06:20,608] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-23 19:06:20,609] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-23 19:06:20,609] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)
main DEBUG [2018-05-23 19:06:20,624] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:20,629] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:20,630] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:20,686] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-23 19:06:20,686] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-23 19:06:20,687] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-23 19:06:20,698] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:20,698] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 19:06:20,762] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:20,873] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:20,934] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:20,949] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 19:06:20,952] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@1c7534c0, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527116780622, sendTimeMs=0) with correlation id 0 due to node -1 being disconnected
main DEBUG [2018-05-23 19:06:20,974] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:06:20,974] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:20,975] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:20,975] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:21,030] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-05-23 19:06:21,031] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-05-23 19:06:21,031] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-05-23 19:06:21,032] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:21,032] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:06:21,089] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:21,216] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:21,274] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:21,275] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:06:21,317] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 19:06:21,317] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:21,318] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:21,318] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:21,379] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:21,379] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 19:06:21,439] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:21,442] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:21,502] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:21,503] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 19:06:21,521] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:06:21,521] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:21,522] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:21,522] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:21,577] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:21,577] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:06:21,596] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:21,635] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:21,641] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:21,696] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:21,698] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:21,699] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:06:21,725] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 19:06:21,725] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:21,725] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:21,726] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:21,775] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:21,775] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 19:06:21,796] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:21,825] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:21,827] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:21,877] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:21,878] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 19:06:21,896] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:21,927] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:06:21,928] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:21,929] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:21,929] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:21,971] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:21,972] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:06:22,011] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:22,016] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:22,018] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:22,060] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:22,061] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:06:22,111] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:22,134] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:06:22,135] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:22,136] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:22,136] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:22,191] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:22,192] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:06:22,211] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:22,247] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:22,248] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:22,304] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:22,306] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:06:22,311] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:22,337] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 19:06:22,337] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:22,338] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:22,338] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:22,398] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:22,398] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 19:06:22,411] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:22,459] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:22,461] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:22,511] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:22,523] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:22,525] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 19:06:22,540] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:06:22,540] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:22,545] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:22,548] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:22,588] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:22,589] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:06:22,611] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main  INFO [2018-05-23 19:06:27,348] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-23 19:06:27,375] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-23 19:06:27,376] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-23 19:06:27,387] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null), azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)], partitions = [])
main  INFO [2018-05-23 19:06:27,790] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-23 19:06:27,790] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-23 19:06:27,791] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-23 19:06:27,792] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-23 19:06:27,792] kerberos.KerberosLogin - TGT valid starting at: 2018-05-23T19:06:27.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 19:06:27,792] kerberos.KerberosLogin - TGT expires: 2018-05-24T19:06:27.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-23 19:06:27,792] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-24T15:22:29.886-0400
main DEBUG [2018-05-23 19:06:27,806] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-23 19:06:27,808] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-23 19:06:27,808] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-23 19:06:27,808] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-23 19:06:27,810] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-23 19:06:27,810] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-23 19:06:27,810] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-23 19:06:27,818] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-23 19:06:27,833] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-23 19:06:27,833] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-23 19:06:27,834] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-23 19:06:27,837] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-23 19:06:27,845] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-23 19:06:27,846] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-23 19:06:27,846] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-23 19:06:27,846] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-23 19:06:27,847] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-23 19:06:27,849] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-23 19:06:27,850] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-23 19:06:27,850] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-23 19:06:27,851] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-23 19:06:27,851] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)
main DEBUG [2018-05-23 19:06:27,871] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:27,876] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:27,878] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:27,888] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:06:27,888] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:27,888] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:27,889] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:27,932] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-23 19:06:27,935] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-23 19:06:27,936] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-23 19:06:27,971] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:27,971] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 19:06:27,972] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-05-23 19:06:27,974] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-05-23 19:06:27,975] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-05-23 19:06:27,976] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:27,977] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:06:28,034] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:28,176] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:28,176] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:28,285] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:28,286] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:28,295] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 19:06:28,296] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@64235b30, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527116787868, sendTimeMs=0) with correlation id 0 due to node -1 being disconnected
main DEBUG [2018-05-23 19:06:28,341] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:28,343] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:06:28,391] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 19:06:28,392] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:28,392] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:28,393] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:28,442] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:28,443] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 19:06:28,492] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:28,496] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:28,546] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:28,546] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 19:06:28,596] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:06:28,597] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:28,598] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:28,599] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:28,641] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:28,641] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:06:28,683] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:28,687] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:28,730] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:28,732] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:06:28,802] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:06:28,802] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:28,802] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:28,803] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:28,804] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 19:06:28,804] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:28,805] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:28,805] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:28,836] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:28,845] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:28,845] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:06:28,855] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:28,855] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 19:06:28,887] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:28,895] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:28,904] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:28,908] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:28,936] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:28,937] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:28,938] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:06:28,958] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:28,960] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 19:06:29,009] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:06:29,009] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:29,010] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:29,010] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:29,011] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 19:06:29,011] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:29,012] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:29,012] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:29,036] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:29,068] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:29,068] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:06:29,074] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:29,074] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 19:06:29,123] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:29,125] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:29,134] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:29,139] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:29,140] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:29,180] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:29,181] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-23 19:06:29,199] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-23 19:06:29,200] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-23 19:06:29,213] clients.NetworkClient - Give up sending metadata request since no node is available
main DEBUG [2018-05-23 19:06:29,239] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:29,313] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-23 19:06:29,313] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:29,314] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:29,314] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:29,315] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-23 19:06:29,315] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-23 19:06:29,315] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-23 19:06:29,315] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-23 19:06:29,339] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-23 19:06:29,371] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:29,371] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-23 19:06:29,375] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-23 19:06:29,376] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-23 19:06:29,428] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-23 19:06:29,438] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-23 19:06:29,439] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main  INFO [2018-05-24 10:15:17,742] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-24 10:15:17,772] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 10:15:17,772] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-24 10:15:17,922] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null), azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)], partitions = [])
main  INFO [2018-05-24 10:15:18,613] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-24 10:15:18,613] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-24 10:15:18,613] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-24 10:15:18,613] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-24 10:15:18,613] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T10:15:18.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 10:15:18,613] kerberos.KerberosLogin - TGT expires: 2018-05-25T10:15:18.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 10:15:18,613] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T05:37:51.039-0400
main DEBUG [2018-05-24 10:15:18,628] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-24 10:15:18,629] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-24 10:15:18,630] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-24 10:15:18,630] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-24 10:15:18,631] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-24 10:15:18,632] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-24 10:15:18,632] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-24 10:15:18,642] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 10:15:18,654] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-24 10:15:18,654] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-24 10:15:18,655] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-24 10:15:18,659] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-24 10:15:18,666] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-24 10:15:18,667] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-24 10:15:18,667] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-24 10:15:18,667] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-24 10:15:18,668] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-24 10:15:18,671] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 10:15:18,671] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-24 10:15:18,671] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-24 10:15:18,672] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-24 10:15:18,672] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null)
main DEBUG [2018-05-24 10:15:18,694] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:15:18,701] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:15:18,704] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:15:18,877] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-05-24 10:15:18,879] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-05-24 10:15:18,881] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-05-24 10:15:18,924] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:15:18,925] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:15:18,981] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:15:19,175] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:15:19,232] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:15:19,241] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:15:19,242] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@52da37d8, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527171318691, sendTimeMs=0) with correlation id 0 due to node -2 being disconnected
main DEBUG [2018-05-24 10:15:19,275] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:15:19,275] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:15:19,275] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:15:19,276] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:15:19,335] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-24 10:15:19,337] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-24 10:15:19,339] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-24 10:15:19,340] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:15:19,341] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:15:19,396] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:15:19,556] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:15:19,625] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:15:19,626] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:15:19,657] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:19,658] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:15:19,658] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:15:19,659] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:15:19,660] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:15:19,728] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:15:19,728] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:15:19,757] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:19,798] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:15:19,800] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:15:19,857] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:19,869] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:15:19,869] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:15:19,957] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:19,963] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:15:19,963] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:15:19,963] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:15:19,963] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:15:20,037] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:15:20,038] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:15:20,057] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:20,110] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:15:20,113] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:15:20,157] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:20,183] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:15:20,185] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:15:20,258] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:20,264] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:15:20,264] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:15:20,265] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:15:20,265] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:15:20,266] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:15:20,266] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:15:20,267] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:15:20,267] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:15:20,328] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:15:20,328] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:15:20,339] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:15:20,340] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:15:20,362] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:20,402] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:15:20,404] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:15:20,410] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:15:20,415] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:15:20,462] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:20,463] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:15:20,464] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:15:20,486] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:15:20,487] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:15:20,501] clients.NetworkClient - Give up sending metadata request since no node is available
main DEBUG [2018-05-24 10:15:20,562] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:20,602] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:15:20,602] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:15:20,602] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:15:20,602] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:15:20,603] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:15:20,603] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:15:20,604] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:15:20,604] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:15:20,662] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:20,675] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:15:20,675] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:15:20,678] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:15:20,678] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:15:20,749] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:15:20,754] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:15:20,758] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:15:20,762] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:15:20,762] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:20,828] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:15:20,830] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:15:20,837] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:15:20,838] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:15:20,864] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:20,905] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:15:20,905] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:15:20,905] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:15:20,906] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:15:20,906] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:15:20,906] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:15:20,907] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:15:20,907] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:15:20,964] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:20,976] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:15:20,976] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:15:20,977] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:15:20,977] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:15:21,046] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:15:21,048] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:15:21,049] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:15:21,050] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:15:21,064] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:21,126] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:15:21,127] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:15:21,128] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:15:21,128] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:15:21,164] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:21,208] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:15:21,208] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:15:21,209] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:15:21,210] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:15:21,211] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:15:21,211] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:15:21,212] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:15:21,212] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:15:21,264] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:21,268] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:15:21,268] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:15:21,278] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:15:21,278] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:15:21,325] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:15:21,333] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:15:21,349] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:15:21,354] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:15:21,364] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:21,389] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:15:21,392] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:15:21,431] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:15:21,433] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:15:21,464] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:21,513] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:15:21,513] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:15:21,514] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:15:21,514] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:15:21,564] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:21,572] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:15:21,572] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:15:21,629] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:15:21,634] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:15:21,664] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:15:21,690] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:15:21,692] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:15:21,716] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:15:21,717] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:15:21,718] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:15:21,718] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:15:21,780] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main  INFO [2018-05-24 10:16:44,318] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-24 10:16:44,338] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 10:16:44,338] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-24 10:16:44,358] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null), azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)], partitions = [])
main  INFO [2018-05-24 10:16:44,828] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-24 10:16:44,828] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-24 10:16:44,828] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-24 10:16:44,828] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-24 10:16:44,828] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T10:16:44.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 10:16:44,828] kerberos.KerberosLogin - TGT expires: 2018-05-25T10:16:44.000-0400
main DEBUG [2018-05-24 10:16:44,829] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-24 10:16:44,829] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-24 10:16:44,829] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-24 10:16:44,829] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-24 10:16:44,829] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-24 10:16:44,829] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-24 10:16:44,829] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-24 10:16:44,836] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 10:16:44,847] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-24 10:16:44,848] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-24 10:16:44,848] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-24 10:16:44,851] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-24 10:16:44,857] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-24 10:16:44,857] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-24 10:16:44,857] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-24 10:16:44,858] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-24 10:16:44,858] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-24 10:16:44,860] utils.AppInfoParser - Kafka version : 0.10.0.1
kafka-kerberos-refresh-thread  INFO [2018-05-24 10:16:44,828] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T06:10:16.047-0400
main  INFO [2018-05-24 10:16:44,862] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-24 10:16:44,872] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-24 10:16:44,872] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-24 10:16:44,882] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)
main DEBUG [2018-05-24 10:16:44,902] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:44,902] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:44,903] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:44,905] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:44,905] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:44,905] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:44,905] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:44,958] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-24 10:16:44,959] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-24 10:16:44,960] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-24 10:16:44,986] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:44,986] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:44,987] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-05-24 10:16:44,988] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-05-24 10:16:44,988] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-05-24 10:16:44,990] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:44,990] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:45,048] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:45,184] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:45,184] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:45,334] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:45,335] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:45,351] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:45,408] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:45,409] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:45,411] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@4d37dfac, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527171404892, sendTimeMs=0) with correlation id 0 due to node -1 being disconnected
main DEBUG [2018-05-24 10:16:45,436] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:45,436] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:45,437] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:45,437] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:45,509] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:45,509] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:45,592] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:45,593] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:45,679] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:45,680] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:45,739] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:45,739] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:45,739] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:45,740] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:45,811] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:45,811] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:45,850] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:45,883] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:45,885] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:45,950] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:45,957] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:45,958] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:46,040] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:46,040] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:46,041] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:46,041] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:46,050] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:46,099] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:46,099] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:46,150] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:46,156] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:46,157] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:46,219] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:46,219] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:46,249] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:46,249] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:46,249] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:46,249] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:46,250] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:46,324] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:46,324] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:46,350] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:46,394] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:46,396] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:46,450] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:46,473] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:46,475] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:46,551] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:46,551] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:46,551] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:46,552] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:46,552] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:46,622] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:46,622] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:46,651] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:46,691] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:46,694] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:46,751] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:46,765] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:46,767] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:46,851] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:46,854] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:46,854] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:46,854] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:46,855] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:46,919] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:46,919] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:46,951] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:46,981] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:46,989] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:47,049] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:47,049] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:47,051] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:47,055] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:47,055] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:47,056] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:47,056] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:47,113] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:47,113] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:47,151] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:47,168] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:47,170] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:47,226] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:47,227] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:47,251] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:47,257] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:47,257] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:47,257] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:47,258] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:47,329] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:47,329] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:47,351] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:47,405] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:47,412] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:47,451] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:47,484] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:47,486] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:47,551] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:47,558] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:47,559] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:47,560] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:47,560] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:47,563] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:47,563] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:47,564] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:47,564] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:47,616] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:47,616] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:47,620] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:47,620] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:47,651] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:47,673] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:47,674] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:47,677] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:47,678] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:47,733] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:47,733] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:47,737] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:47,737] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:47,751] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:47,770] clients.NetworkClient - Give up sending metadata request since no node is available
main DEBUG [2018-05-24 10:16:47,851] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:47,870] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:47,870] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:47,870] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:47,870] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:47,950] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:47,951] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:47,951] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:48,042] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:48,049] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:48,051] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:48,136] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:48,137] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:48,155] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:48,171] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:48,171] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:48,171] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:48,172] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:48,230] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:48,230] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:48,255] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:48,289] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:48,291] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:48,348] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:48,349] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:48,355] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:48,372] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:48,373] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:48,374] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:48,375] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:48,430] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:48,430] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:48,455] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:48,486] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:48,487] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:48,545] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:48,549] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:48,555] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:48,577] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:48,577] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:48,577] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:48,577] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:48,661] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:48,661] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:48,661] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:48,731] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:48,732] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:48,761] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:48,808] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:48,809] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:48,861] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:48,879] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:48,879] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:48,879] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:48,880] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:48,935] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:48,935] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:48,961] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:48,991] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:48,992] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:49,049] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:49,050] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:49,061] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:49,080] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:49,080] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:49,080] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:49,081] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:49,152] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:49,152] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:49,161] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:49,225] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:49,229] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:49,261] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:49,301] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:49,303] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:49,361] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:49,381] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:49,381] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:49,381] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:49,381] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:49,382] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:49,382] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:49,383] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:49,383] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:49,437] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:49,438] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:49,439] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:49,439] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:49,461] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:49,500] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:49,507] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:49,509] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:49,515] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:49,561] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:49,576] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:49,577] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:49,580] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:49,582] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:49,583] clients.NetworkClient - Give up sending metadata request since no node is available
main DEBUG [2018-05-24 10:16:49,661] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:49,683] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:49,683] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:49,683] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:49,684] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:49,744] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:49,744] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:49,761] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:49,801] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:49,803] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:49,861] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:49,864] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:49,865] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:49,885] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:49,885] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:49,885] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:49,886] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:49,957] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:49,957] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:49,961] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:50,027] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:50,030] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:50,061] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:50,102] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:50,104] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:50,161] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:50,186] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:50,186] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:50,186] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:50,187] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:50,261] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:50,275] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:50,275] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:50,358] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:50,361] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:50,361] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:50,443] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:50,445] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:50,461] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:50,487] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:50,487] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:50,488] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:50,488] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:50,544] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:50,544] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:50,561] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:50,601] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:50,605] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:50,661] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:50,662] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:50,663] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:50,688] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:50,688] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:50,689] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:50,689] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:50,749] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:50,749] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:50,762] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:50,805] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:50,807] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:50,862] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:50,863] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:50,863] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:50,890] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:50,890] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:50,890] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:50,891] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:50,961] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:50,961] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:50,962] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:51,030] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:51,032] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:51,062] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:51,104] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:51,104] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:51,162] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:51,191] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:51,191] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:51,191] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:51,191] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:51,192] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:51,192] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:51,192] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:51,192] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:51,262] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:51,273] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:51,273] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:51,273] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:51,273] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:51,352] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:51,353] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:51,353] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:51,355] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:51,362] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:51,442] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:51,442] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:51,442] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:51,443] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:51,462] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:51,493] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:51,493] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:51,493] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:51,493] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:51,562] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:51,566] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:51,566] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:51,638] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:51,639] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:51,662] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:51,715] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:51,716] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:51,762] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:51,794] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:51,794] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:51,794] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:51,794] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:51,862] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:51,883] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:51,883] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:51,951] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:51,953] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:51,962] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:52,025] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:52,028] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:52,062] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:52,095] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:52,096] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:52,097] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:52,098] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:52,100] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:52,101] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:52,102] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:52,103] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:52,163] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:52,164] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:52,164] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:52,166] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:52,167] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:52,220] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:52,222] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:52,237] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:52,239] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:52,263] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:52,279] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:52,281] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:52,308] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:52,309] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:52,363] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:52,405] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:52,405] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:52,405] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:52,405] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:52,463] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:52,479] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:52,479] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:52,550] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:52,556] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:52,563] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:52,626] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:52,627] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:52,663] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:52,706] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:52,706] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:52,708] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:52,708] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:52,708] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:52,708] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:52,709] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:52,709] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:52,763] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:52,763] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:52,764] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:52,766] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:52,766] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:52,820] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:52,827] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:52,828] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:52,831] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:52,863] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:52,883] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:52,884] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:52,887] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:52,888] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:52,909] clients.NetworkClient - Give up sending metadata request since no node is available
main DEBUG [2018-05-24 10:16:52,963] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:53,009] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:53,010] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:53,011] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:53,012] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:53,014] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:53,014] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:53,015] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:53,016] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:53,063] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:53,070] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:53,070] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:53,072] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:53,072] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:53,126] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:53,127] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:53,128] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:53,129] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:53,163] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:53,194] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:53,195] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:53,195] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:53,196] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:53,218] clients.NetworkClient - Give up sending metadata request since no node is available
main DEBUG [2018-05-24 10:16:53,263] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:53,319] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:53,319] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:53,320] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:53,320] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:53,321] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:53,321] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:53,321] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:53,322] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:53,363] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:53,393] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:53,393] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:53,393] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:53,393] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:53,463] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:53,464] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:53,470] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:53,471] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:53,476] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:53,554] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:53,554] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:53,558] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:53,558] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:53,563] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:53,623] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:53,623] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:53,623] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:53,623] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:53,663] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:53,697] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:53,697] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:53,763] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:53,772] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:53,779] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:53,863] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:53,868] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:53,878] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:53,924] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:53,924] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:53,925] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:53,925] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:53,963] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:54,004] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:54,004] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:54,063] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:54,074] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:54,085] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:54,157] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:54,157] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:54,163] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:54,227] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:54,227] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:54,227] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:54,227] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:54,263] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:54,283] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:54,283] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:54,340] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:54,344] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:54,363] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:54,400] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:54,403] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:54,429] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:54,430] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:54,431] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:54,431] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:54,463] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:54,487] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:54,487] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:54,543] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:54,544] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:54,563] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:54,602] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:54,604] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:54,633] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:54,633] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:54,633] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:54,633] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:54,663] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:54,689] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:54,689] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:54,746] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:54,748] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:54,763] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:54,804] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:54,805] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:54,835] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:54,835] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:54,835] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:54,836] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:54,863] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:54,892] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:54,892] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:54,948] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:54,955] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:54,963] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:55,012] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:55,012] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:55,037] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:55,037] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:55,038] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:55,039] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:55,069] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:55,112] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:55,112] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:55,169] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:55,198] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:55,201] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:55,269] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:55,274] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:55,274] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:55,340] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:55,341] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:55,342] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:55,343] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:55,369] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:55,410] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:55,411] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:55,469] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:55,478] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:55,484] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:55,550] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:55,551] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:55,569] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:55,646] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:55,647] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:55,648] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:55,648] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:55,649] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:55,649] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:55,650] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:55,650] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:55,669] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:55,718] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:55,718] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:55,722] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:55,722] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:55,769] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:55,789] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:55,797] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:55,798] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:55,800] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:55,869] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:55,870] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:55,872] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:55,873] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:55,875] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:55,950] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:55,951] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:55,952] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:55,953] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:55,969] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:56,022] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:56,022] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:56,070] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:56,101] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:56,103] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:56,170] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:56,173] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:56,174] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:56,256] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:56,257] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:56,259] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:56,260] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:56,270] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:56,329] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:56,330] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:56,370] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:56,402] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:56,405] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:56,470] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:56,474] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:56,475] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:56,563] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:56,563] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:56,565] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:56,565] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:56,570] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:56,636] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:56,636] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:56,670] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:56,705] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:56,707] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:56,770] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:56,778] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:56,780] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:56,868] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:56,869] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:56,869] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:56,869] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:56,870] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:56,925] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:56,925] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:56,970] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:56,981] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:56,983] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:57,041] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:57,043] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:57,070] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:57,070] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:57,071] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:57,072] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:57,073] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:57,128] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:57,129] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:57,170] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:57,184] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:57,186] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:57,253] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:57,255] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:57,270] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:57,275] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:57,275] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:57,276] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:57,276] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:57,333] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:57,333] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:57,370] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:57,389] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:57,392] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:57,449] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:57,451] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:57,470] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:57,477] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:57,478] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:57,478] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:57,478] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:57,538] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:57,539] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:57,570] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:57,595] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:57,619] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:57,670] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:57,675] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:57,676] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:57,681] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:57,681] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:57,682] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:57,683] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:57,753] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:57,753] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:57,770] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:57,826] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:57,833] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:57,870] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:57,903] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:57,904] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:57,971] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:57,984] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:57,984] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:57,985] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:57,985] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:57,986] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:57,986] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:57,987] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:57,987] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:58,056] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:58,056] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:58,058] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:58,058] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:58,071] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:58,127] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:58,130] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:58,131] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:58,134] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:58,171] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:58,200] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:58,202] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:58,204] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:58,208] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:58,271] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:58,288] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:58,288] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:58,290] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:58,290] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:58,291] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:58,292] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:58,293] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:58,293] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:58,355] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:58,355] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:58,361] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:58,361] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:58,371] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:58,411] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:58,412] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:58,437] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:58,439] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:58,468] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:58,469] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:58,471] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:58,510] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:58,512] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:58,571] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:58,596] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:58,596] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:58,597] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:58,597] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:58,598] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:58,598] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:58,598] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:58,599] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:58,652] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:58,653] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:58,671] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:58,675] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:58,675] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:58,709] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:58,715] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:58,745] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:58,748] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:58,771] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:58,772] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:58,773] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:58,818] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:58,819] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:58,871] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:58,899] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:58,899] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:58,900] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:58,900] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:58,970] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:58,970] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:58,971] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:59,044] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:59,046] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:59,071] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:59,118] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:59,119] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:59,171] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:59,200] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:59,200] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:59,200] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:59,201] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:59,270] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:59,270] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:59,271] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:59,344] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:59,347] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:59,371] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:59,427] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:59,429] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:59,472] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:59,501] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:59,501] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:59,502] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:59,502] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:59,503] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:16:59,504] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:59,504] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:59,504] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:59,563] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:59,564] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:59,567] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:59,568] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:16:59,572] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:59,619] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:59,621] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:59,624] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:59,625] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:59,672] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:59,677] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:59,678] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:16:59,681] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:59,682] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:16:59,705] clients.NetworkClient - Give up sending metadata request since no node is available
main DEBUG [2018-05-24 10:16:59,772] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:59,805] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:16:59,805] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:16:59,805] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:16:59,806] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:16:59,861] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:16:59,861] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:16:59,872] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:59,916] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:16:59,917] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:16:59,972] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:16:59,974] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:16:59,976] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:17:00,009] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:17:00,009] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:00,010] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:00,010] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:00,072] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:00,081] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:00,081] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:17:00,161] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:00,162] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:00,172] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:00,234] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:00,236] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:17:00,272] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:00,316] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:17:00,316] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:00,318] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:00,318] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:00,321] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:17:00,321] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:00,322] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:00,323] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:00,373] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:00,379] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:00,379] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:17:00,388] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:00,388] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:17:00,435] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:00,436] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:00,459] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:00,462] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:00,474] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:00,493] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:00,495] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:17:00,532] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:00,533] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:17:00,574] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:00,627] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:17:00,627] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:00,628] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:00,628] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:00,629] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:17:00,629] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:00,630] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:00,630] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:00,674] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:00,684] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:00,684] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:17:00,698] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:00,698] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:17:00,740] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:00,746] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:00,772] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:00,777] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:00,777] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:00,802] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:00,803] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:17:00,849] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:00,850] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:17:00,877] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:00,931] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:17:00,931] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:00,931] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:00,932] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:00,977] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:01,002] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:01,002] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:17:01,077] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:01,078] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:01,081] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:01,151] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:01,152] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:17:01,177] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:01,232] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:17:01,233] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:01,233] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:01,234] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:01,235] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:17:01,235] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:01,236] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:01,237] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:01,277] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:01,305] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:01,305] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:17:01,309] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:01,309] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:17:01,374] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:01,376] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:01,377] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:01,382] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:01,383] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:01,446] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:01,448] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:17:01,454] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:01,456] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:17:01,477] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:01,538] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:17:01,539] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:01,541] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:01,542] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:01,544] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:17:01,545] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:01,547] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:01,547] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:01,577] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:01,612] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:01,612] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:17:01,617] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:01,617] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:17:01,677] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:01,693] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:01,699] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:01,700] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:01,705] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:01,776] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:01,777] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:17:01,777] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:01,778] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:01,780] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:17:01,851] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:17:01,852] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:01,853] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:01,854] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:01,877] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:01,924] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:01,924] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:17:01,977] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:01,993] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:01,997] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:02,071] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:02,072] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:17:02,077] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:02,156] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:17:02,156] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:02,158] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:02,158] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:02,159] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:17:02,160] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:02,160] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:02,161] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:02,177] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:02,214] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:02,214] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:17:02,232] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:02,232] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:17:02,272] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:02,277] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:02,278] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:02,303] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:02,305] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:02,334] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:02,335] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:17:02,378] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:02,381] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:02,383] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:17:02,462] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:17:02,462] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:02,463] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:02,463] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:02,464] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:17:02,464] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:02,465] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:02,466] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:02,478] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:02,525] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:02,526] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:17:02,527] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:02,527] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:17:02,578] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:02,585] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:02,588] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:02,588] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:02,589] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:02,644] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:02,645] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:17:02,646] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:02,647] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:17:02,667] clients.NetworkClient - Give up sending metadata request since no node is available
main DEBUG [2018-05-24 10:17:02,678] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:02,767] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:17:02,767] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:02,767] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:02,767] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:02,778] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:02,844] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:02,844] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:17:02,878] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:02,913] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:02,922] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:02,978] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:02,992] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:02,994] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:17:03,068] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:17:03,068] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:03,069] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:03,069] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:03,070] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:17:03,070] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:03,070] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:03,071] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:03,078] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:03,155] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:03,155] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:17:03,155] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:03,156] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:17:03,178] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:03,239] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:03,241] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:03,242] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:03,244] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:03,278] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:03,320] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:03,320] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:17:03,322] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:03,322] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:17:03,371] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:17:03,371] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:03,371] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:03,371] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:03,378] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:03,441] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:03,441] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:17:03,478] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:03,511] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:03,516] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:03,578] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:03,588] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:03,588] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:17:03,673] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:17:03,673] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:03,673] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:03,674] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:03,674] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:17:03,674] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:03,675] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:03,675] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:03,678] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:03,731] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:03,732] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:17:03,744] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:03,745] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:17:03,778] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:03,787] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:03,788] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:03,813] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:03,814] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:03,844] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:03,845] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:17:03,878] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:03,886] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:03,888] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:17:03,976] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:17:03,976] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:03,977] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:03,977] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:17:03,978] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:04,047] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:17:04,047] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:17:04,078] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:04,115] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:17:04,116] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:17:04,178] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:04,187] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:17:04,188] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:17:04,278] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:17:04,278] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:17:04,278] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:17:04,279] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:17:04,279] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main  INFO [2018-05-24 10:28:47,123] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-24 10:28:47,153] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 10:28:47,153] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-24 10:28:47,173] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null), azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null)], partitions = [])
main  INFO [2018-05-24 10:28:47,685] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-24 10:28:47,685] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-24 10:28:47,685] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-24 10:28:47,685] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-24 10:28:47,685] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T10:28:47.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 10:28:47,685] kerberos.KerberosLogin - TGT expires: 2018-05-25T10:28:47.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 10:28:47,685] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T06:16:52.330-0400
main DEBUG [2018-05-24 10:28:47,695] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-24 10:28:47,695] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-24 10:28:47,695] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-24 10:28:47,695] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-24 10:28:47,695] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-24 10:28:47,695] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-24 10:28:47,695] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-24 10:28:47,705] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 10:28:47,715] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-24 10:28:47,715] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-24 10:28:47,715] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-24 10:28:47,716] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-24 10:28:47,717] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-24 10:28:47,718] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-24 10:28:47,718] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-24 10:28:47,719] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-24 10:28:47,719] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-24 10:28:47,722] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 10:28:47,722] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-24 10:28:47,722] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-24 10:28:47,724] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-24 10:28:47,724] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)
main DEBUG [2018-05-24 10:28:47,750] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:47,756] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:47,758] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:47,835] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-24 10:28:47,835] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-24 10:28:47,836] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-24 10:28:47,846] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:47,846] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:28:47,935] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:48,085] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:48,155] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:48,161] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:28:48,162] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@1c7534c0, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527172127745, sendTimeMs=0) with correlation id 0 due to node -1 being disconnected
main DEBUG [2018-05-24 10:28:48,185] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:28:48,185] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:48,185] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:48,185] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:48,257] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-05-24 10:28:48,258] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-05-24 10:28:48,258] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-05-24 10:28:48,259] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:48,259] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:28:48,329] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:48,482] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:48,552] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:48,553] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:28:48,583] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:28:48,583] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:48,583] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:48,583] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:48,654] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:48,654] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:28:48,716] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:48,726] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:48,730] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:48,800] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:48,801] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:28:48,816] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:48,884] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:28:48,884] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:48,886] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:48,886] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:48,889] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:28:48,889] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:48,890] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:48,890] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:48,917] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:48,955] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:48,956] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:28:48,964] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:48,964] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:28:49,017] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:49,020] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:49,021] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:49,027] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:49,028] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:49,099] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:49,099] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:28:49,117] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:49,217] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:49,317] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:49,417] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:49,517] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:49,525] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:49,525] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:28:49,593] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:28:49,593] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:49,593] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:49,593] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:49,617] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:49,662] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:49,662] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:28:49,717] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:49,732] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:49,733] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:49,803] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:49,803] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:28:49,818] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:49,894] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:28:49,894] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:49,895] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:49,895] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:49,918] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:49,950] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:49,951] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:28:50,006] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:50,008] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:50,018] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:50,065] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:50,066] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:28:50,096] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:28:50,096] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:50,097] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:50,097] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:50,118] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:50,154] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:50,155] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:28:50,210] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:50,212] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:50,218] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:50,269] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:50,270] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:28:50,299] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:28:50,299] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:50,300] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:50,300] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:50,318] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:50,370] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:50,371] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:28:50,418] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:50,439] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:50,441] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:50,518] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:50,520] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:28:50,521] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:50,600] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:28:50,600] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:50,600] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:50,600] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:50,621] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:50,676] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:50,677] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:28:50,721] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:50,746] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:50,747] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:50,817] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:50,818] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:28:50,821] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:50,901] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:28:50,902] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:50,904] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:50,905] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:50,921] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:50,978] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:50,978] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:28:51,021] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:51,050] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:51,053] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:51,121] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:51,125] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:51,127] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:28:51,207] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:28:51,207] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:51,208] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:51,208] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:51,209] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:28:51,210] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:51,210] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:51,210] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:51,221] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:51,271] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:51,271] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:28:51,279] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:51,279] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:28:51,321] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:51,331] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:51,333] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:51,348] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:51,350] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:51,395] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:51,396] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:28:51,419] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:51,419] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 10:28:51,421] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:51,514] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 10:28:51,514] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:51,515] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:51,515] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:51,515] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 10:28:51,515] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 10:28:51,516] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 10:28:51,516] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 10:28:51,521] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:51,587] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:51,588] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 10:28:51,589] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 10:28:51,589] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 10:28:51,621] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:51,657] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:51,658] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:51,659] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 10:28:51,660] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 10:28:51,721] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 10:28:51,733] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:51,737] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 10:28:51,738] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 10:28:51,741] clients.NetworkClient - Node -1 disconnected.
main  INFO [2018-05-24 11:10:01,101] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-24 11:10:01,183] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 11:10:01,183] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-24 11:10:01,345] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null), azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)], partitions = [])
main  INFO [2018-05-24 11:10:02,107] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-24 11:10:02,108] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-24 11:10:02,110] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-24 11:10:02,114] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-24 11:10:02,114] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T11:10:01.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 11:10:02,115] kerberos.KerberosLogin - TGT expires: 2018-05-25T11:10:01.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 11:10:02,115] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T06:30:16.345-0400
main DEBUG [2018-05-24 11:10:02,136] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-24 11:10:02,137] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-24 11:10:02,137] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-24 11:10:02,138] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-24 11:10:02,139] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-24 11:10:02,140] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-24 11:10:02,140] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-24 11:10:02,159] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 11:10:02,175] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-24 11:10:02,176] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-24 11:10:02,176] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-24 11:10:02,179] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-24 11:10:02,189] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-24 11:10:02,190] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-24 11:10:02,190] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-24 11:10:02,191] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-24 11:10:02,191] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-24 11:10:02,196] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 11:10:02,196] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-24 11:10:02,196] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-24 11:10:02,197] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-24 11:10:02,197] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)
main DEBUG [2018-05-24 11:10:02,244] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 11:10:02,252] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:10:02,254] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:10:02,405] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 11:10:02,405] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 11:10:02,406] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:10:02,406] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main  INFO [2018-05-24 11:27:31,203] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-24 11:27:31,233] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 11:27:31,233] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-24 11:27:31,253] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null), azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null)], partitions = [])
main  INFO [2018-05-24 11:27:31,691] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-24 11:27:31,691] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-24 11:27:31,701] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-24 11:27:31,701] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-24 11:27:31,701] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T11:27:31.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 11:27:31,701] kerberos.KerberosLogin - TGT expires: 2018-05-25T11:27:31.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 11:27:31,701] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T06:58:52.757-0400
main DEBUG [2018-05-24 11:27:31,711] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-24 11:27:31,711] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-24 11:27:31,711] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-24 11:27:31,711] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-24 11:27:31,712] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-24 11:27:31,712] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-24 11:27:31,712] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-24 11:27:31,713] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 11:27:31,729] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-24 11:27:31,729] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-24 11:27:31,730] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-24 11:27:31,734] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-24 11:27:31,740] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-24 11:27:31,741] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-24 11:27:31,741] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-24 11:27:31,741] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-24 11:27:31,742] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-24 11:27:31,744] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 11:27:31,744] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-24 11:27:31,744] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-24 11:27:31,745] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-24 11:27:31,745] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)
main DEBUG [2018-05-24 11:27:31,764] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:31,771] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:31,772] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:31,786] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 11:27:31,786] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:31,786] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:31,786] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:31,821] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-24 11:27:31,822] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-24 11:27:31,822] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-24 11:27:31,835] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:31,835] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 11:27:31,856] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-05-24 11:27:31,856] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-05-24 11:27:31,857] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-05-24 11:27:31,857] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:31,857] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 11:27:31,892] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:32,065] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:32,065] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:32,220] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:32,220] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:32,225] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 11:27:32,226] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@2a8f6be6, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527175651761, sendTimeMs=0) with correlation id 0 due to node -1 being disconnected
main DEBUG [2018-05-24 11:27:32,292] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:32,292] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 11:27:32,320] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 11:27:32,320] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:32,320] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:32,320] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:32,376] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:32,376] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 11:27:32,432] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:32,441] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:32,498] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:32,498] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 11:27:32,522] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 11:27:32,522] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:32,522] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:32,522] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:32,579] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:32,579] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 11:27:32,635] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:32,645] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:32,702] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:32,702] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 11:27:32,724] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 11:27:32,724] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:32,724] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:32,724] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:32,733] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:32,780] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:32,780] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 11:27:32,833] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:32,836] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:32,842] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:32,898] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:32,899] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 11:27:32,925] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 11:27:32,925] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:32,925] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:32,925] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:32,933] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:33,044] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:33,044] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 11:27:33,044] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:33,112] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:33,123] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:33,144] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:33,194] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:33,195] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 11:27:33,244] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:33,244] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 11:27:33,244] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:33,244] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:33,244] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:33,245] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 11:27:33,245] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:33,246] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:33,246] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:33,302] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:33,302] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 11:27:33,314] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:33,315] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 11:27:33,344] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:33,358] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:33,363] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:33,385] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:33,389] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:33,420] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:33,420] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 11:27:33,444] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:33,459] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:33,460] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 11:27:33,544] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:33,546] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 11:27:33,546] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:33,546] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:33,546] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:33,602] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:33,602] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 11:27:33,644] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:33,658] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:33,661] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:33,718] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:33,719] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 11:27:33,744] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:33,748] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 11:27:33,748] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:33,750] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:33,750] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:33,824] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:33,824] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 11:27:33,844] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:33,894] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:33,897] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:33,944] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:33,970] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:33,970] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 11:27:34,044] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:34,055] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 11:27:34,055] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:34,055] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:34,055] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:34,056] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 11:27:34,056] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:34,057] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:34,057] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:34,112] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:34,112] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 11:27:34,112] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:34,112] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 11:27:34,144] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:34,168] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:34,170] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:34,171] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:34,173] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:34,229] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:34,235] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 11:27:34,236] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:34,238] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 11:27:34,245] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:34,257] clients.NetworkClient - Give up sending metadata request since no node is available
main DEBUG [2018-05-24 11:27:34,345] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:34,357] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 11:27:34,357] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:34,357] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:34,357] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:34,413] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:34,413] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 11:27:34,445] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:34,470] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:34,472] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:34,530] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:34,530] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 11:27:34,545] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:34,558] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 11:27:34,558] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:34,558] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:34,558] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:34,631] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:34,631] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 11:27:34,645] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:34,700] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:34,703] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:34,745] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:34,772] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:34,773] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 11:27:34,845] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:34,859] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 11:27:34,859] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:34,859] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:34,860] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:34,861] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 11:27:34,861] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:34,861] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:34,862] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:34,918] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:34,918] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 11:27:34,931] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:34,931] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 11:27:34,945] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:34,975] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:34,978] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:35,001] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:35,003] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:35,034] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:35,035] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 11:27:35,045] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:35,074] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:35,074] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 11:27:35,145] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:35,163] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 11:27:35,163] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:35,163] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:35,163] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:35,164] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 11:27:35,164] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 11:27:35,164] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 11:27:35,164] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 11:27:35,220] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:35,220] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 11:27:35,220] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 11:27:35,220] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 11:27:35,245] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:35,275] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:35,278] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:35,278] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 11:27:35,280] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 11:27:35,334] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:35,336] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 11:27:35,337] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 11:27:35,338] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 11:27:35,345] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 11:27:35,364] clients.NetworkClient - Give up sending metadata request since no node is available
main  INFO [2018-05-24 12:08:24,276] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-24 12:08:24,306] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 12:08:24,306] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-24 12:08:24,316] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null), azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null)], partitions = [])
main  INFO [2018-05-24 12:08:24,771] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-24 12:08:24,771] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-24 12:08:24,771] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-24 12:08:24,771] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-24 12:08:24,771] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T12:08:24.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 12:08:24,771] kerberos.KerberosLogin - TGT expires: 2018-05-25T12:08:24.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 12:08:24,771] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T08:03:56.045-0400
main DEBUG [2018-05-24 12:08:24,791] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-24 12:08:24,791] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-24 12:08:24,791] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-24 12:08:24,791] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-24 12:08:24,791] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-24 12:08:24,791] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-24 12:08:24,791] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-24 12:08:24,801] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 12:08:24,812] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-24 12:08:24,812] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-24 12:08:24,812] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-24 12:08:24,812] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-24 12:08:24,820] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-24 12:08:24,820] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-24 12:08:24,821] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-24 12:08:24,821] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-24 12:08:24,821] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-24 12:08:24,825] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 12:08:24,826] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-24 12:08:24,826] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-24 12:08:24,827] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-24 12:08:24,827] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)
main DEBUG [2018-05-24 12:08:24,852] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 12:08:24,858] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 12:08:24,860] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 12:08:24,909] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-24 12:08:24,909] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-24 12:08:24,910] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-24 12:08:24,924] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 12:08:24,924] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 12:08:24,981] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 12:08:25,139] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 12:08:25,195] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 12:08:25,198] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 12:08:25,199] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@4f4f5969, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527178104847, sendTimeMs=0) with correlation id 0 due to node -1 being disconnected
main DEBUG [2018-05-24 12:08:25,239] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 12:08:25,239] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 12:08:25,239] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 12:08:25,239] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 12:08:25,311] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-05-24 12:08:25,312] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-05-24 12:08:25,312] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-05-24 12:08:25,313] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 12:08:25,313] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 12:08:25,382] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 12:08:25,536] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 12:08:25,606] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 12:08:25,607] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 12:08:25,636] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 12:08:25,636] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 12:08:25,636] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 12:08:25,636] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 12:08:25,693] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 12:08:25,693] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 12:08:25,750] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 12:08:25,759] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 12:08:25,813] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:25,816] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 12:08:25,816] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 12:08:25,837] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 12:08:25,837] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 12:08:25,837] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 12:08:25,837] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 12:08:25,907] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 12:08:25,908] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 12:08:25,913] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:25,979] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 12:08:25,988] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 12:08:26,013] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:26,058] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 12:08:26,058] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 12:08:26,113] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:26,139] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 12:08:26,139] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 12:08:26,139] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 12:08:26,139] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 12:08:26,140] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 12:08:26,141] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 12:08:26,141] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 12:08:26,141] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 12:08:26,195] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 12:08:26,195] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 12:08:26,210] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 12:08:26,210] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 12:08:26,213] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:26,251] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 12:08:26,257] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 12:08:26,282] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 12:08:26,291] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 12:08:26,313] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:26,315] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 12:08:26,316] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 12:08:26,360] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 12:08:26,361] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 12:08:26,413] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:26,448] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 12:08:26,448] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 12:08:26,448] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 12:08:26,448] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 12:08:26,505] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 12:08:26,505] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 12:08:26,513] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:26,561] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 12:08:26,567] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 12:08:26,613] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:26,623] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 12:08:26,624] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 12:08:26,649] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 12:08:26,649] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 12:08:26,649] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 12:08:26,649] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 12:08:26,713] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:26,719] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 12:08:26,719] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 12:08:26,791] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 12:08:26,794] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 12:08:26,813] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:26,864] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 12:08:26,865] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 12:08:26,913] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:26,950] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 12:08:26,950] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 12:08:26,950] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 12:08:26,950] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 12:08:26,951] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 12:08:26,951] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 12:08:26,951] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 12:08:26,952] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 12:08:27,013] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:27,020] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 12:08:27,020] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 12:08:27,020] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 12:08:27,020] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 12:08:27,089] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 12:08:27,091] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 12:08:27,091] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 12:08:27,094] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 12:08:27,113] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:27,162] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 12:08:27,163] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 12:08:27,168] network.Selector - Connection with azbuvuatkafka02.activehealth.loc/172.18.49.42 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 12:08:27,168] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 12:08:27,213] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:27,252] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 12:08:27,252] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 12:08:27,252] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 12:08:27,252] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 12:08:27,313] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:27,322] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 12:08:27,322] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 12:08:27,392] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 12:08:27,395] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 12:08:27,413] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:27,465] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveResponseOrToken(SaslClientAuthenticator.java:239) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:182) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 12:08:27,465] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 12:08:27,513] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 12:08:27,553] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 12:08:27,553] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 12:08:27,553] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 12:08:27,553] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 12:08:27,554] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 12:08:27,554] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 12:08:27,554] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 12:08:27,554] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 12:08:27,610] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 12:08:27,610] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 12:08:27,611] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 12:08:27,611] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 12:08:27,613] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main  INFO [2018-05-24 15:29:14,389] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-24 15:29:14,421] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:29:14,422] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-24 15:29:14,552] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null), azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null)], partitions = [])
main  INFO [2018-05-24 15:29:15,088] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-24 15:29:15,088] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:29:15,090] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-24 15:29:15,090] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:29:15,091] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T15:29:14.000-0400
main DEBUG [2018-05-24 15:29:15,101] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-24 15:29:15,102] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-24 15:29:15,103] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-24 15:29:15,103] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-24 15:29:15,104] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-24 15:29:15,104] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-24 15:29:15,104] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-24 15:29:15,113] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:29:15,124] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-24 15:29:15,124] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-24 15:29:15,125] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-24 15:29:15,127] metrics.Metrics - Added sensor with name commit-latency
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:29:15,093] kerberos.KerberosLogin - TGT expires: 2018-05-25T15:29:14.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:29:15,128] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T10:45:56.832-0400
main DEBUG [2018-05-24 15:29:15,136] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-24 15:29:15,136] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-24 15:29:15,136] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-24 15:29:15,137] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-24 15:29:15,137] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-24 15:29:15,140] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 15:29:15,140] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-24 15:29:15,141] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-24 15:29:15,141] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-24 15:29:15,142] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)
main DEBUG [2018-05-24 15:29:15,162] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 15:29:15,167] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:29:15,169] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:29:15,244] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-24 15:29:15,247] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-24 15:29:15,248] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-24 15:29:15,276] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:29:15,276] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 15:29:15,353] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:29:15,500] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-24 15:29:15,513] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 15:29:15,514] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@1147d0ad, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527190155159, sendTimeMs=0) with correlation id 0 due to node -1 being disconnected
main DEBUG [2018-05-24 15:29:15,514] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 15:29:15,514] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 15:29:15,514] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:29:15,514] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:29:15,845] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 15:29:15,845] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 15:29:15,846] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:29:15,846] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main  INFO [2018-05-24 15:31:07,397] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-24 15:31:07,428] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:31:07,429] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-24 15:31:07,441] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null), azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)], partitions = [])
main  INFO [2018-05-24 15:31:07,867] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-24 15:31:07,867] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:31:07,868] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-24 15:31:07,869] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:31:07,869] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T15:31:07.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:31:07,869] kerberos.KerberosLogin - TGT expires: 2018-05-25T15:31:07.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:31:07,870] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T11:06:27.030-0400
main DEBUG [2018-05-24 15:31:07,885] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-24 15:31:07,886] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-24 15:31:07,887] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-24 15:31:07,887] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-24 15:31:07,889] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-24 15:31:07,889] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-24 15:31:07,889] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-24 15:31:07,899] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:31:07,913] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-24 15:31:07,913] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-24 15:31:07,914] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-24 15:31:07,916] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-24 15:31:07,922] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-24 15:31:07,923] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-24 15:31:07,923] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-24 15:31:07,923] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-24 15:31:07,924] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-24 15:31:07,926] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 15:31:07,926] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-24 15:31:07,927] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-24 15:31:07,927] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-24 15:31:07,928] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null)
main DEBUG [2018-05-24 15:31:07,946] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 15:31:07,950] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:31:07,952] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:31:07,963] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 15:31:07,963] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 15:31:07,963] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:31:07,963] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:31:08,017] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-24 15:31:08,017] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-24 15:31:08,018] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-24 15:31:08,030] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:31:08,031] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 15:31:08,101] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:31:08,230] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-24 15:31:08,247] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 15:31:08,249] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@1147d0ad, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527190267943, sendTimeMs=0) with correlation id 0 due to node -1 being disconnected
main DEBUG [2018-05-24 15:31:08,349] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 15:31:08,349] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.activehealth.loc:9092.
main DEBUG [2018-05-24 15:31:08,350] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:31:08,350] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.activehealth.loc;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:31:08,420] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:31:08,420] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 15:31:08,489] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:31:08,638] network.Selector - Connection with azbuvuatkafka01.activehealth.loc/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-24 15:31:08,641] clients.NetworkClient - Node -1 disconnected.
main  INFO [2018-05-24 15:32:34,463] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-05-24 15:32:34,491] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:32:34,492] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-24 15:32:34,504] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka01.activehealth.loc:9092 (id: -1 rack: null), azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null)], partitions = [])
main  INFO [2018-05-24 15:32:34,974] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-24 15:32:34,975] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:32:34,976] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-24 15:32:34,976] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:32:34,977] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T15:32:34.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:32:34,977] kerberos.KerberosLogin - TGT expires: 2018-05-25T15:32:34.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:32:34,977] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T11:39:00.977-0400
main DEBUG [2018-05-24 15:32:34,992] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-24 15:32:34,994] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-24 15:32:34,994] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-24 15:32:34,994] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-24 15:32:34,996] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-24 15:32:34,996] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-24 15:32:34,997] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-24 15:32:35,007] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.activehealth.loc:9092, azbuvuatkafka02.activehealth.loc:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:32:35,021] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-24 15:32:35,021] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-24 15:32:35,021] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-24 15:32:35,025] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-24 15:32:35,031] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-24 15:32:35,031] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-24 15:32:35,032] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-24 15:32:35,032] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-24 15:32:35,032] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-24 15:32:35,036] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 15:32:35,036] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-24 15:32:35,036] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-24 15:32:35,037] consumer.KafkaConsumer - Subscribed to topic(s): MemberDataNewEvents
main DEBUG [2018-05-24 15:32:35,037] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka02.activehealth.loc:9092 (id: -2 rack: null)
main DEBUG [2018-05-24 15:32:35,055] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.activehealth.loc:9092.
main DEBUG [2018-05-24 15:32:35,060] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:32:35,062] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.activehealth.loc;mechs=[GSSAPI]
main  INFO [2018-05-24 15:34:17,176] careengine.CEKafkaConsumer - Topic name is: CEmemberRun
main  INFO [2018-05-24 15:34:17,202] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvqa1kafka01:9092, azbuvqa1kafka02:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:34:17,203] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-24 15:34:17,345] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvqa1kafka02:9092 (id: -2 rack: null), azbuvqa1kafka01:9092 (id: -1 rack: null)], partitions = [])
main  INFO [2018-05-24 15:34:17,796] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-24 15:34:17,796] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:34:17,798] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-24 15:34:17,799] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:34:17,799] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T15:34:17.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:34:17,799] kerberos.KerberosLogin - TGT expires: 2018-05-25T15:34:17.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:34:17,800] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T11:14:49.000-0400
main DEBUG [2018-05-24 15:34:17,815] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-24 15:34:17,817] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-24 15:34:17,817] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-24 15:34:17,817] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-24 15:34:17,819] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-24 15:34:17,819] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-24 15:34:17,820] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-24 15:34:17,830] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvqa1kafka01:9092, azbuvqa1kafka02:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:34:17,847] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-24 15:34:17,848] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-24 15:34:17,848] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-24 15:34:17,853] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-24 15:34:17,862] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-24 15:34:17,862] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-24 15:34:17,863] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-24 15:34:17,863] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-24 15:34:17,864] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-24 15:34:17,866] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 15:34:17,867] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-24 15:34:17,867] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-24 15:34:17,868] consumer.KafkaConsumer - Subscribed to topic(s): CEmemberRun
main DEBUG [2018-05-24 15:34:17,868] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvqa1kafka02:9092 (id: -2 rack: null)
main DEBUG [2018-05-24 15:34:17,891] clients.NetworkClient - Initiating connection to node -2 at azbuvqa1kafka02:9092.
main DEBUG [2018-05-24 15:34:17,898] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:34:17,900] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvqa1kafka02;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:34:18,042] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 15:34:18,043] clients.NetworkClient - Initiating connection to node -1 at azbuvqa1kafka01:9092.
main DEBUG [2018-05-24 15:34:18,044] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:34:18,045] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvqa1kafka01;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:34:18,177] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-05-24 15:34:18,178] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-05-24 15:34:18,179] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-05-24 15:34:18,214] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:34:18,215] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-24 15:34:18,218] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-24 15:34:18,219] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-24 15:34:18,220] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:34:18,220] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 15:34:18,220] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 15:34:18,286] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:34:18,446] network.Selector - Connection with azbuvqa1kafka02/172.18.48.46 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-24 15:34:18,465] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 15:34:18,465] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@c8925d7, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527190457887, sendTimeMs=0) with correlation id 0 due to node -2 being disconnected
main DEBUG [2018-05-24 15:34:18,466] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:34:18,592] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 15:34:18,668] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-05-24 15:34:18,693] clients.NetworkClient - Sending metadata request {topics=[CEmemberRun]} to node -1
main DEBUG [2018-05-24 15:34:18,773] clients.Metadata - Updated cluster metadata version 2 to Cluster(nodes = [azbuvqa1kafka02.ahmcert.com:9092 (id: 1 rack: null), azbuvqa1kafka01.ahmcert.com:9092 (id: 0 rack: null)], partitions = [Partition(topic = CEmemberRun, partition = 4, leader = 1, replicas = [0,1,], isr = [0,1,], Partition(topic = CEmemberRun, partition = 3, leader = 0, replicas = [0,1,], isr = [0,1,], Partition(topic = CEmemberRun, partition = 0, leader = 1, replicas = [0,1,], isr = [0,1,], Partition(topic = CEmemberRun, partition = 1, leader = 0, replicas = [0,1,], isr = [0,1,], Partition(topic = CEmemberRun, partition = 2, leader = 1, replicas = [0,1,], isr = [0,1,]])
main DEBUG [2018-05-24 15:34:18,774] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvqa1kafka01.ahmcert.com:9092 (id: 0 rack: null)
main DEBUG [2018-05-24 15:34:18,774] clients.NetworkClient - Initiating connection to node 0 at azbuvqa1kafka01.ahmcert.com:9092.
main DEBUG [2018-05-24 15:34:18,775] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:34:18,775] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvqa1kafka01.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:34:18,831] metrics.Metrics - Added sensor with name node-0.bytes-sent
main DEBUG [2018-05-24 15:34:18,831] metrics.Metrics - Added sensor with name node-0.bytes-received
main DEBUG [2018-05-24 15:34:18,831] metrics.Metrics - Added sensor with name node-0.latency
main DEBUG [2018-05-24 15:34:18,832] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:34:18,832] clients.NetworkClient - Completed connection to node 0
main DEBUG [2018-05-24 15:34:18,851] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:34:18,888] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:34:18,915] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 15:34:18,951] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:34:18,973] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-05-24 15:34:19,031] internals.AbstractCoordinator - Received group coordinator response ClientResponse(receivedTimeMs=1527190459030, disconnected=false, request=ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@4d83f728, request=RequestSend(header={api_key=10,api_version=0,correlation_id=2,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527190458774, sendTimeMs=1527190458974), responseBody={error_code=0,coordinator={node_id=0,host=azbuvqa1kafka01.ahmcert.com,port=9092}})
main  INFO [2018-05-24 15:34:19,031] internals.AbstractCoordinator - Discovered coordinator azbuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group ALPTDESAI7136TD.
main DEBUG [2018-05-24 15:34:19,031] clients.NetworkClient - Initiating connection to node 2147483647 at azbuvqa1kafka01.ahmcert.com:9092.
main DEBUG [2018-05-24 15:34:19,032] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:34:19,032] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvqa1kafka01.ahmcert.com;mechs=[GSSAPI]
main  INFO [2018-05-24 15:34:19,034] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD
main  INFO [2018-05-24 15:34:19,034] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD
main DEBUG [2018-05-24 15:34:19,039] internals.AbstractCoordinator - Sending JoinGroup ({group_id=ALPTDESAI7136TD,session_timeout=30000,member_id=,protocol_type=consumer,group_protocols=[{protocol_name=range,protocol_metadata=java.nio.HeapByteBuffer[pos=0 lim=23 cap=23]}]}) to coordinator azbuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null)
main DEBUG [2018-05-24 15:34:19,102] metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
main DEBUG [2018-05-24 15:34:19,103] metrics.Metrics - Added sensor with name node-2147483647.bytes-received
main DEBUG [2018-05-24 15:34:19,104] metrics.Metrics - Added sensor with name node-2147483647.latency
main DEBUG [2018-05-24 15:34:19,105] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:34:19,105] clients.NetworkClient - Completed connection to node 2147483647
main DEBUG [2018-05-24 15:34:19,174] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:34:19,183] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 15:34:19,255] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-05-24 15:34:19,329] internals.AbstractCoordinator - Received successful join group response for group ALPTDESAI7136TD: {error_code=0,generation_id=1,group_protocol=range,leader_id=consumer-1-437a5b72-3466-4fab-aca2-33d0d1141baf,member_id=consumer-1-437a5b72-3466-4fab-aca2-33d0d1141baf,members=[{member_id=consumer-1-437a5b72-3466-4fab-aca2-33d0d1141baf,member_metadata=java.nio.HeapByteBuffer[pos=0 lim=23 cap=23]}]}
main DEBUG [2018-05-24 15:34:19,330] internals.ConsumerCoordinator - Performing assignment for group ALPTDESAI7136TD using strategy range with subscriptions {consumer-1-437a5b72-3466-4fab-aca2-33d0d1141baf=Subscription(topics=[CEmemberRun])}
main DEBUG [2018-05-24 15:34:19,330] internals.ConsumerCoordinator - Finished assignment for group ALPTDESAI7136TD: {consumer-1-437a5b72-3466-4fab-aca2-33d0d1141baf=Assignment(partitions=[CEmemberRun-0, CEmemberRun-1, CEmemberRun-2, CEmemberRun-3, CEmemberRun-4])}
main DEBUG [2018-05-24 15:34:19,331] internals.AbstractCoordinator - Sending leader SyncGroup for group ALPTDESAI7136TD to coordinator azbuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null): {group_id=ALPTDESAI7136TD,generation_id=1,member_id=consumer-1-437a5b72-3466-4fab-aca2-33d0d1141baf,group_assignment=[{member_id=consumer-1-437a5b72-3466-4fab-aca2-33d0d1141baf,member_assignment=java.nio.HeapByteBuffer[pos=0 lim=47 cap=47]}]}
main  INFO [2018-05-24 15:34:19,404] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD with generation 1
main  INFO [2018-05-24 15:34:19,405] internals.ConsumerCoordinator - Setting newly assigned partitions [CEmemberRun-1, CEmemberRun-2, CEmemberRun-4, CEmemberRun-3, CEmemberRun-0] for group ALPTDESAI7136TD
main DEBUG [2018-05-24 15:34:19,405] internals.ConsumerCoordinator - Group ALPTDESAI7136TD fetching committed offsets for partitions: [CEmemberRun-1, CEmemberRun-2, CEmemberRun-4, CEmemberRun-3, CEmemberRun-0]
main DEBUG [2018-05-24 15:34:19,480] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CEmemberRun-1
main DEBUG [2018-05-24 15:34:19,480] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CEmemberRun-2
main DEBUG [2018-05-24 15:34:19,480] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CEmemberRun-4
main DEBUG [2018-05-24 15:34:19,480] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CEmemberRun-3
main DEBUG [2018-05-24 15:34:19,480] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CEmemberRun-0
main DEBUG [2018-05-24 15:34:19,480] internals.Fetcher - Resetting offset for partition CEmemberRun-1 to latest offset.
main DEBUG [2018-05-24 15:34:19,540] internals.Fetcher - Fetched offset 9031 for partition CEmemberRun-1
main DEBUG [2018-05-24 15:34:19,540] internals.Fetcher - Resetting offset for partition CEmemberRun-2 to latest offset.
main DEBUG [2018-05-24 15:34:19,541] clients.NetworkClient - Initiating connection to node 1 at azbuvqa1kafka02.ahmcert.com:9092.
main DEBUG [2018-05-24 15:34:19,598] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:34:19,599] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvqa1kafka02.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:34:19,667] metrics.Metrics - Added sensor with name node-1.bytes-sent
main DEBUG [2018-05-24 15:34:19,668] metrics.Metrics - Added sensor with name node-1.bytes-received
main DEBUG [2018-05-24 15:34:19,668] metrics.Metrics - Added sensor with name node-1.latency
main DEBUG [2018-05-24 15:34:19,669] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:34:19,669] clients.NetworkClient - Completed connection to node 1
main DEBUG [2018-05-24 15:34:19,738] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:34:19,888] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 15:34:19,959] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-05-24 15:34:20,031] internals.Fetcher - Fetched offset 9047 for partition CEmemberRun-2
main DEBUG [2018-05-24 15:34:20,031] internals.Fetcher - Resetting offset for partition CEmemberRun-4 to latest offset.
main DEBUG [2018-05-24 15:34:20,101] internals.Fetcher - Fetched offset 9049 for partition CEmemberRun-4
main DEBUG [2018-05-24 15:34:20,101] internals.Fetcher - Resetting offset for partition CEmemberRun-3 to latest offset.
main DEBUG [2018-05-24 15:34:20,125] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9031 for partition CEmemberRun-1
main DEBUG [2018-05-24 15:34:20,125] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9047 for partition CEmemberRun-2
main DEBUG [2018-05-24 15:34:20,159] internals.Fetcher - Fetched offset 8979 for partition CEmemberRun-3
main DEBUG [2018-05-24 15:34:20,159] internals.Fetcher - Resetting offset for partition CEmemberRun-0 to latest offset.
main DEBUG [2018-05-24 15:34:20,231] internals.Fetcher - Fetched offset 8888 for partition CEmemberRun-0
main DEBUG [2018-05-24 15:34:20,475] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9031 for partition CEmemberRun-1
main DEBUG [2018-05-24 15:34:20,476] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9047 for partition CEmemberRun-2
main DEBUG [2018-05-24 15:34:20,476] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9049 for partition CEmemberRun-4
main DEBUG [2018-05-24 15:34:20,476] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8979 for partition CEmemberRun-3
main DEBUG [2018-05-24 15:34:20,476] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8888 for partition CEmemberRun-0
main DEBUG [2018-05-24 15:34:20,804] metrics.Metrics - Added sensor with name topic.CEmemberRun.bytes-fetched
main DEBUG [2018-05-24 15:34:20,805] metrics.Metrics - Added sensor with name topic.CEmemberRun.records-fetched
main DEBUG [2018-05-24 15:34:21,121] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9031 for partition CEmemberRun-1
main DEBUG [2018-05-24 15:34:21,121] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9047 for partition CEmemberRun-2
main DEBUG [2018-05-24 15:34:21,121] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9049 for partition CEmemberRun-4
main DEBUG [2018-05-24 15:34:21,122] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8979 for partition CEmemberRun-3
main DEBUG [2018-05-24 15:34:21,122] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8888 for partition CEmemberRun-0
main DEBUG [2018-05-24 15:34:21,477] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9031 for partition CEmemberRun-1
main DEBUG [2018-05-24 15:34:21,477] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9047 for partition CEmemberRun-2
main DEBUG [2018-05-24 15:34:21,478] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9049 for partition CEmemberRun-4
main DEBUG [2018-05-24 15:34:21,478] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8979 for partition CEmemberRun-3
main DEBUG [2018-05-24 15:34:21,478] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8888 for partition CEmemberRun-0
main DEBUG [2018-05-24 15:34:22,122] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9031 for partition CEmemberRun-1
main DEBUG [2018-05-24 15:34:22,123] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9047 for partition CEmemberRun-2
main DEBUG [2018-05-24 15:34:22,123] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9049 for partition CEmemberRun-4
main DEBUG [2018-05-24 15:34:22,123] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8979 for partition CEmemberRun-3
main DEBUG [2018-05-24 15:34:22,123] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8888 for partition CEmemberRun-0
main DEBUG [2018-05-24 15:34:22,478] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9031 for partition CEmemberRun-1
main DEBUG [2018-05-24 15:34:22,478] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9047 for partition CEmemberRun-2
main DEBUG [2018-05-24 15:34:22,479] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9049 for partition CEmemberRun-4
main DEBUG [2018-05-24 15:34:22,479] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8979 for partition CEmemberRun-3
main DEBUG [2018-05-24 15:34:22,479] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8888 for partition CEmemberRun-0
main DEBUG [2018-05-24 15:34:22,482] internals.AbstractCoordinator - Received successful heartbeat response for group ALPTDESAI7136TD
main DEBUG [2018-05-24 15:34:23,122] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9031 for partition CEmemberRun-1
main DEBUG [2018-05-24 15:34:23,122] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9047 for partition CEmemberRun-2
main DEBUG [2018-05-24 15:34:23,122] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9049 for partition CEmemberRun-4
main DEBUG [2018-05-24 15:34:23,123] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8979 for partition CEmemberRun-3
main DEBUG [2018-05-24 15:34:23,123] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8888 for partition CEmemberRun-0
main DEBUG [2018-05-24 15:34:23,477] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9031 for partition CEmemberRun-1
main DEBUG [2018-05-24 15:34:23,477] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9047 for partition CEmemberRun-2
main DEBUG [2018-05-24 15:34:23,477] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9049 for partition CEmemberRun-4
main DEBUG [2018-05-24 15:34:23,478] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8979 for partition CEmemberRun-3
main DEBUG [2018-05-24 15:34:23,478] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8888 for partition CEmemberRun-0
main DEBUG [2018-05-24 15:34:24,124] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9031 for partition CEmemberRun-1
main DEBUG [2018-05-24 15:34:24,124] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9047 for partition CEmemberRun-2
main DEBUG [2018-05-24 15:34:24,124] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9049 for partition CEmemberRun-4
main DEBUG [2018-05-24 15:34:24,124] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8979 for partition CEmemberRun-3
main DEBUG [2018-05-24 15:34:24,124] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8888 for partition CEmemberRun-0
main DEBUG [2018-05-24 15:34:24,475] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9031 for partition CEmemberRun-1
main DEBUG [2018-05-24 15:34:24,475] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9047 for partition CEmemberRun-2
main DEBUG [2018-05-24 15:34:24,475] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 9049 for partition CEmemberRun-4
main DEBUG [2018-05-24 15:34:24,475] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8979 for partition CEmemberRun-3
main DEBUG [2018-05-24 15:34:24,475] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 8888 for partition CEmemberRun-0
main  INFO [2018-05-24 15:35:23,168] careengine.CEKafkaConsumer - Topic name is: CEmemberRun
main  INFO [2018-05-24 15:35:23,200] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01:9092, azbuvuatkafka02:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:35:23,201] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-24 15:35:23,350] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka01:9092 (id: -1 rack: null), azbuvuatkafka02:9092 (id: -2 rack: null)], partitions = [])
main  INFO [2018-05-24 15:35:23,825] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-24 15:35:23,825] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:35:23,826] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-24 15:35:23,827] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:35:23,827] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T15:35:23.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:35:23,827] kerberos.KerberosLogin - TGT expires: 2018-05-25T15:35:23.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:35:23,828] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T10:50:24.944-0400
main DEBUG [2018-05-24 15:35:23,840] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-24 15:35:23,841] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-24 15:35:23,841] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-24 15:35:23,841] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-24 15:35:23,843] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-24 15:35:23,843] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-24 15:35:23,844] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-24 15:35:23,854] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01:9092, azbuvuatkafka02:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:35:23,869] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-24 15:35:23,869] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-24 15:35:23,870] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-24 15:35:23,872] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-24 15:35:23,879] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-24 15:35:23,880] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-24 15:35:23,880] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-24 15:35:23,880] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-24 15:35:23,880] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-24 15:35:23,883] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 15:35:23,884] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-24 15:35:23,884] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-24 15:35:23,884] consumer.KafkaConsumer - Subscribed to topic(s): CEmemberRun
main DEBUG [2018-05-24 15:35:23,885] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka01:9092 (id: -1 rack: null)
main DEBUG [2018-05-24 15:35:23,902] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01:9092.
main DEBUG [2018-05-24 15:35:23,907] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:35:23,908] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:35:23,959] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-24 15:35:23,960] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-24 15:35:23,960] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-24 15:35:23,972] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:35:23,973] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 15:35:24,030] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:35:24,154] network.Selector - Connection with azbuvuatkafka01/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-24 15:35:24,163] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 15:35:24,164] internals.ConsumerNetworkClient - Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@458e8b00, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527190523899, sendTimeMs=0) with correlation id 0 due to node -1 being disconnected
main DEBUG [2018-05-24 15:35:24,164] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 15:35:24,165] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02:9092.
main DEBUG [2018-05-24 15:35:24,165] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:35:24,165] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:35:24,367] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 15:35:24,367] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01:9092.
main DEBUG [2018-05-24 15:35:24,368] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:35:24,368] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:35:24,438] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:35:24,438] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 15:35:24,507] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:35:24,629] network.Selector - Connection with azbuvuatkafka01/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-24 15:35:24,639] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 15:35:24,739] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 15:35:24,739] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01:9092.
main DEBUG [2018-05-24 15:35:24,740] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:35:24,741] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:35:24,796] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:35:24,796] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 15:35:24,852] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:35:25,001] network.Selector - Connection with azbuvuatkafka01/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-24 15:35:25,007] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 15:35:25,008] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:35:25,113] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:35:25,213] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:35:25,213] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 15:35:25,214] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01:9092.
main DEBUG [2018-05-24 15:35:25,215] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:35:25,215] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:35:25,270] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:35:25,271] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 15:35:25,313] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:35:25,321] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-05-24 15:35:25,321] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-05-24 15:35:25,321] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-05-24 15:35:25,322] network.Selector - Connection with azbuvuatkafka02/172.18.49.42 disconnected
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.7.0_79]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739) ~[?:1.7.0_79]
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:51) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:73) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:309) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
main DEBUG [2018-05-24 15:35:25,322] clients.NetworkClient - Node -2 disconnected.
main DEBUG [2018-05-24 15:35:25,327] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:35:25,476] network.Selector - Connection with azbuvuatkafka01/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-24 15:35:25,481] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 15:35:25,481] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:35:25,481] clients.NetworkClient - Initialize connection to node -2 for sending metadata request
main DEBUG [2018-05-24 15:35:25,482] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02:9092.
main DEBUG [2018-05-24 15:35:25,482] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:35:25,482] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:35:25,581] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:35:25,681] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:35:25,781] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:35:25,784] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 15:35:25,784] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01:9092.
main DEBUG [2018-05-24 15:35:25,785] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:35:25,785] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:35:25,841] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:35:25,841] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 15:35:25,881] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:35:25,896] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:35:26,019] network.Selector - Connection with azbuvuatkafka01/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-24 15:35:26,022] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 15:35:26,022] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:35:26,122] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:35:26,122] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 15:35:26,122] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01:9092.
main DEBUG [2018-05-24 15:35:26,123] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:35:26,123] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:35:26,194] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:35:26,194] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 15:35:26,222] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:35:26,263] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:35:26,408] network.Selector - Connection with azbuvuatkafka01/172.18.49.41 disconnected
javax.security.sasl.SaslException: An error: (java.security.PrivilegedActionException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)]) occurred when evaluating SASL token received from the Kafka Broker. This may be caused by Java's being unable to resolve the Kafka Broker's hostname correctly. You may want to try to adding '-Dsun.net.spi.nameservice.provider.1=dns,sun' to your client's JVMFLAGS environment. Users must configure FQDN of kafka brokers when authenticating using SASL and `socketChannel.socket().getInetAddress().getHostName()` must match the hostname in `principal/hostname@realm` Kafka Client will go to AUTH_FAILED state.
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:293) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.sendSaslToken(SaslClientAuthenticator.java:210) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.authenticate(SaslClientAuthenticator.java:178) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:64) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:318) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:283) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at net.ahm.careengine.CEKafkaConsumer.main(CEKafkaConsumer.java:37) [classes/:?]
Caused by: javax.security.sasl.SaslException: GSS initiate failed
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:710) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:143) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:66) ~[?:1.7.0_79]
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:61) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:192) ~[?:1.7.0_79]
	at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:203) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:309) ~[?:1.7.0_79]
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:115) ~[?:1.7.0_79]
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:454) ~[?:1.7.0_79]
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:641) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.7.0_79]
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.7.0_79]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:275) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator$2.run(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_79]
	at javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_79]
	at org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.createSaslToken(SaslClientAuthenticator.java:273) ~[kafka-clients-0.10.0.1.jar:?]
	... 14 more
main DEBUG [2018-05-24 15:35:26,410] clients.NetworkClient - Node -1 disconnected.
main DEBUG [2018-05-24 15:35:26,410] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:35:26,510] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main  INFO [2018-05-24 15:36:24,990] careengine.CEKafkaConsumer - Topic name is: CEmemberRun
main  INFO [2018-05-24 15:36:25,017] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:36:25,018] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-24 15:36:25,179] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka01.ahmcert.com:9092 (id: -1 rack: null), azbuvuatkafka02.ahmcert.com:9092 (id: -2 rack: null)], partitions = [])
main  INFO [2018-05-24 15:36:25,658] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-24 15:36:25,659] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:36:25,660] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-24 15:36:25,661] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:36:25,661] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T15:36:25.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:36:25,661] kerberos.KerberosLogin - TGT expires: 2018-05-25T15:36:25.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:36:25,662] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T11:27:55.701-0400
main DEBUG [2018-05-24 15:36:25,677] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-24 15:36:25,678] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-24 15:36:25,679] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-24 15:36:25,679] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-24 15:36:25,680] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-24 15:36:25,681] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-24 15:36:25,681] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-24 15:36:25,691] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:36:25,703] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-24 15:36:25,703] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-24 15:36:25,703] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-24 15:36:25,706] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-24 15:36:25,712] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-24 15:36:25,713] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-24 15:36:25,713] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-24 15:36:25,713] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-24 15:36:25,713] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-24 15:36:25,716] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 15:36:25,716] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-24 15:36:25,716] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-24 15:36:25,717] consumer.KafkaConsumer - Subscribed to topic(s): CEmemberRun
main DEBUG [2018-05-24 15:36:25,717] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka01.ahmcert.com:9092 (id: -1 rack: null)
main DEBUG [2018-05-24 15:36:25,738] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.ahmcert.com:9092.
main DEBUG [2018-05-24 15:36:25,744] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:36:25,746] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:36:25,808] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-24 15:36:25,809] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-24 15:36:25,809] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-24 15:36:25,821] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:36:25,822] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 15:36:25,897] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:36:26,054] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 15:36:26,133] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-05-24 15:36:26,155] clients.NetworkClient - Sending metadata request {topics=[CEmemberRun]} to node -1
main  WARN [2018-05-24 15:36:26,235] clients.NetworkClient - Error while fetching metadata with correlation id 1 : {CEmemberRun=TOPIC_AUTHORIZATION_FAILED}
main  INFO [2018-05-24 15:46:41,686] careengine.CEKafkaConsumer - Topic name is: CETestTopic
main  INFO [2018-05-24 15:46:41,714] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:46:41,715] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-24 15:46:41,728] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka01.ahmcert.com:9092 (id: -1 rack: null), azbuvuatkafka02.ahmcert.com:9092 (id: -2 rack: null)], partitions = [])
main  INFO [2018-05-24 15:46:42,162] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-24 15:46:42,163] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:46:42,164] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-24 15:46:42,165] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:46:42,165] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T15:46:42.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:46:42,165] kerberos.KerberosLogin - TGT expires: 2018-05-25T15:46:42.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:46:42,165] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T11:21:20.794-0400
main DEBUG [2018-05-24 15:46:42,180] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-24 15:46:42,181] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-24 15:46:42,182] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-24 15:46:42,182] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-24 15:46:42,183] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-24 15:46:42,184] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-24 15:46:42,184] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-24 15:46:42,194] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:46:42,207] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-24 15:46:42,207] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-24 15:46:42,208] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-24 15:46:42,211] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-24 15:46:42,221] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-24 15:46:42,222] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-24 15:46:42,222] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-24 15:46:42,222] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-24 15:46:42,223] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-24 15:46:42,226] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 15:46:42,226] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-24 15:46:42,226] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-24 15:46:42,227] consumer.KafkaConsumer - Subscribed to topic(s): CETestTopic
main DEBUG [2018-05-24 15:46:42,227] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka01.ahmcert.com:9092 (id: -1 rack: null)
main DEBUG [2018-05-24 15:46:42,244] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.ahmcert.com:9092.
main DEBUG [2018-05-24 15:46:42,250] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:46:42,252] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:46:42,301] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-24 15:46:42,302] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-24 15:46:42,302] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-24 15:46:42,313] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:46:42,313] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 15:46:42,371] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:46:42,501] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 15:46:42,560] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-05-24 15:46:42,603] clients.NetworkClient - Sending metadata request {topics=[CETestTopic]} to node -1
main DEBUG [2018-05-24 15:46:42,671] clients.Metadata - Updated cluster metadata version 2 to Cluster(nodes = [azbuvuatkafka02.ahmcert.com:9092 (id: 1 rack: null), azbuvuatkafka01.ahmcert.com:9092 (id: 0 rack: null)], partitions = [Partition(topic = CETestTopic, partition = 3, leader = 0, replicas = [0,1,], isr = [0,1,], Partition(topic = CETestTopic, partition = 4, leader = 1, replicas = [0,1,], isr = [1,0,], Partition(topic = CETestTopic, partition = 5, leader = 0, replicas = [0,1,], isr = [0,1,], Partition(topic = CETestTopic, partition = 2, leader = 1, replicas = [0,1,], isr = [1,0,], Partition(topic = CETestTopic, partition = 1, leader = 0, replicas = [0,1,], isr = [0,1,], Partition(topic = CETestTopic, partition = 0, leader = 1, replicas = [0,1,], isr = [1,0,]])
main DEBUG [2018-05-24 15:46:42,672] internals.AbstractCoordinator - Received group coordinator response ClientResponse(receivedTimeMs=1527191202671, disconnected=false, request=ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@2c299063, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527191202241, sendTimeMs=1527191202603), responseBody={error_code=30,coordinator={node_id=-1,host=,port=-1}})
main  INFO [2018-05-24 15:51:50,695] careengine.CEKafkaConsumer - Topic name is: CETestTopic
main  INFO [2018-05-24 15:51:50,725] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-05-24 15:51:50,726] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-05-24 15:51:50,741] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azbuvuatkafka02.ahmcert.com:9092 (id: -2 rack: null), azbuvuatkafka01.ahmcert.com:9092 (id: -1 rack: null)], partitions = [])
main  INFO [2018-05-24 15:51:51,193] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-05-24 15:51:51,194] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:51:51,195] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-05-24 15:51:51,196] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:51:51,196] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T15:51:51.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:51:51,197] kerberos.KerberosLogin - TGT expires: 2018-05-25T15:51:51.000-0400
main DEBUG [2018-05-24 15:51:51,207] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-05-24 15:51:51,208] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-05-24 15:51:51,208] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-05-24 15:51:51,208] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-05-24 15:51:51,209] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-05-24 15:51:51,210] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-05-24 15:51:51,210] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-05-24 15:51:51,217] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

kafka-kerberos-refresh-thread  INFO [2018-05-24 15:51:51,224] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T11:20:49.142-0400
main DEBUG [2018-05-24 15:51:51,231] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-05-24 15:51:51,231] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-05-24 15:51:51,232] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-05-24 15:51:51,235] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-05-24 15:51:51,242] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-05-24 15:51:51,243] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-05-24 15:51:51,243] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-05-24 15:51:51,243] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-05-24 15:51:51,244] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-05-24 15:51:51,246] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 15:51:51,246] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-05-24 15:51:51,247] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-05-24 15:51:51,247] consumer.KafkaConsumer - Subscribed to topic(s): CETestTopic
main DEBUG [2018-05-24 15:51:51,247] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka02.ahmcert.com:9092 (id: -2 rack: null)
main DEBUG [2018-05-24 15:51:51,267] clients.NetworkClient - Initiating connection to node -2 at azbuvuatkafka02.ahmcert.com:9092.
main DEBUG [2018-05-24 15:51:51,273] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:51:51,274] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:51:51,287] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-05-24 15:51:51,287] clients.NetworkClient - Initiating connection to node -1 at azbuvuatkafka01.ahmcert.com:9092.
main DEBUG [2018-05-24 15:51:51,288] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:51:51,288] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:51:51,324] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-05-24 15:51:51,324] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-05-24 15:51:51,325] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-05-24 15:51:51,334] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:51:51,334] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-05-24 15:51:51,344] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-05-24 15:51:51,344] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-05-24 15:51:51,345] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-05-24 15:51:51,345] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:51:51,345] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-05-24 15:51:51,392] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:51:51,528] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 15:51:51,528] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:51:51,679] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 15:51:51,682] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-05-24 15:51:51,738] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-05-24 15:51:51,781] clients.NetworkClient - Sending metadata request {topics=[CETestTopic]} to node -2
main DEBUG [2018-05-24 15:51:51,858] clients.Metadata - Updated cluster metadata version 2 to Cluster(nodes = [azbuvuatkafka02.ahmcert.com:9092 (id: 1 rack: null), azbuvuatkafka01.ahmcert.com:9092 (id: 0 rack: null)], partitions = [Partition(topic = CETestTopic, partition = 3, leader = 0, replicas = [0,1,], isr = [0,1,], Partition(topic = CETestTopic, partition = 4, leader = 1, replicas = [0,1,], isr = [1,0,], Partition(topic = CETestTopic, partition = 5, leader = 0, replicas = [0,1,], isr = [0,1,], Partition(topic = CETestTopic, partition = 2, leader = 1, replicas = [0,1,], isr = [1,0,], Partition(topic = CETestTopic, partition = 1, leader = 0, replicas = [0,1,], isr = [0,1,], Partition(topic = CETestTopic, partition = 0, leader = 1, replicas = [0,1,], isr = [1,0,]])
main DEBUG [2018-05-24 15:51:51,927] internals.AbstractCoordinator - Received group coordinator response ClientResponse(receivedTimeMs=1527191511925, disconnected=false, request=ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@4fdab00b, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527191511264, sendTimeMs=1527191511782), responseBody={error_code=15,coordinator={node_id=-1,host=,port=-1}})
main DEBUG [2018-05-24 15:51:51,950] clients.NetworkClient - Initialize connection to node 1 for sending metadata request
main DEBUG [2018-05-24 15:51:51,950] clients.NetworkClient - Initiating connection to node 1 at azbuvuatkafka02.ahmcert.com:9092.
main DEBUG [2018-05-24 15:51:51,951] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:51:51,952] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka02.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:51:52,022] metrics.Metrics - Added sensor with name node-1.bytes-sent
main DEBUG [2018-05-24 15:51:52,023] metrics.Metrics - Added sensor with name node-1.bytes-received
main DEBUG [2018-05-24 15:51:52,023] metrics.Metrics - Added sensor with name node-1.latency
main DEBUG [2018-05-24 15:51:52,023] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:51:52,024] clients.NetworkClient - Completed connection to node 1
main DEBUG [2018-05-24 15:51:52,095] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:51:52,097] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 15:51:52,169] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-05-24 15:51:52,234] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:51:52,254] clients.NetworkClient - Sending metadata request {topics=[CETestTopic]} to node 1
main DEBUG [2018-05-24 15:51:52,330] clients.Metadata - Updated cluster metadata version 3 to Cluster(nodes = [azbuvuatkafka02.ahmcert.com:9092 (id: 1 rack: null), azbuvuatkafka01.ahmcert.com:9092 (id: 0 rack: null)], partitions = [Partition(topic = CETestTopic, partition = 3, leader = 0, replicas = [0,1,], isr = [0,1,], Partition(topic = CETestTopic, partition = 4, leader = 1, replicas = [0,1,], isr = [1,0,], Partition(topic = CETestTopic, partition = 5, leader = 0, replicas = [0,1,], isr = [0,1,], Partition(topic = CETestTopic, partition = 2, leader = 1, replicas = [0,1,], isr = [1,0,], Partition(topic = CETestTopic, partition = 1, leader = 0, replicas = [0,1,], isr = [0,1,], Partition(topic = CETestTopic, partition = 0, leader = 1, replicas = [0,1,], isr = [1,0,]])
main DEBUG [2018-05-24 15:51:52,330] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka02.ahmcert.com:9092 (id: 1 rack: null)
main DEBUG [2018-05-24 15:51:52,334] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:51:52,411] internals.AbstractCoordinator - Received group coordinator response ClientResponse(receivedTimeMs=1527191512410, disconnected=false, request=ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@28103d8, request=RequestSend(header={api_key=10,api_version=0,correlation_id=3,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527191512330, sendTimeMs=1527191512331), responseBody={error_code=15,coordinator={node_id=-1,host=,port=-1}})
main DEBUG [2018-05-24 15:51:52,427] clients.NetworkClient - Sending metadata request {topics=[CETestTopic]} to node 1
main DEBUG [2018-05-24 15:51:52,434] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:51:52,501] clients.Metadata - Updated cluster metadata version 4 to Cluster(nodes = [azbuvuatkafka02.ahmcert.com:9092 (id: 1 rack: null), azbuvuatkafka01.ahmcert.com:9092 (id: 0 rack: null)], partitions = [Partition(topic = CETestTopic, partition = 3, leader = 0, replicas = [0,1,], isr = [0,1,], Partition(topic = CETestTopic, partition = 4, leader = 1, replicas = [0,1,], isr = [1,0,], Partition(topic = CETestTopic, partition = 5, leader = 0, replicas = [0,1,], isr = [0,1,], Partition(topic = CETestTopic, partition = 2, leader = 1, replicas = [0,1,], isr = [1,0,], Partition(topic = CETestTopic, partition = 1, leader = 0, replicas = [0,1,], isr = [0,1,], Partition(topic = CETestTopic, partition = 0, leader = 1, replicas = [0,1,], isr = [1,0,]])
main DEBUG [2018-05-24 15:51:52,501] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azbuvuatkafka02.ahmcert.com:9092 (id: 1 rack: null)
main DEBUG [2018-05-24 15:51:52,534] internals.ConsumerCoordinator - Cannot auto-commit offsets for group ALPTDESAI7136TD since the coordinator is unknown
main DEBUG [2018-05-24 15:51:52,576] internals.AbstractCoordinator - Received group coordinator response ClientResponse(receivedTimeMs=1527191512576, disconnected=false, request=ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@64235b30, request=RequestSend(header={api_key=10,api_version=0,correlation_id=5,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1527191512501, sendTimeMs=1527191512502), responseBody={error_code=0,coordinator={node_id=0,host=azbuvuatkafka01.ahmcert.com,port=9092}})
main  INFO [2018-05-24 15:51:52,577] internals.AbstractCoordinator - Discovered coordinator azbuvuatkafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group ALPTDESAI7136TD.
main DEBUG [2018-05-24 15:51:52,577] clients.NetworkClient - Initiating connection to node 2147483647 at azbuvuatkafka01.ahmcert.com:9092.
main DEBUG [2018-05-24 15:51:52,578] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:51:52,578] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.ahmcert.com;mechs=[GSSAPI]
main  INFO [2018-05-24 15:51:52,581] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD
main  INFO [2018-05-24 15:51:52,582] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD
main DEBUG [2018-05-24 15:51:52,588] internals.AbstractCoordinator - Sending JoinGroup ({group_id=ALPTDESAI7136TD,session_timeout=30000,member_id=,protocol_type=consumer,group_protocols=[{protocol_name=range,protocol_metadata=java.nio.HeapByteBuffer[pos=0 lim=23 cap=23]}]}) to coordinator azbuvuatkafka01.ahmcert.com:9092 (id: 2147483647 rack: null)
main DEBUG [2018-05-24 15:51:52,649] metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
main DEBUG [2018-05-24 15:51:52,650] metrics.Metrics - Added sensor with name node-2147483647.bytes-received
main DEBUG [2018-05-24 15:51:52,650] metrics.Metrics - Added sensor with name node-2147483647.latency
main DEBUG [2018-05-24 15:51:52,651] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:51:52,651] clients.NetworkClient - Completed connection to node 2147483647
main DEBUG [2018-05-24 15:51:52,721] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:51:52,723] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 15:51:52,796] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-05-24 15:51:52,880] internals.AbstractCoordinator - Received successful join group response for group ALPTDESAI7136TD: {error_code=0,generation_id=1,group_protocol=range,leader_id=consumer-1-809d32e5-e3b3-426b-9f80-1e04c462799e,member_id=consumer-1-809d32e5-e3b3-426b-9f80-1e04c462799e,members=[{member_id=consumer-1-809d32e5-e3b3-426b-9f80-1e04c462799e,member_metadata=java.nio.HeapByteBuffer[pos=0 lim=23 cap=23]}]}
main DEBUG [2018-05-24 15:51:52,881] internals.ConsumerCoordinator - Performing assignment for group ALPTDESAI7136TD using strategy range with subscriptions {consumer-1-809d32e5-e3b3-426b-9f80-1e04c462799e=Subscription(topics=[CETestTopic])}
main DEBUG [2018-05-24 15:51:52,884] internals.ConsumerCoordinator - Finished assignment for group ALPTDESAI7136TD: {consumer-1-809d32e5-e3b3-426b-9f80-1e04c462799e=Assignment(partitions=[CETestTopic-0, CETestTopic-1, CETestTopic-2, CETestTopic-3, CETestTopic-4, CETestTopic-5])}
main DEBUG [2018-05-24 15:51:52,886] internals.AbstractCoordinator - Sending leader SyncGroup for group ALPTDESAI7136TD to coordinator azbuvuatkafka01.ahmcert.com:9092 (id: 2147483647 rack: null): {group_id=ALPTDESAI7136TD,generation_id=1,member_id=consumer-1-809d32e5-e3b3-426b-9f80-1e04c462799e,group_assignment=[{member_id=consumer-1-809d32e5-e3b3-426b-9f80-1e04c462799e,member_assignment=java.nio.HeapByteBuffer[pos=0 lim=51 cap=51]}]}
main  INFO [2018-05-24 15:51:53,016] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD with generation 1
main  INFO [2018-05-24 15:51:53,018] internals.ConsumerCoordinator - Setting newly assigned partitions [CETestTopic-5, CETestTopic-2, CETestTopic-1, CETestTopic-0, CETestTopic-3, CETestTopic-4] for group ALPTDESAI7136TD
main DEBUG [2018-05-24 15:51:53,018] internals.ConsumerCoordinator - Group ALPTDESAI7136TD fetching committed offsets for partitions: [CETestTopic-5, CETestTopic-2, CETestTopic-1, CETestTopic-0, CETestTopic-3, CETestTopic-4]
main DEBUG [2018-05-24 15:51:53,096] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:53,096] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:53,096] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:53,097] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CETestTopic-0
main DEBUG [2018-05-24 15:51:53,097] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CETestTopic-3
main DEBUG [2018-05-24 15:51:53,097] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CETestTopic-4
main DEBUG [2018-05-24 15:51:53,097] internals.Fetcher - Resetting offset for partition CETestTopic-5 to latest offset.
main DEBUG [2018-05-24 15:51:53,099] clients.NetworkClient - Initiating connection to node 0 at azbuvuatkafka01.ahmcert.com:9092.
main DEBUG [2018-05-24 15:51:53,100] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-05-24 15:51:53,100] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azbuvuatkafka01.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-05-24 15:51:53,169] metrics.Metrics - Added sensor with name node-0.bytes-sent
main DEBUG [2018-05-24 15:51:53,180] metrics.Metrics - Added sensor with name node-0.bytes-received
main DEBUG [2018-05-24 15:51:53,180] metrics.Metrics - Added sensor with name node-0.latency
main DEBUG [2018-05-24 15:51:53,181] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-05-24 15:51:53,181] clients.NetworkClient - Completed connection to node 0
main DEBUG [2018-05-24 15:51:53,255] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-05-24 15:51:53,258] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-05-24 15:51:53,330] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-05-24 15:51:53,410] internals.Fetcher - Fetched offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:53,410] internals.Fetcher - Resetting offset for partition CETestTopic-2 to latest offset.
main DEBUG [2018-05-24 15:51:53,492] internals.Fetcher - Fetched offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:53,492] internals.Fetcher - Resetting offset for partition CETestTopic-1 to latest offset.
main DEBUG [2018-05-24 15:51:53,565] internals.Fetcher - Fetched offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:53,565] internals.Fetcher - Resetting offset for partition CETestTopic-0 to latest offset.
main DEBUG [2018-05-24 15:51:53,641] internals.Fetcher - Fetched offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:51:53,642] internals.Fetcher - Resetting offset for partition CETestTopic-3 to latest offset.
main DEBUG [2018-05-24 15:51:53,714] internals.Fetcher - Fetched offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:51:53,714] internals.Fetcher - Resetting offset for partition CETestTopic-4 to latest offset.
main DEBUG [2018-05-24 15:51:53,725] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:53,725] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:53,726] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:53,789] internals.Fetcher - Fetched offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:51:54,095] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:54,095] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:54,095] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:54,095] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:51:54,095] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:51:54,096] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:51:54,374] metrics.Metrics - Added sensor with name topic.CETestTopic.bytes-fetched
main DEBUG [2018-05-24 15:51:54,375] metrics.Metrics - Added sensor with name topic.CETestTopic.records-fetched
main DEBUG [2018-05-24 15:51:54,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:54,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:54,714] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:54,714] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:51:54,714] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:51:54,714] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:51:55,095] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:55,095] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:55,095] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:55,095] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:51:55,096] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:51:55,096] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:51:55,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:55,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:55,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:55,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:51:55,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:51:55,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:51:56,092] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:56,092] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:56,093] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:56,093] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:51:56,093] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:51:56,093] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:51:56,094] internals.AbstractCoordinator - Received successful heartbeat response for group ALPTDESAI7136TD
main DEBUG [2018-05-24 15:51:56,711] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:56,711] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:56,711] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:56,711] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:51:56,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:51:56,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:51:57,097] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:57,098] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:57,098] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:57,098] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:51:57,098] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:51:57,099] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:51:57,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:57,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:57,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:57,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:51:57,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:51:57,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:51:58,097] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:58,097] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:58,098] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:58,098] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:51:58,098] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:51:58,098] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:51:58,711] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:58,711] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:58,711] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:58,711] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:51:58,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:51:58,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:51:59,093] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:59,093] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:59,093] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:59,093] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:51:59,093] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:51:59,094] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:51:59,094] internals.AbstractCoordinator - Received successful heartbeat response for group ALPTDESAI7136TD
main DEBUG [2018-05-24 15:51:59,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:51:59,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:51:59,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:51:59,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:51:59,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:51:59,713] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:52:00,095] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:52:00,095] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:52:00,095] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:52:00,095] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:52:00,096] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:52:00,096] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:52:00,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:52:00,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:52:00,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:52:00,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:52:00,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:52:00,712] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main DEBUG [2018-05-24 15:52:01,093] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-5
main DEBUG [2018-05-24 15:52:01,093] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-2
main DEBUG [2018-05-24 15:52:01,094] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-1
main DEBUG [2018-05-24 15:52:01,094] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-0
main DEBUG [2018-05-24 15:52:01,094] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-3
main DEBUG [2018-05-24 15:52:01,094] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CETestTopic-4
main  INFO [2018-05-24 15:52:19,072] careengine.CEKafkaConsumer - Topic name is: CETestTopic
main  INFO [2018-05-24 15:52:19,101] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-24 15:52:19,529] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:52:19,531] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:52:19,531] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T15:52:19.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:52:19,531] kerberos.KerberosLogin - TGT expires: 2018-05-25T15:52:19.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:52:19,532] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T11:41:05.355-0400
main  INFO [2018-05-24 15:52:19,559] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-24 15:52:19,586] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 15:52:19,586] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-05-24 15:52:20,224] internals.AbstractCoordinator - Discovered coordinator azbuvuatkafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group ALPTDESAI7136TD.
main  INFO [2018-05-24 15:52:20,227] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD
main  INFO [2018-05-24 15:52:20,227] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD
main  INFO [2018-05-24 15:52:31,145] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD with generation 2
main  INFO [2018-05-24 15:52:31,147] internals.ConsumerCoordinator - Setting newly assigned partitions [CETestTopic-5, CETestTopic-2, CETestTopic-1, CETestTopic-0, CETestTopic-3, CETestTopic-4] for group ALPTDESAI7136TD
main  INFO [2018-05-24 15:54:28,430] careengine.CEKafkaConsumer - Topic name is: CETestTopic
main  INFO [2018-05-24 15:54:28,478] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-24 15:54:28,945] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:54:28,947] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:54:28,948] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T15:54:28.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:54:28,949] kerberos.KerberosLogin - TGT expires: 2018-05-25T15:54:28.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:54:28,949] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T11:56:18.775-0400
main  INFO [2018-05-24 15:54:28,979] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-24 15:54:29,013] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 15:54:29,013] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-05-24 15:54:29,489] internals.AbstractCoordinator - Discovered coordinator azbuvuatkafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group ALPTDESAI7136TD.
main  INFO [2018-05-24 15:54:29,491] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD
main  INFO [2018-05-24 15:54:29,492] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD
main  INFO [2018-05-24 15:54:29,783] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD with generation 1
main  INFO [2018-05-24 15:54:29,785] internals.ConsumerCoordinator - Setting newly assigned partitions [CETestTopic-5, CETestTopic-2, CETestTopic-1, CETestTopic-0, CETestTopic-3, CETestTopic-4] for group ALPTDESAI7136TD
main  INFO [2018-05-24 15:54:40,465] careengine.CEKafkaProducer - Topic name is: CETestTopic
main  INFO [2018-05-24 15:54:40,496] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2018-05-24 15:54:40,917] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:54:40,918] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:54:40,919] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T15:54:40.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:54:40,919] kerberos.KerberosLogin - TGT expires: 2018-05-25T15:54:40.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 15:54:40,920] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T11:29:20.519-0400
main  INFO [2018-05-24 15:54:40,944] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2018-05-24 15:54:40,949] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 15:54:40,949] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-05-24 15:54:48,632] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2018-05-24 15:54:48,634] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2018-05-24 15:56:55,521] internals.AbstractCoordinator - Marking the coordinator azbuvuatkafka01.ahmcert.com:9092 (id: 2147483647 rack: null) dead for group ALPTDESAI7136TD
main  INFO [2018-05-24 15:56:55,938] internals.AbstractCoordinator - Discovered coordinator azbuvuatkafka02.ahmcert.com:9092 (id: 2147483646 rack: null) for group ALPTDESAI7136TD.
main  INFO [2018-05-24 15:57:19,779] internals.AbstractCoordinator - Marking the coordinator azbuvuatkafka02.ahmcert.com:9092 (id: 2147483646 rack: null) dead for group ALPTDESAI7136TD
main  INFO [2018-05-24 16:25:25,858] careengine.CEKafkaConsumer - Topic name is: CETestTopic
main  INFO [2018-05-24 16:25:25,887] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-24 16:25:26,303] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:25:26,305] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:25:26,305] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T16:25:26.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:25:26,306] kerberos.KerberosLogin - TGT expires: 2018-05-25T16:25:26.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:25:26,306] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T11:42:40.299-0400
main  INFO [2018-05-24 16:25:26,333] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-24 16:25:26,363] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 16:25:26,363] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  WARN [2018-05-24 16:25:27,029] clients.NetworkClient - Error while fetching metadata with correlation id 1 : {CETestTopic=TOPIC_AUTHORIZATION_FAILED}
main  INFO [2018-05-24 16:36:12,140] careengine.CEKafkaConsumer - Topic name is: CEmemberRun
main  INFO [2018-05-24 16:36:12,168] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-24 16:36:12,644] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:36:12,646] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:36:12,647] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T16:36:12.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:36:12,647] kerberos.KerberosLogin - TGT expires: 2018-05-25T16:36:12.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:36:12,647] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T12:41:42.127-0400
main  INFO [2018-05-24 16:36:12,673] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-24 16:36:12,700] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 16:36:12,700] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-05-24 16:36:14,192] internals.AbstractCoordinator - Discovered coordinator azbuvuatkafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group ALPTDESAI7136TD.
main  INFO [2018-05-24 16:36:14,193] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD
main  INFO [2018-05-24 16:36:14,194] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD
main  INFO [2018-05-24 16:36:14,626] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD with generation 1
main  INFO [2018-05-24 16:36:14,627] internals.ConsumerCoordinator - Setting newly assigned partitions [CEmemberRun-1, CEmemberRun-2, CEmemberRun-5, CEmemberRun-4, CEmemberRun-3, CEmemberRun-0] for group ALPTDESAI7136TD
main  INFO [2018-05-24 16:36:20,621] careengine.CEKafkaProducer - Topic name is: CEmemberRun
main  INFO [2018-05-24 16:36:20,655] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2018-05-24 16:36:21,106] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:36:21,108] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:36:21,109] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T16:36:20.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:36:21,109] kerberos.KerberosLogin - TGT expires: 2018-05-25T16:36:20.000-0400
main  INFO [2018-05-24 16:36:21,127] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2018-05-24 16:36:21,130] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 16:36:21,130] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:36:21,133] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T12:04:35.581-0400
main  INFO [2018-05-24 16:36:28,673] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2018-05-24 16:36:28,680] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2018-05-24 16:38:03,626] careengine.CEKafkaConsumer - Topic name is: CEmemberRun
main  INFO [2018-05-24 16:38:03,654] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-24 16:38:04,253] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:38:04,255] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:38:04,256] kerberos.KerberosLogin - TGT valid starting at: 2018-05-24T16:38:04.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:38:04,256] kerberos.KerberosLogin - TGT expires: 2018-05-25T16:38:04.000-0400
kafka-kerberos-refresh-thread  INFO [2018-05-24 16:38:04,256] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-05-25T12:24:29.353-0400
main  INFO [2018-05-24 16:38:04,280] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvuatkafka01.ahmcert.com:9092, azbuvuatkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-05-24 16:38:04,308] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-05-24 16:38:04,308] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-05-24 16:38:04,808] internals.AbstractCoordinator - Discovered coordinator azbuvuatkafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group ALPTDESAI7136TD.
main  INFO [2018-05-24 16:38:04,814] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD
main  INFO [2018-05-24 16:38:04,814] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD
main  INFO [2018-05-24 16:38:05,110] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD with generation 1
main  INFO [2018-05-24 16:38:05,113] internals.ConsumerCoordinator - Setting newly assigned partitions [CEmemberRun-1, CEmemberRun-2, CEmemberRun-5, CEmemberRun-4, CEmemberRun-3, CEmemberRun-0] for group ALPTDESAI7136TD
main  INFO [2018-09-20 14:44:25,836] careengine.CEKafkaConsumer - Topic name is: CEmemberRun
main  INFO [2018-09-20 14:44:25,866] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-09-20 14:44:25,876] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-09-20 14:44:25,877] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azauvprdkafka02.ahmcert.com:9092 (id: -2 rack: null), azauvprdkafka01.ahmcert.com:9092 (id: -1 rack: null)], partitions = [])
main  INFO [2018-09-20 14:44:26,866] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-09-20 14:44:26,866] kerberos.KerberosLogin - It is a Kerberos ticket
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:44:26,866] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread DEBUG [2018-09-20 14:44:26,866] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:44:26,866] kerberos.KerberosLogin - TGT valid starting at: 2018-09-20T14:44:26.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:44:26,866] kerberos.KerberosLogin - TGT expires: 2018-09-21T14:44:26.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:44:26,866] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-21T10:01:04.491-0400
main DEBUG [2018-09-20 14:44:26,867] metrics.Metrics - Added sensor with name connections-closed:
main DEBUG [2018-09-20 14:44:26,867] metrics.Metrics - Added sensor with name connections-created:
main DEBUG [2018-09-20 14:44:26,867] metrics.Metrics - Added sensor with name bytes-sent-received:
main DEBUG [2018-09-20 14:44:26,867] metrics.Metrics - Added sensor with name bytes-sent:
main DEBUG [2018-09-20 14:44:26,867] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-09-20 14:44:26,867] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-09-20 14:44:26,867] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-09-20 14:44:26,874] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-09-20 14:44:26,891] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-09-20 14:44:26,892] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-09-20 14:44:26,892] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-09-20 14:44:26,896] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-09-20 14:44:26,906] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-09-20 14:44:26,907] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-09-20 14:44:26,907] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-09-20 14:44:26,908] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-09-20 14:44:26,908] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-09-20 14:44:26,911] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-20 14:44:26,911] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-09-20 14:44:26,912] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-09-20 14:44:26,913] consumer.KafkaConsumer - Subscribed to topic(s): CEmemberRun
main DEBUG [2018-09-20 14:44:26,913] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azauvprdkafka02.ahmcert.com:9092 (id: -2 rack: null)
main DEBUG [2018-09-20 14:44:26,936] clients.NetworkClient - Initiating connection to node -2 at azauvprdkafka02.ahmcert.com:9092.
main DEBUG [2018-09-20 14:44:26,947] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-09-20 14:44:26,950] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azauvprdkafka02.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-09-20 14:44:27,077] clients.NetworkClient - Initialize connection to node -1 for sending metadata request
main DEBUG [2018-09-20 14:44:27,077] clients.NetworkClient - Initiating connection to node -1 at azauvprdkafka01.ahmcert.com:9092.
main DEBUG [2018-09-20 14:44:27,079] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-09-20 14:44:27,079] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azauvprdkafka01.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-09-20 14:44:27,189] metrics.Metrics - Added sensor with name node--1.bytes-sent
main DEBUG [2018-09-20 14:44:27,190] metrics.Metrics - Added sensor with name node--1.bytes-received
main DEBUG [2018-09-20 14:44:27,191] metrics.Metrics - Added sensor with name node--1.latency
main DEBUG [2018-09-20 14:44:27,203] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-09-20 14:44:27,203] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-09-20 14:44:27,204] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-09-20 14:44:27,204] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-09-20 14:44:27,204] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-09-20 14:44:27,205] clients.NetworkClient - Completed connection to node -1
main DEBUG [2018-09-20 14:44:27,205] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-09-20 14:44:27,251] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-09-20 14:44:27,406] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-09-20 14:44:27,406] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-09-20 14:44:27,508] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-09-20 14:44:27,512] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-09-20 14:44:27,581] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-09-20 14:44:27,613] clients.NetworkClient - Sending metadata request {topics=[CEmemberRun]} to node -1
main DEBUG [2018-09-20 14:44:27,667] clients.Metadata - Updated cluster metadata version 2 to Cluster(nodes = [azauvprdkafka01.ahmcert.com:9092 (id: 1 rack: null), azauvprdkafka02.ahmcert.com:9092 (id: 2 rack: null)], partitions = [Partition(topic = CEmemberRun, partition = 4, leader = 1, replicas = [1,2,], isr = [1,2,], Partition(topic = CEmemberRun, partition = 3, leader = 2, replicas = [1,2,], isr = [1,2,], Partition(topic = CEmemberRun, partition = 0, leader = 1, replicas = [1,2,], isr = [1,2,], Partition(topic = CEmemberRun, partition = 1, leader = 2, replicas = [1,2,], isr = [1,2,], Partition(topic = CEmemberRun, partition = 2, leader = 1, replicas = [1,2,], isr = [1,2,]])
main DEBUG [2018-09-20 14:44:27,686] internals.AbstractCoordinator - Received group coordinator response ClientResponse(receivedTimeMs=1537469067684, disconnected=false, request=ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@518944a, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1537469066932, sendTimeMs=1537469067614), responseBody={error_code=0,coordinator={node_id=2,host=azauvprdkafka02.ahmcert.com,port=9092}})
main  INFO [2018-09-20 14:44:27,686] internals.AbstractCoordinator - Discovered coordinator azauvprdkafka02.ahmcert.com:9092 (id: 2147483645 rack: null) for group ALPTDESAI7136TD.
main DEBUG [2018-09-20 14:44:27,686] clients.NetworkClient - Initiating connection to node 2147483645 at azauvprdkafka02.ahmcert.com:9092.
main DEBUG [2018-09-20 14:44:27,687] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-09-20 14:44:27,687] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azauvprdkafka02.ahmcert.com;mechs=[GSSAPI]
main  INFO [2018-09-20 14:44:27,690] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD
main  INFO [2018-09-20 14:44:27,690] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD
main DEBUG [2018-09-20 14:44:27,695] internals.AbstractCoordinator - Sending JoinGroup ({group_id=ALPTDESAI7136TD,session_timeout=30000,member_id=,protocol_type=consumer,group_protocols=[{protocol_name=range,protocol_metadata=java.nio.HeapByteBuffer[pos=0 lim=23 cap=23]}]}) to coordinator azauvprdkafka02.ahmcert.com:9092 (id: 2147483645 rack: null)
main DEBUG [2018-09-20 14:44:27,758] metrics.Metrics - Added sensor with name node-2147483645.bytes-sent
main DEBUG [2018-09-20 14:44:27,759] metrics.Metrics - Added sensor with name node-2147483645.bytes-received
main DEBUG [2018-09-20 14:44:27,760] metrics.Metrics - Added sensor with name node-2147483645.latency
main DEBUG [2018-09-20 14:44:27,762] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-09-20 14:44:27,762] clients.NetworkClient - Completed connection to node 2147483645
main DEBUG [2018-09-20 14:44:27,833] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-09-20 14:44:27,839] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-09-20 14:44:27,910] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-09-20 14:44:27,990] internals.AbstractCoordinator - Received successful join group response for group ALPTDESAI7136TD: {error_code=0,generation_id=1,group_protocol=range,leader_id=consumer-1-2fceff2d-3615-4b88-9359-4a27928ed7f0,member_id=consumer-1-2fceff2d-3615-4b88-9359-4a27928ed7f0,members=[{member_id=consumer-1-2fceff2d-3615-4b88-9359-4a27928ed7f0,member_metadata=java.nio.HeapByteBuffer[pos=0 lim=23 cap=23]}]}
main DEBUG [2018-09-20 14:44:27,991] internals.ConsumerCoordinator - Performing assignment for group ALPTDESAI7136TD using strategy range with subscriptions {consumer-1-2fceff2d-3615-4b88-9359-4a27928ed7f0=Subscription(topics=[CEmemberRun])}
main DEBUG [2018-09-20 14:44:27,992] internals.ConsumerCoordinator - Finished assignment for group ALPTDESAI7136TD: {consumer-1-2fceff2d-3615-4b88-9359-4a27928ed7f0=Assignment(partitions=[CEmemberRun-0, CEmemberRun-1, CEmemberRun-2, CEmemberRun-3, CEmemberRun-4])}
main DEBUG [2018-09-20 14:44:27,993] internals.AbstractCoordinator - Sending leader SyncGroup for group ALPTDESAI7136TD to coordinator azauvprdkafka02.ahmcert.com:9092 (id: 2147483645 rack: null): {group_id=ALPTDESAI7136TD,generation_id=1,member_id=consumer-1-2fceff2d-3615-4b88-9359-4a27928ed7f0,group_assignment=[{member_id=consumer-1-2fceff2d-3615-4b88-9359-4a27928ed7f0,member_assignment=java.nio.HeapByteBuffer[pos=0 lim=47 cap=47]}]}
main  INFO [2018-09-20 14:44:28,105] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD with generation 1
main  INFO [2018-09-20 14:44:28,106] internals.ConsumerCoordinator - Setting newly assigned partitions [CEmemberRun-1, CEmemberRun-2, CEmemberRun-4, CEmemberRun-3, CEmemberRun-0] for group ALPTDESAI7136TD
main DEBUG [2018-09-20 14:44:28,106] internals.ConsumerCoordinator - Group ALPTDESAI7136TD fetching committed offsets for partitions: [CEmemberRun-1, CEmemberRun-2, CEmemberRun-4, CEmemberRun-3, CEmemberRun-0]
main DEBUG [2018-09-20 14:44:28,185] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:28,185] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:28,186] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:28,186] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:28,186] internals.ConsumerCoordinator - Group ALPTDESAI7136TD has no committed offset for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:28,186] internals.Fetcher - Resetting offset for partition CEmemberRun-1 to latest offset.
main DEBUG [2018-09-20 14:44:28,189] clients.NetworkClient - Initiating connection to node 2 at azauvprdkafka02.ahmcert.com:9092.
main DEBUG [2018-09-20 14:44:28,190] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-09-20 14:44:28,190] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azauvprdkafka02.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-09-20 14:44:28,248] metrics.Metrics - Added sensor with name node-2.bytes-sent
main DEBUG [2018-09-20 14:44:28,249] metrics.Metrics - Added sensor with name node-2.bytes-received
main DEBUG [2018-09-20 14:44:28,250] metrics.Metrics - Added sensor with name node-2.latency
main DEBUG [2018-09-20 14:44:28,251] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-09-20 14:44:28,251] clients.NetworkClient - Completed connection to node 2
main DEBUG [2018-09-20 14:44:28,311] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-09-20 14:44:28,322] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-09-20 14:44:28,389] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-09-20 14:44:28,463] internals.Fetcher - Fetched offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:28,464] internals.Fetcher - Resetting offset for partition CEmemberRun-2 to latest offset.
main DEBUG [2018-09-20 14:44:28,464] clients.NetworkClient - Initiating connection to node 1 at azauvprdkafka01.ahmcert.com:9092.
main DEBUG [2018-09-20 14:44:28,464] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-09-20 14:44:28,465] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azauvprdkafka01.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-09-20 14:44:28,521] metrics.Metrics - Added sensor with name node-1.bytes-sent
main DEBUG [2018-09-20 14:44:28,522] metrics.Metrics - Added sensor with name node-1.bytes-received
main DEBUG [2018-09-20 14:44:28,522] metrics.Metrics - Added sensor with name node-1.latency
main DEBUG [2018-09-20 14:44:28,523] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-09-20 14:44:28,523] clients.NetworkClient - Completed connection to node 1
main DEBUG [2018-09-20 14:44:28,580] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-09-20 14:44:28,583] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-09-20 14:44:28,644] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-09-20 14:44:28,710] internals.Fetcher - Fetched offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:28,710] internals.Fetcher - Resetting offset for partition CEmemberRun-4 to latest offset.
main DEBUG [2018-09-20 14:44:28,768] internals.Fetcher - Fetched offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:28,769] internals.Fetcher - Resetting offset for partition CEmemberRun-3 to latest offset.
main DEBUG [2018-09-20 14:44:28,830] internals.Fetcher - Fetched offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:28,830] internals.Fetcher - Resetting offset for partition CEmemberRun-0 to latest offset.
main DEBUG [2018-09-20 14:44:28,890] internals.Fetcher - Fetched offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:28,991] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:28,991] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:28,992] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:28,993] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:28,993] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:29,184] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:29,184] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:29,184] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:29,185] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:29,185] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:29,483] metrics.Metrics - Added sensor with name topic.CEmemberRun.bytes-fetched
main DEBUG [2018-09-20 14:44:29,485] metrics.Metrics - Added sensor with name topic.CEmemberRun.records-fetched
main DEBUG [2018-09-20 14:44:29,978] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:29,978] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:29,978] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:29,978] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:29,979] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:30,182] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:30,182] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:30,182] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:30,183] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:30,183] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:30,978] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:30,978] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:30,979] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:30,979] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:30,979] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:31,183] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:31,183] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:31,183] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:31,183] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:31,184] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:31,185] internals.AbstractCoordinator - Received successful heartbeat response for group ALPTDESAI7136TD
main DEBUG [2018-09-20 14:44:31,978] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:31,978] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:31,979] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:31,979] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:31,979] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:32,179] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:32,179] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:32,180] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:32,180] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:32,180] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:32,979] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:32,979] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:32,979] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:32,979] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:32,979] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:33,181] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:33,181] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:33,181] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:33,182] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:33,182] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:33,980] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:33,981] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:33,981] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:33,981] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:33,981] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:34,181] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:34,181] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:34,181] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:34,182] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:34,182] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:34,183] internals.AbstractCoordinator - Received successful heartbeat response for group ALPTDESAI7136TD
main DEBUG [2018-09-20 14:44:34,981] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:34,982] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:34,982] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:34,983] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:34,983] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:35,181] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:35,181] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:35,181] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:35,182] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:35,182] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:44:35,987] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:44:35,987] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:44:35,988] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:44:35,988] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:44:35,988] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main  INFO [2018-09-20 14:47:40,409] careengine.CEKafkaConsumer - Topic name is: CEmemberRun
main  INFO [2018-09-20 14:47:40,471] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-09-20 14:47:40,471] consumer.KafkaConsumer - Starting the Kafka consumer
main DEBUG [2018-09-20 14:47:40,543] clients.Metadata - Updated cluster metadata version 1 to Cluster(nodes = [azauvprdkafka01.ahmcert.com:9092 (id: -1 rack: null), azauvprdkafka02.ahmcert.com:9092 (id: -2 rack: null)], partitions = [])
main  INFO [2018-09-20 14:47:41,252] authenticator.AbstractLogin - Successfully logged in.
main DEBUG [2018-09-20 14:47:41,252] kerberos.KerberosLogin - It is a Kerberos ticket
main DEBUG [2018-09-20 14:47:41,314] metrics.Metrics - Added sensor with name connections-closed:
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:47:41,315] kerberos.KerberosLogin - TGT refresh thread started.
main DEBUG [2018-09-20 14:47:41,316] metrics.Metrics - Added sensor with name connections-created:
kafka-kerberos-refresh-thread DEBUG [2018-09-20 14:47:41,316] kerberos.KerberosLogin - Found TGT with client principal 'careengineuser@AHMCERT.COM' and server principal 'krbtgt/AHMCERT.COM@AHMCERT.COM'.
main DEBUG [2018-09-20 14:47:41,316] metrics.Metrics - Added sensor with name bytes-sent-received:
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:47:41,316] kerberos.KerberosLogin - TGT valid starting at: 2018-09-20T14:47:41.000-0400
main DEBUG [2018-09-20 14:47:41,316] metrics.Metrics - Added sensor with name bytes-sent:
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:47:41,316] kerberos.KerberosLogin - TGT expires: 2018-09-21T14:47:41.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:47:41,317] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-21T10:57:42.141-0400
main DEBUG [2018-09-20 14:47:41,318] metrics.Metrics - Added sensor with name bytes-received:
main DEBUG [2018-09-20 14:47:41,320] metrics.Metrics - Added sensor with name select-time:
main DEBUG [2018-09-20 14:47:41,320] metrics.Metrics - Added sensor with name io-time:
main  INFO [2018-09-20 14:47:41,332] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main DEBUG [2018-09-20 14:47:41,346] metrics.Metrics - Added sensor with name heartbeat-latency
main DEBUG [2018-09-20 14:47:41,347] metrics.Metrics - Added sensor with name join-latency
main DEBUG [2018-09-20 14:47:41,348] metrics.Metrics - Added sensor with name sync-latency
main DEBUG [2018-09-20 14:47:41,351] metrics.Metrics - Added sensor with name commit-latency
main DEBUG [2018-09-20 14:47:41,360] metrics.Metrics - Added sensor with name bytes-fetched
main DEBUG [2018-09-20 14:47:41,361] metrics.Metrics - Added sensor with name records-fetched
main DEBUG [2018-09-20 14:47:41,361] metrics.Metrics - Added sensor with name fetch-latency
main DEBUG [2018-09-20 14:47:41,362] metrics.Metrics - Added sensor with name records-lag
main DEBUG [2018-09-20 14:47:41,362] metrics.Metrics - Added sensor with name fetch-throttle-time
main  INFO [2018-09-20 14:47:41,365] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-20 14:47:41,365] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main DEBUG [2018-09-20 14:47:41,366] consumer.KafkaConsumer - Kafka consumer created
main DEBUG [2018-09-20 14:47:41,367] consumer.KafkaConsumer - Subscribed to topic(s): CEmemberRun
main DEBUG [2018-09-20 14:47:41,367] internals.AbstractCoordinator - Sending coordinator request for group ALPTDESAI7136TD to broker azauvprdkafka02.ahmcert.com:9092 (id: -2 rack: null)
main DEBUG [2018-09-20 14:47:41,395] clients.NetworkClient - Initiating connection to node -2 at azauvprdkafka02.ahmcert.com:9092.
main DEBUG [2018-09-20 14:47:41,403] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-09-20 14:47:41,405] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azauvprdkafka02.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-09-20 14:47:41,466] metrics.Metrics - Added sensor with name node--2.bytes-sent
main DEBUG [2018-09-20 14:47:41,467] metrics.Metrics - Added sensor with name node--2.bytes-received
main DEBUG [2018-09-20 14:47:41,467] metrics.Metrics - Added sensor with name node--2.latency
main DEBUG [2018-09-20 14:47:41,482] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-09-20 14:47:41,482] clients.NetworkClient - Completed connection to node -2
main DEBUG [2018-09-20 14:47:41,554] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-09-20 14:47:41,664] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-09-20 14:47:41,737] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-09-20 14:47:41,765] clients.NetworkClient - Sending metadata request {topics=[CEmemberRun]} to node -2
main DEBUG [2018-09-20 14:47:41,839] clients.Metadata - Updated cluster metadata version 2 to Cluster(nodes = [azauvprdkafka02.ahmcert.com:9092 (id: 2 rack: null), azauvprdkafka01.ahmcert.com:9092 (id: 1 rack: null)], partitions = [Partition(topic = CEmemberRun, partition = 4, leader = 1, replicas = [1,2,], isr = [1,2,], Partition(topic = CEmemberRun, partition = 3, leader = 2, replicas = [1,2,], isr = [1,2,], Partition(topic = CEmemberRun, partition = 0, leader = 1, replicas = [1,2,], isr = [1,2,], Partition(topic = CEmemberRun, partition = 1, leader = 2, replicas = [1,2,], isr = [1,2,], Partition(topic = CEmemberRun, partition = 2, leader = 1, replicas = [1,2,], isr = [1,2,]])
main DEBUG [2018-09-20 14:47:41,840] internals.AbstractCoordinator - Received group coordinator response ClientResponse(receivedTimeMs=1537469261839, disconnected=false, request=ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@338bda4f, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=consumer-1}, body={group_id=ALPTDESAI7136TD}), createdTimeMs=1537469261389, sendTimeMs=1537469261765), responseBody={error_code=0,coordinator={node_id=2,host=azauvprdkafka02.ahmcert.com,port=9092}})
main  INFO [2018-09-20 14:47:41,840] internals.AbstractCoordinator - Discovered coordinator azauvprdkafka02.ahmcert.com:9092 (id: 2147483645 rack: null) for group ALPTDESAI7136TD.
main DEBUG [2018-09-20 14:47:41,840] clients.NetworkClient - Initiating connection to node 2147483645 at azauvprdkafka02.ahmcert.com:9092.
main DEBUG [2018-09-20 14:47:41,841] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-09-20 14:47:41,841] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azauvprdkafka02.ahmcert.com;mechs=[GSSAPI]
main  INFO [2018-09-20 14:47:41,842] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD
main  INFO [2018-09-20 14:47:41,842] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD
main DEBUG [2018-09-20 14:47:41,845] internals.AbstractCoordinator - Sending JoinGroup ({group_id=ALPTDESAI7136TD,session_timeout=30000,member_id=,protocol_type=consumer,group_protocols=[{protocol_name=range,protocol_metadata=java.nio.HeapByteBuffer[pos=0 lim=23 cap=23]}]}) to coordinator azauvprdkafka02.ahmcert.com:9092 (id: 2147483645 rack: null)
main DEBUG [2018-09-20 14:47:41,900] metrics.Metrics - Added sensor with name node-2147483645.bytes-sent
main DEBUG [2018-09-20 14:47:41,900] metrics.Metrics - Added sensor with name node-2147483645.bytes-received
main DEBUG [2018-09-20 14:47:41,901] metrics.Metrics - Added sensor with name node-2147483645.latency
main DEBUG [2018-09-20 14:47:41,901] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-09-20 14:47:41,901] clients.NetworkClient - Completed connection to node 2147483645
main DEBUG [2018-09-20 14:47:41,960] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-09-20 14:47:41,963] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-09-20 14:47:42,032] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-09-20 14:47:42,096] internals.AbstractCoordinator - Received successful join group response for group ALPTDESAI7136TD: {error_code=0,generation_id=1,group_protocol=range,leader_id=consumer-1-18daea8c-0d95-4a9b-aadf-9269bf94eaf2,member_id=consumer-1-18daea8c-0d95-4a9b-aadf-9269bf94eaf2,members=[{member_id=consumer-1-18daea8c-0d95-4a9b-aadf-9269bf94eaf2,member_metadata=java.nio.HeapByteBuffer[pos=0 lim=23 cap=23]}]}
main DEBUG [2018-09-20 14:47:42,096] internals.ConsumerCoordinator - Performing assignment for group ALPTDESAI7136TD using strategy range with subscriptions {consumer-1-18daea8c-0d95-4a9b-aadf-9269bf94eaf2=Subscription(topics=[CEmemberRun])}
main DEBUG [2018-09-20 14:47:42,097] internals.ConsumerCoordinator - Finished assignment for group ALPTDESAI7136TD: {consumer-1-18daea8c-0d95-4a9b-aadf-9269bf94eaf2=Assignment(partitions=[CEmemberRun-0, CEmemberRun-1, CEmemberRun-2, CEmemberRun-3, CEmemberRun-4])}
main DEBUG [2018-09-20 14:47:42,098] internals.AbstractCoordinator - Sending leader SyncGroup for group ALPTDESAI7136TD to coordinator azauvprdkafka02.ahmcert.com:9092 (id: 2147483645 rack: null): {group_id=ALPTDESAI7136TD,generation_id=1,member_id=consumer-1-18daea8c-0d95-4a9b-aadf-9269bf94eaf2,group_assignment=[{member_id=consumer-1-18daea8c-0d95-4a9b-aadf-9269bf94eaf2,member_assignment=java.nio.HeapByteBuffer[pos=0 lim=47 cap=47]}]}
main  INFO [2018-09-20 14:47:42,163] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD with generation 1
main  INFO [2018-09-20 14:47:42,164] internals.ConsumerCoordinator - Setting newly assigned partitions [CEmemberRun-1, CEmemberRun-2, CEmemberRun-4, CEmemberRun-3, CEmemberRun-0] for group ALPTDESAI7136TD
main DEBUG [2018-09-20 14:47:42,165] internals.ConsumerCoordinator - Group ALPTDESAI7136TD fetching committed offsets for partitions: [CEmemberRun-1, CEmemberRun-2, CEmemberRun-4, CEmemberRun-3, CEmemberRun-0]
main DEBUG [2018-09-20 14:47:42,229] internals.Fetcher - Resetting offset for partition CEmemberRun-1 to the committed offset 1
main DEBUG [2018-09-20 14:47:42,229] internals.Fetcher - Resetting offset for partition CEmemberRun-2 to the committed offset 0
main DEBUG [2018-09-20 14:47:42,229] internals.Fetcher - Resetting offset for partition CEmemberRun-4 to the committed offset 1
main DEBUG [2018-09-20 14:47:42,229] internals.Fetcher - Resetting offset for partition CEmemberRun-3 to the committed offset 0
main DEBUG [2018-09-20 14:47:42,229] internals.Fetcher - Resetting offset for partition CEmemberRun-0 to the committed offset 2
main DEBUG [2018-09-20 14:47:42,232] clients.NetworkClient - Initiating connection to node 2 at azauvprdkafka02.ahmcert.com:9092.
main DEBUG [2018-09-20 14:47:42,232] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-09-20 14:47:42,232] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azauvprdkafka02.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-09-20 14:47:42,233] clients.NetworkClient - Initiating connection to node 1 at azauvprdkafka01.ahmcert.com:9092.
main DEBUG [2018-09-20 14:47:42,234] authenticator.SaslClientAuthenticator - Set SASL client state to SEND_HANDSHAKE_REQUEST
main DEBUG [2018-09-20 14:47:42,234] authenticator.SaslClientAuthenticator - Creating SaslClient: client=careengineuser@AHMCERT.COM;service=kafka;serviceHostname=azauvprdkafka01.ahmcert.com;mechs=[GSSAPI]
main DEBUG [2018-09-20 14:47:42,280] metrics.Metrics - Added sensor with name node-1.bytes-sent
main DEBUG [2018-09-20 14:47:42,281] metrics.Metrics - Added sensor with name node-1.bytes-received
main DEBUG [2018-09-20 14:47:42,281] metrics.Metrics - Added sensor with name node-1.latency
main DEBUG [2018-09-20 14:47:42,281] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-09-20 14:47:42,281] clients.NetworkClient - Completed connection to node 1
main DEBUG [2018-09-20 14:47:42,300] metrics.Metrics - Added sensor with name node-2.bytes-sent
main DEBUG [2018-09-20 14:47:42,301] metrics.Metrics - Added sensor with name node-2.bytes-received
main DEBUG [2018-09-20 14:47:42,301] metrics.Metrics - Added sensor with name node-2.latency
main DEBUG [2018-09-20 14:47:42,301] authenticator.SaslClientAuthenticator - Set SASL client state to RECEIVE_HANDSHAKE_RESPONSE
main DEBUG [2018-09-20 14:47:42,301] clients.NetworkClient - Completed connection to node 2
main DEBUG [2018-09-20 14:47:42,328] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-09-20 14:47:42,466] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-09-20 14:47:42,469] authenticator.SaslClientAuthenticator - Set SASL client state to INITIAL
main DEBUG [2018-09-20 14:47:42,472] authenticator.SaslClientAuthenticator - Set SASL client state to INTERMEDIATE
main DEBUG [2018-09-20 14:47:42,517] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-09-20 14:47:42,536] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:47:42,536] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:47:42,536] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:47:42,536] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:47:42,536] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:47:42,544] authenticator.SaslClientAuthenticator - Set SASL client state to COMPLETE
main DEBUG [2018-09-20 14:47:43,069] metrics.Metrics - Added sensor with name topic.CEmemberRun.bytes-fetched
main DEBUG [2018-09-20 14:47:43,070] metrics.Metrics - Added sensor with name topic.CEmemberRun.records-fetched
main DEBUG [2018-09-20 14:47:43,227] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:47:43,227] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:47:43,227] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:47:43,227] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:47:43,227] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main DEBUG [2018-09-20 14:47:43,532] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-1
main DEBUG [2018-09-20 14:47:43,532] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-2
main DEBUG [2018-09-20 14:47:43,532] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 1 for partition CEmemberRun-4
main DEBUG [2018-09-20 14:47:43,532] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 0 for partition CEmemberRun-3
main DEBUG [2018-09-20 14:47:43,532] internals.ConsumerCoordinator - Group ALPTDESAI7136TD committed offset 2 for partition CEmemberRun-0
main  INFO [2018-09-20 14:47:57,571] careengine.CEKafkaConsumer - Topic name is: CEmemberRun
main  INFO [2018-09-20 14:47:57,611] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-20 14:47:58,167] authenticator.AbstractLogin - Successfully logged in.
main  INFO [2018-09-20 14:47:58,201] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-20 14:47:58,236] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-20 14:47:58,236] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:47:58,249] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:47:58,250] kerberos.KerberosLogin - TGT valid starting at: 2018-09-20T14:47:58.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:47:58,250] kerberos.KerberosLogin - TGT expires: 2018-09-21T14:47:58.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:47:58,251] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-21T11:05:45.644-0400
main  INFO [2018-09-20 14:47:58,679] internals.AbstractCoordinator - Discovered coordinator azauvprdkafka02.ahmcert.com:9092 (id: 2147483645 rack: null) for group ALPTDESAI7136TD.
main  INFO [2018-09-20 14:47:58,683] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD
main  INFO [2018-09-20 14:47:58,683] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD
main  INFO [2018-09-20 14:48:13,620] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD with generation 2
main  INFO [2018-09-20 14:48:13,624] internals.ConsumerCoordinator - Setting newly assigned partitions [CEmemberRun-1, CEmemberRun-2, CEmemberRun-4, CEmemberRun-3, CEmemberRun-0] for group ALPTDESAI7136TD
main  INFO [2018-09-20 14:55:28,153] careengine.CEKafkaProducer - Topic name is: CEmemberRun
main  INFO [2018-09-20 14:55:28,193] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2018-09-20 14:55:37,562] careengine.CEKafkaConsumer - Topic name is: CEmemberRun
main  INFO [2018-09-20 14:55:37,615] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-20 14:55:38,266] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:55:38,287] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:55:38,287] kerberos.KerberosLogin - TGT valid starting at: 2018-09-20T14:55:38.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:55:38,288] kerberos.KerberosLogin - TGT expires: 2018-09-21T14:55:38.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:55:38,288] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-21T11:10:41.893-0400
main  INFO [2018-09-20 14:55:38,301] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-20 14:55:38,336] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-20 14:55:38,336] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-09-20 14:55:38,923] internals.AbstractCoordinator - Discovered coordinator azauvprdkafka02.ahmcert.com:9092 (id: 2147483645 rack: null) for group ALPTDESAI7136TD.
main  INFO [2018-09-20 14:55:38,924] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD
main  INFO [2018-09-20 14:55:38,925] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD
main  INFO [2018-09-20 14:55:39,244] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD with generation 1
main  INFO [2018-09-20 14:55:39,247] internals.ConsumerCoordinator - Setting newly assigned partitions [CEmemberRun-1, CEmemberRun-2, CEmemberRun-4, CEmemberRun-3, CEmemberRun-0] for group ALPTDESAI7136TD
main  INFO [2018-09-20 14:55:49,911] careengine.CEKafkaProducer - Topic name is: CEmemberRun
main  INFO [2018-09-20 14:55:49,950] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2018-09-20 14:55:50,587] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:55:50,589] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:55:50,590] kerberos.KerberosLogin - TGT valid starting at: 2018-09-20T14:55:50.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:55:50,590] kerberos.KerberosLogin - TGT expires: 2018-09-21T14:55:50.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-20 14:55:50,590] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-21T10:26:56.468-0400
main  INFO [2018-09-20 14:55:50,621] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2018-09-20 14:55:50,625] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-20 14:55:50,625] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-09-21 13:32:54,209] careengine.CEKafkaProducer - Topic name is: CEmemberRun
main  INFO [2018-09-21 13:32:54,273] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2018-09-21 13:32:55,130] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:32:55,130] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:32:55,130] kerberos.KerberosLogin - TGT valid starting at: 2018-09-21T13:32:54.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:32:55,130] kerberos.KerberosLogin - TGT expires: 2018-09-22T13:32:54.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:32:55,130] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-22T09:25:55.482-0400
main  INFO [2018-09-21 13:32:55,146] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2018-09-21 13:32:55,149] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-21 13:32:55,149] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-09-21 13:33:02,705] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2018-09-21 13:33:02,708] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2018-09-21 13:33:12,006] careengine.CEKafkaConsumer - Topic name is: CECommunications
main  INFO [2018-09-21 13:33:12,046] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvdv1kafka01:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD4
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-21 13:33:12,896] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:33:12,926] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:33:12,926] kerberos.KerberosLogin - TGT valid starting at: 2018-09-21T13:33:12.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:33:12,926] kerberos.KerberosLogin - TGT expires: 2018-09-22T13:33:12.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:33:12,926] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-22T08:59:39.767-0400
main  INFO [2018-09-21 13:33:12,926] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvdv1kafka01:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD4
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-21 13:33:12,950] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-21 13:33:12,951] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-09-21 13:34:22,852] careengine.CEKafkaConsumer - Topic name is: CECommunications
main  INFO [2018-09-21 13:34:22,892] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD2
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-21 13:34:23,632] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:34:23,680] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:34:23,681] kerberos.KerberosLogin - TGT valid starting at: 2018-09-21T13:34:23.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:34:23,681] kerberos.KerberosLogin - TGT expires: 2018-09-22T13:34:23.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:34:23,681] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-22T09:54:26.062-0400
main  INFO [2018-09-21 13:34:23,683] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD2
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-21 13:34:23,720] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-21 13:34:23,720] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-09-21 13:34:24,166] internals.AbstractCoordinator - Discovered coordinator azauvprdkafka02.ahmcert.com:9092 (id: 2147483645 rack: null) for group ALPTDESAI7136TD2.
main  INFO [2018-09-21 13:34:24,168] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD2
main  INFO [2018-09-21 13:34:24,168] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD2
main  INFO [2018-09-21 13:34:24,622] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD2 with generation 1
main  INFO [2018-09-21 13:34:24,623] internals.ConsumerCoordinator - Setting newly assigned partitions [CECommunications-1, CECommunications-3, CECommunications-2, CECommunications-4, CECommunications-0] for group ALPTDESAI7136TD2
main  INFO [2018-09-21 13:40:27,647] careengine.CEKafkaConsumer - Topic name is: CECommunications
main  INFO [2018-09-21 13:40:27,687] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD8
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-21 13:40:28,268] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:40:28,368] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:40:28,368] kerberos.KerberosLogin - TGT valid starting at: 2018-09-21T13:40:28.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:40:28,368] kerberos.KerberosLogin - TGT expires: 2018-09-22T13:40:28.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-21 13:40:28,368] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-22T09:23:14.878-0400
main  INFO [2018-09-21 13:40:28,387] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD8
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-21 13:40:28,411] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-21 13:40:28,411] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-09-21 13:40:29,033] internals.AbstractCoordinator - Discovered coordinator azauvprdkafka02.ahmcert.com:9092 (id: 2147483645 rack: null) for group ALPTDESAI7136TD8.
main  INFO [2018-09-21 13:40:29,043] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD8
main  INFO [2018-09-21 13:40:29,043] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD8
main  INFO [2018-09-21 13:40:29,384] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD8 with generation 1
main  INFO [2018-09-21 13:40:29,387] internals.ConsumerCoordinator - Setting newly assigned partitions [MemberDataNewEvents-0, MemberDataNewEvents-10, MemberDataNewEvents-11, MemberDataNewEvents-12, MemberDataNewEvents-9, MemberDataNewEvents-1, MemberDataNewEvents-7, MemberDataNewEvents-4, MemberDataNewEvents-3, MemberDataNewEvents-2, MemberDataNewEvents-8, CECommunications-0, MemberDataNewEvents-21, MemberDataNewEvents-6, MemberDataNewEvents-16, CECommunications-1, MemberDataNewEvents-15, MemberDataNewEvents-5, CECommunications-3, CECommunications-2, MemberDataNewEvents-13, CECommunications-4, MemberDataNewEvents-14, MemberDataNewEvents-20, MemberDataNewEvents-17, MemberDataNewEvents-18, MemberDataNewEvents-19] for group ALPTDESAI7136TD8
main  INFO [2018-09-21 14:01:11,533] careengine.CEKafkaConsumer - Topic name is: CECommunications
main  INFO [2018-09-21 14:01:11,587] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD8
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-21 14:01:12,216] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-09-21 14:01:12,234] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-21 14:01:12,234] kerberos.KerberosLogin - TGT valid starting at: 2018-09-21T14:01:12.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-21 14:01:12,235] kerberos.KerberosLogin - TGT expires: 2018-09-22T14:01:12.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-21 14:01:12,235] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-22T09:15:04.721-0400
main  INFO [2018-09-21 14:01:12,280] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD8
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-21 14:01:12,313] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-21 14:01:12,313] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-09-21 14:01:12,758] internals.AbstractCoordinator - Discovered coordinator azauvprdkafka02.ahmcert.com:9092 (id: 2147483645 rack: null) for group ALPTDESAI7136TD8.
main  INFO [2018-09-21 14:01:12,760] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD8
main  INFO [2018-09-21 14:01:12,760] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD8
main  INFO [2018-09-21 14:01:28,376] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD8 with generation 2
main  INFO [2018-09-21 14:01:28,377] internals.ConsumerCoordinator - Setting newly assigned partitions [CECommunications-1, CECommunications-3, CECommunications-2, CECommunications-4, CECommunications-0] for group ALPTDESAI7136TD8
main  INFO [2018-09-25 09:42:04,440] careengine.CEKafkaConsumer - Topic name is: CECommunications
main  INFO [2018-09-25 09:42:04,482] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD8
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-25 09:42:05,355] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-09-25 09:42:05,359] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-25 09:42:05,359] kerberos.KerberosLogin - TGT valid starting at: 2018-09-25T09:42:05.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-25 09:42:05,360] kerberos.KerberosLogin - TGT expires: 2018-09-26T09:42:05.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-25 09:42:05,360] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-26T05:09:39.118-0400
main  INFO [2018-09-25 09:42:05,415] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD8
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-25 09:42:05,445] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-25 09:42:05,445] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-09-25 09:42:06,201] internals.AbstractCoordinator - Discovered coordinator azauvprdkafka02.ahmcert.com:9092 (id: 2147483645 rack: null) for group ALPTDESAI7136TD8.
main  INFO [2018-09-25 09:42:06,202] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD8
main  INFO [2018-09-25 09:42:06,203] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD8
main  INFO [2018-09-25 09:42:06,496] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD8 with generation 1
main  INFO [2018-09-25 09:42:06,499] internals.ConsumerCoordinator - Setting newly assigned partitions [MemberDataNewEvents-0, MemberDataNewEvents-10, MemberDataNewEvents-11, MemberDataNewEvents-12, MemberDataNewEvents-9, MemberDataNewEvents-1, MemberDataNewEvents-7, MemberDataNewEvents-4, MemberDataNewEvents-3, MemberDataNewEvents-2, MemberDataNewEvents-8, CECommunications-0, MemberDataNewEvents-21, MemberDataNewEvents-6, MemberDataNewEvents-16, CECommunications-1, MemberDataNewEvents-15, MemberDataNewEvents-5, CECommunications-3, CECommunications-2, MemberDataNewEvents-13, CECommunications-4, MemberDataNewEvents-14, MemberDataNewEvents-20, MemberDataNewEvents-17, MemberDataNewEvents-18, MemberDataNewEvents-19] for group ALPTDESAI7136TD8
main  INFO [2018-09-25 09:54:36,014] careengine.CEKafkaConsumer - Topic name is: aapreauth
main  INFO [2018-09-25 09:54:36,056] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD1
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-25 09:54:43,255] careengine.CEKafkaConsumer - Topic name is: aapreauth
main  INFO [2018-09-25 09:54:43,294] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD1
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-25 09:54:43,929] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-09-25 09:54:43,936] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-25 09:54:43,937] kerberos.KerberosLogin - TGT valid starting at: 2018-09-25T09:54:43.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-25 09:54:43,937] kerberos.KerberosLogin - TGT expires: 2018-09-26T09:54:43.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-25 09:54:43,937] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-26T05:31:32.363-0400
main  INFO [2018-09-25 09:54:43,998] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD1
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-25 09:54:44,034] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-25 09:54:44,035] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-09-25 09:54:44,540] internals.AbstractCoordinator - Discovered coordinator azauvprdkafka01.ahmcert.com:9092 (id: 2147483646 rack: null) for group ALPTDESAI7136TD1.
main  INFO [2018-09-25 09:54:44,547] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD1
main  INFO [2018-09-25 09:54:44,547] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD1
main  INFO [2018-09-25 09:54:44,992] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD1 with generation 1
main  INFO [2018-09-25 09:54:44,994] internals.ConsumerCoordinator - Setting newly assigned partitions [aapreauth-10, MemberDataNewEvents-10, MemberDataNewEvents-12, MemberDataNewEvents-1, aapreauth-6, MemberDataNewEvents-3, MemberDataNewEvents-8, MemberDataNewEvents-21, aapreauth-8, MemberDataNewEvents-6, MemberDataNewEvents-16, aapreauth-0, aapreauth-4, MemberDataNewEvents-14, MemberDataNewEvents-20, aapreauth-2, MemberDataNewEvents-18, MemberDataNewEvents-0, MemberDataNewEvents-11, aapreauth-9, MemberDataNewEvents-9, MemberDataNewEvents-7, MemberDataNewEvents-4, aapreauth-5, MemberDataNewEvents-2, aapreauth-7, MemberDataNewEvents-15, MemberDataNewEvents-5, MemberDataNewEvents-13, aapreauth-3, MemberDataNewEvents-17, aapreauth-1, MemberDataNewEvents-19] for group ALPTDESAI7136TD1
main  INFO [2018-09-25 09:56:03,682] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-09-25 09:56:03,717] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD4
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-25 09:56:04,330] authenticator.AbstractLogin - Successfully logged in.
main  INFO [2018-09-25 09:56:04,369] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD4
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

kafka-kerberos-refresh-thread  INFO [2018-09-25 09:56:04,385] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-25 09:56:04,386] kerberos.KerberosLogin - TGT valid starting at: 2018-09-25T09:56:04.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-25 09:56:04,386] kerberos.KerberosLogin - TGT expires: 2018-09-26T09:56:04.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-25 09:56:04,387] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-26T05:38:12.750-0400
main  INFO [2018-09-25 09:56:04,429] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-25 09:56:04,429] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-09-25 09:56:04,820] internals.AbstractCoordinator - Discovered coordinator azauvprdkafka02.ahmcert.com:9092 (id: 2147483645 rack: null) for group ALPTDESAI7136TD4.
main  INFO [2018-09-25 09:56:04,824] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD4
main  INFO [2018-09-25 09:56:04,824] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD4
main  INFO [2018-09-25 09:56:05,305] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD4 with generation 1
main  INFO [2018-09-25 09:56:05,312] internals.ConsumerCoordinator - Setting newly assigned partitions [MemberDataNewEvents-0, MemberDataNewEvents-10, MemberDataNewEvents-11, MemberDataNewEvents-12, MemberDataNewEvents-9, MemberDataNewEvents-1, MemberDataNewEvents-7, MemberDataNewEvents-4, MemberDataNewEvents-3, MemberDataNewEvents-2, MemberDataNewEvents-8, MemberDataNewEvents-21, MemberDataNewEvents-6, MemberDataNewEvents-16, MemberDataNewEvents-15, MemberDataNewEvents-5, MemberDataNewEvents-13, MemberDataNewEvents-14, MemberDataNewEvents-20, MemberDataNewEvents-17, MemberDataNewEvents-18, MemberDataNewEvents-19] for group ALPTDESAI7136TD4
main  INFO [2018-09-25 10:53:54,188] careengine.CEKafkaConsumer - Topic name is: MemberDataNewEvents
main  INFO [2018-09-25 10:53:54,248] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvqa1kafka01.ahmcert.com:9092, azbuvqa1kafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD0
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-25 10:53:56,201] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-09-25 10:53:56,201] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-25 10:53:56,201] kerberos.KerberosLogin - TGT valid starting at: 2018-09-25T10:53:56.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-25 10:53:56,201] kerberos.KerberosLogin - TGT expires: 2018-09-26T10:53:56.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-25 10:53:56,201] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-26T06:42:26.246-0400
main  INFO [2018-09-25 10:53:56,221] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azbuvqa1kafka01.ahmcert.com:9092, azbuvqa1kafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD0
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-25 10:53:56,251] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-25 10:53:56,251] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-09-25 10:53:57,001] internals.AbstractCoordinator - Discovered coordinator azbuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group ALPTDESAI7136TD0.
main  INFO [2018-09-25 10:53:57,005] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD0
main  INFO [2018-09-25 10:53:57,006] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD0
main  INFO [2018-09-25 10:53:57,260] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD0 with generation 1
main  INFO [2018-09-25 10:53:57,261] internals.ConsumerCoordinator - Setting newly assigned partitions [MemberDataNewEvents-0, MemberDataNewEvents-1, MemberDataNewEvents-4, MemberDataNewEvents-3, MemberDataNewEvents-2] for group ALPTDESAI7136TD0
main  INFO [2018-09-25 14:02:08,087] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2018-09-25 14:02:08,121] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [azbuvdv1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2018-09-25 14:02:09,084] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-09-25 14:02:09,084] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-25 14:02:09,094] kerberos.KerberosLogin - TGT valid starting at: 2018-09-25T14:02:08.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-25 14:02:09,094] kerberos.KerberosLogin - TGT expires: 2018-09-26T14:02:08.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-25 14:02:09,094] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-26T09:50:55.582-0400
main  INFO [2018-09-25 14:02:09,107] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [azbuvdv1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2018-09-25 14:02:09,111] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-25 14:02:09,111] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-09-25 14:02:16,618] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2018-09-25 14:02:16,621] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2018-09-25 14:39:24,700] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2018-09-25 14:39:24,746] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [azbuvdv1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2018-09-25 14:39:25,775] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-09-25 14:39:25,780] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-25 14:39:25,781] kerberos.KerberosLogin - TGT valid starting at: 2018-09-25T14:39:25.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-25 14:39:25,781] kerberos.KerberosLogin - TGT expires: 2018-09-26T14:39:25.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-25 14:39:25,782] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-26T10:52:08.050-0400
main  INFO [2018-09-25 14:39:25,863] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [azbuvdv1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2018-09-25 14:39:25,868] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-25 14:39:25,868] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-09-25 14:39:33,336] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2018-09-25 14:39:33,339] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2018-09-27 14:30:47,192] careengine.CEKafkaConsumer - Topic name is: aapreauth
main  INFO [2018-09-27 14:30:47,235] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD7
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-27 14:30:48,305] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2018-09-27 14:30:48,307] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2018-09-27 14:30:48,307] kerberos.KerberosLogin - TGT valid starting at: 2018-09-27T14:30:48.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-27 14:30:48,308] kerberos.KerberosLogin - TGT expires: 2018-09-28T14:30:48.000-0400
kafka-kerberos-refresh-thread  INFO [2018-09-27 14:30:48,308] kerberos.KerberosLogin - TGT refresh sleeping until: 2018-09-28T10:31:03.579-0400
main  INFO [2018-09-27 14:30:48,340] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [azauvprdkafka01.ahmcert.com:9092, azauvprdkafka02.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ALPTDESAI7136TD7
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2018-09-27 14:30:48,379] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2018-09-27 14:30:48,379] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2018-09-27 14:30:48,927] internals.AbstractCoordinator - Discovered coordinator azauvprdkafka01.ahmcert.com:9092 (id: 2147483646 rack: null) for group ALPTDESAI7136TD7.
main  INFO [2018-09-27 14:30:49,027] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ALPTDESAI7136TD7
main  INFO [2018-09-27 14:30:49,027] internals.AbstractCoordinator - (Re-)joining group ALPTDESAI7136TD7
main  INFO [2018-09-27 14:30:49,392] internals.AbstractCoordinator - Successfully joined group ALPTDESAI7136TD7 with generation 1
main  INFO [2018-09-27 14:30:49,393] internals.ConsumerCoordinator - Setting newly assigned partitions [aapreauth-10, aapreauth-0, aapreauth-9, aapreauth-4, aapreauth-6, aapreauth-5, aapreauth-3, aapreauth-7, aapreauth-1, aapreauth-2, aapreauth-8] for group ALPTDESAI7136TD7
