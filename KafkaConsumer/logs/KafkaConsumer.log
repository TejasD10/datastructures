main  INFO [2017-10-19 14:01:19,810] streams.StreamsConfig - StreamsConfig values: 
	key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	state.dir = /tmp/kafka-streams
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	state.cleanup.delay.ms = 60000
	timestamp.extractor = class org.apache.kafka.streams.processor.ConsumerRecordTimestampExtractor
	buffered.records.per.partition = 1000
	application.id = CEStreamConsumer
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	zookeeper.connect = 
	num.stream.threads = 1
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	metric.reporters = []
	client.id = 
	commit.interval.ms = 30000
	replication.factor = 1
	poll.ms = 100
	metrics.num.samples = 2

main  INFO [2017-10-19 14:01:19,835] internals.StreamThread - Creating producer client for stream thread [StreamThread-1]
main  INFO [2017-10-19 14:01:19,848] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-producer
	max.request.size = 1048576
	acks = 1
	linger.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-19 14:01:20,227] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:01:20,230] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:01:20,231] kerberos.KerberosLogin - TGT valid starting at: 2017-10-19T14:01:20.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:01:20,232] kerberos.KerberosLogin - TGT expires: 2017-10-20T14:01:20.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:01:20,232] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-20T09:29:44.711-0400
main  INFO [2017-10-19 14:01:20,247] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-producer
	max.request.size = 1048576
	acks = 1
	linger.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-19 14:01:20,251] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-19 14:01:20,251] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-19 14:01:20,252] internals.StreamThread - Creating consumer client for stream thread [StreamThread-1]
main  INFO [2017-10-19 14:01:20,259] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = CEStreamConsumer
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:01:20,269] internals.StreamPartitionAssignor - Config 'zookeeper.connect' isn't supplied and hence no internal topics will be created.
main  INFO [2017-10-19 14:01:20,270] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = CEStreamConsumer
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  WARN [2017-10-19 14:01:20,294] consumer.ConsumerConfig - The configuration num.standby.replicas = 0 was supplied but isn't a known config.
main  WARN [2017-10-19 14:01:20,294] consumer.ConsumerConfig - The configuration replication.factor = 1 was supplied but isn't a known config.
main  WARN [2017-10-19 14:01:20,294] consumer.ConsumerConfig - The configuration __stream.thread.instance__ = Thread[StreamThread-1,5,main] was supplied but isn't a known config.
main  INFO [2017-10-19 14:01:20,295] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-19 14:01:20,295] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-19 14:01:20,295] internals.StreamThread - Creating restore consumer client for stream thread [StreamThread-1]
main  INFO [2017-10-19 14:01:20,295] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-restore-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = 
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:01:20,299] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-restore-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = 
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:01:20,302] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-19 14:01:20,302] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-19 14:48:45,008] streams.StreamsConfig - StreamsConfig values: 
	key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	state.dir = /tmp/kafka-streams
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	state.cleanup.delay.ms = 60000
	timestamp.extractor = class org.apache.kafka.streams.processor.ConsumerRecordTimestampExtractor
	buffered.records.per.partition = 1000
	application.id = CEStreamConsumer
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	zookeeper.connect = 
	num.stream.threads = 1
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	metric.reporters = []
	client.id = 
	commit.interval.ms = 30000
	replication.factor = 1
	poll.ms = 100
	metrics.num.samples = 2

main  INFO [2017-10-19 14:48:45,033] internals.StreamThread - Creating producer client for stream thread [StreamThread-1]
main  INFO [2017-10-19 14:48:45,046] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-producer
	max.request.size = 1048576
	acks = 1
	linger.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-19 14:48:45,427] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:48:45,430] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:48:45,431] kerberos.KerberosLogin - TGT valid starting at: 2017-10-19T14:48:45.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:48:45,432] kerberos.KerberosLogin - TGT expires: 2017-10-20T14:48:45.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:48:45,432] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-20T10:39:49.351-0400
main  INFO [2017-10-19 14:48:45,447] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-producer
	max.request.size = 1048576
	acks = 1
	linger.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-19 14:48:45,451] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-19 14:48:45,451] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-19 14:48:45,451] internals.StreamThread - Creating consumer client for stream thread [StreamThread-1]
main  INFO [2017-10-19 14:48:45,458] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = CEStreamConsumer
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:48:45,468] internals.StreamPartitionAssignor - Config 'zookeeper.connect' isn't supplied and hence no internal topics will be created.
main  INFO [2017-10-19 14:48:45,469] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = CEStreamConsumer
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  WARN [2017-10-19 14:48:45,493] consumer.ConsumerConfig - The configuration num.standby.replicas = 0 was supplied but isn't a known config.
main  WARN [2017-10-19 14:48:45,493] consumer.ConsumerConfig - The configuration replication.factor = 1 was supplied but isn't a known config.
main  WARN [2017-10-19 14:48:45,493] consumer.ConsumerConfig - The configuration __stream.thread.instance__ = Thread[StreamThread-1,5,main] was supplied but isn't a known config.
main  INFO [2017-10-19 14:48:45,493] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-19 14:48:45,493] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-19 14:48:45,493] internals.StreamThread - Creating restore consumer client for stream thread [StreamThread-1]
main  INFO [2017-10-19 14:48:45,494] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-restore-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = 
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:48:45,497] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = CEStreamConsumer-1-StreamThread-1-restore-consumer
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 5000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = 
	enable.auto.commit = false
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:48:45,501] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-19 14:48:45,501] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-19 14:48:45,503] streams.KafkaStreams - Started Kafka Stream process
StreamThread-1  INFO [2017-10-19 14:48:45,505] internals.StreamThread - Starting stream thread [StreamThread-1]
StreamThread-1  INFO [2017-10-19 14:48:45,827] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group CEStreamConsumer.
StreamThread-1  INFO [2017-10-19 14:48:45,828] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group CEStreamConsumer
StreamThread-1  INFO [2017-10-19 14:48:45,828] internals.AbstractCoordinator - (Re-)joining group CEStreamConsumer
StreamThread-1  INFO [2017-10-19 14:48:45,843] assignment.TaskAssignor - Assigning tasks to clients: {4834d8c5-7403-4e4a-982f-7be2c33b50a1=[activeTasks: ([]) assignedTasks: ([]) prevActiveTasks: ([]) prevAssignedTasks: ([]) capacity: 1.0 cost: 0.0]}, prevAssignmentBalanced: false, prevClientsUnchangeed: false, tasks: [0_0, 0_1, 0_2, 0_3, 0_4], replicas: 0
StreamThread-1  INFO [2017-10-19 14:48:45,844] assignment.TaskAssignor - Assigned with: {4834d8c5-7403-4e4a-982f-7be2c33b50a1=[activeTasks: ([0_0, 0_1, 0_2, 0_3, 0_4]) assignedTasks: ([0_0, 0_1, 0_2, 0_3, 0_4]) prevActiveTasks: ([]) prevAssignedTasks: ([]) capacity: 1.0 cost: 2.5]}
StreamThread-1  INFO [2017-10-19 14:48:45,849] internals.AbstractCoordinator - Successfully joined group CEStreamConsumer with generation 1
StreamThread-1  INFO [2017-10-19 14:48:45,850] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group CEStreamConsumer
StreamThread-1  INFO [2017-10-19 14:48:45,864] internals.StreamTask - Creating restoration consumer client for stream task #0_0
StreamThread-1  INFO [2017-10-19 14:48:45,870] internals.StreamTask - Creating restoration consumer client for stream task #0_1
StreamThread-1  INFO [2017-10-19 14:48:45,871] internals.StreamTask - Creating restoration consumer client for stream task #0_2
StreamThread-1  INFO [2017-10-19 14:48:45,871] internals.StreamTask - Creating restoration consumer client for stream task #0_3
StreamThread-1  INFO [2017-10-19 14:48:45,872] internals.StreamTask - Creating restoration consumer client for stream task #0_4
main  INFO [2017-10-19 14:49:09,451] careengine.CEKafkaProducer - Topic name is: CEmemberRun
main  INFO [2017-10-19 14:49:09,487] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvcrtkafka02.ahmcert.com:9092, nycuvcrtkafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ConsumerGroup
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:49:09,876] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:49:09,879] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:49:09,881] kerberos.KerberosLogin - TGT valid starting at: 2017-10-19T14:49:09.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:49:09,881] kerberos.KerberosLogin - TGT expires: 2017-10-20T14:49:09.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-19 14:49:09,881] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-20T10:24:00.895-0400
main  INFO [2017-10-19 14:49:09,899] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvcrtkafka02.ahmcert.com:9092, nycuvcrtkafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ConsumerGroup
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-19 14:49:09,930] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-19 14:49:09,930] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-19 14:49:10,231] internals.AbstractCoordinator - Discovered coordinator nycuvcrtkafka02.ahmcert.com:9092 (id: 2147483646 rack: null) for group ConsumerGroup.
main  INFO [2017-10-19 14:49:10,234] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ConsumerGroup
main  INFO [2017-10-19 14:49:10,235] internals.AbstractCoordinator - (Re-)joining group ConsumerGroup
main  INFO [2017-10-19 14:49:10,392] internals.AbstractCoordinator - Successfully joined group ConsumerGroup with generation 1
main  INFO [2017-10-19 14:49:10,393] internals.ConsumerCoordinator - Setting newly assigned partitions [CEmemberRun-1, CEmemberRun-2, CEmemberRun-4, CEmemberRun-3, CEmemberRun-0] for group ConsumerGroup
main  INFO [2017-10-20 10:15:22,046] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-20 10:15:22,081] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ConsumerGroup
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:15:22,457] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:15:22,460] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:15:22,462] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T10:15:22.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:15:22,462] kerberos.KerberosLogin - TGT expires: 2017-10-21T10:15:22.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:15:22,463] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T06:24:04.247-0400
main  INFO [2017-10-20 10:15:22,480] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = ConsumerGroup
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:15:22,509] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 10:15:22,509] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 10:15:22,808] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group ConsumerGroup.
main  INFO [2017-10-20 10:15:22,809] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group ConsumerGroup
main  INFO [2017-10-20 10:15:22,810] internals.AbstractCoordinator - (Re-)joining group ConsumerGroup
main  INFO [2017-10-20 10:15:22,823] internals.AbstractCoordinator - Successfully joined group ConsumerGroup with generation 1
main  INFO [2017-10-20 10:15:22,824] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group ConsumerGroup
main  INFO [2017-10-20 10:19:10,063] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-20 10:19:10,098] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:19:10,485] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:19:10,488] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:19:10,489] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T10:19:10.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:19:10,490] kerberos.KerberosLogin - TGT expires: 2017-10-21T10:19:10.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:19:10,490] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T05:40:18.093-0400
main  INFO [2017-10-20 10:19:10,508] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:19:10,538] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 10:19:10,539] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 10:19:10,847] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-20 10:19:10,848] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:19:10,849] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:19:10,863] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-20 10:19:10,864] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:22:22,115] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-20 10:22:22,149] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:22:22,546] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:22:22,549] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:22:22,550] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T10:22:22.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:22:22,551] kerberos.KerberosLogin - TGT expires: 2017-10-21T10:22:22.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:22:22,551] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T06:21:20.137-0400
main  INFO [2017-10-20 10:22:22,569] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:22:22,598] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 10:22:22,598] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 10:22:22,903] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-20 10:22:22,905] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:22:22,905] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:22:22,919] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-20 10:22:22,920] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:37:38,740] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-20 10:37:38,774] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:37:39,154] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:37:39,157] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:37:39,159] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T10:37:39.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:37:39,159] kerberos.KerberosLogin - TGT expires: 2017-10-21T10:37:39.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 10:37:39,159] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T06:39:58.287-0400
main  INFO [2017-10-20 10:37:39,178] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 10:37:39,207] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 10:37:39,207] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 10:37:39,517] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-20 10:37:39,519] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:37:39,519] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 10:37:39,532] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-20 10:37:39,533] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:24:15,699] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-20 11:24:15,733] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:24:16,119] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:24:16,122] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:24:16,124] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T11:24:15.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:24:16,124] kerberos.KerberosLogin - TGT expires: 2017-10-21T11:24:15.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:24:16,125] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T07:05:51.110-0400
main  INFO [2017-10-20 11:24:16,142] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:24:16,171] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 11:24:16,172] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 11:24:16,477] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-20 11:24:16,479] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:24:16,479] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:24:27,971] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 2
main  INFO [2017-10-20 11:24:27,973] internals.ConsumerCoordinator - Setting newly assigned partitions [MemberDataNewEvents-0, MemberDataNewEvents-1, MemberDataNewEvents-4, MemberDataNewEvents-3, MemberDataNewEvents-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:26:41,820] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-20 11:26:41,855] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:26:42,239] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:42,241] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:42,243] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T11:26:42.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:42,244] kerberos.KerberosLogin - TGT expires: 2017-10-21T11:26:42.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:42,244] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T07:34:26.393-0400
main  INFO [2017-10-20 11:26:42,262] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:26:42,292] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 11:26:42,292] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 11:26:42,598] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-20 11:26:42,599] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:26:42,600] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:26:42,613] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-20 11:26:42,614] internals.ConsumerCoordinator - Setting newly assigned partitions [MemberDataNewEvents-0, MemberDataNewEvents-1, MemberDataNewEvents-4, MemberDataNewEvents-3, MemberDataNewEvents-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:26:56,886] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-20 11:26:56,923] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = all
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-20 11:26:57,319] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:57,322] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:57,323] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T11:26:57.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:57,323] kerberos.KerberosLogin - TGT expires: 2017-10-21T11:26:57.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:26:57,323] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T06:53:11.349-0400
main  INFO [2017-10-20 11:26:57,340] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = all
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-20 11:26:57,344] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 11:26:57,344] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 11:27:11,681] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-20 11:27:11,690] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-20 11:36:42,261] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-20 11:36:42,303] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-20 11:36:42,720] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:42,723] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:42,725] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T11:36:42.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:42,725] kerberos.KerberosLogin - TGT expires: 2017-10-21T11:36:42.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:42,726] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T07:05:46.351-0400
main  INFO [2017-10-20 11:36:42,743] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-20 11:36:42,748] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 11:36:42,749] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 11:36:46,679] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-20 11:36:46,714] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:36:47,087] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:47,090] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:47,091] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T11:36:46.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:47,092] kerberos.KerberosLogin - TGT expires: 2017-10-21T11:36:46.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:36:47,092] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T07:43:07.138-0400
main  INFO [2017-10-20 11:36:47,110] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:36:47,140] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 11:36:47,140] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 11:36:47,448] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-20 11:36:47,449] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:36:47,450] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:36:47,464] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-20 11:36:47,465] internals.ConsumerCoordinator - Setting newly assigned partitions [MemberDataNewEvents-0, MemberDataNewEvents-1, MemberDataNewEvents-4, MemberDataNewEvents-3, MemberDataNewEvents-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:36:57,080] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-20 11:36:57,088] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-20 11:45:00,901] careengine.CEKafkaProducer - Topic name is: CECommunications
main  INFO [2017-10-20 11:45:00,936] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:45:01,333] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:45:01,336] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:45:01,337] kerberos.KerberosLogin - TGT valid starting at: 2017-10-20T11:45:01.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:45:01,337] kerberos.KerberosLogin - TGT expires: 2017-10-21T11:45:01.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-20 11:45:01,338] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-21T07:48:45.175-0400
main  INFO [2017-10-20 11:45:01,357] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-20 11:45:01,386] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-20 11:45:01,386] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-20 11:45:01,697] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-20 11:45:01,698] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:45:01,699] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-20 11:45:01,713] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-20 11:45:01,714] internals.ConsumerCoordinator - Setting newly assigned partitions [CECommunications-1, CECommunications-3, CECommunications-2, CECommunications-4, CECommunications-0] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 16:23:19,840] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 16:23:19,877] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 16:23:20,348] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:23:20,351] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:23:20,353] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T16:23:20.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:23:20,353] kerberos.KerberosLogin - TGT expires: 2017-10-26T16:23:20.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:23:20,353] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T12:03:18.962-0400
main  INFO [2017-10-25 16:23:20,370] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 16:23:20,375] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 16:23:20,375] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 16:23:34,730] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-25 16:23:34,739] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-25 16:30:26,737] careengine.CEKafkaProducer - Topic name is: CECommunications
main  INFO [2017-10-25 16:30:26,772] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 16:30:27,168] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:27,171] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:27,173] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T16:30:26.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:27,173] kerberos.KerberosLogin - TGT expires: 2017-10-26T16:30:26.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:27,174] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T12:28:13.085-0400
main  INFO [2017-10-25 16:30:27,191] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 16:30:27,221] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 16:30:27,221] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 16:30:27,530] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-25 16:30:27,531] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 16:30:27,532] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 16:30:27,551] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-25 16:30:27,552] internals.ConsumerCoordinator - Setting newly assigned partitions [CECommunications-1, CECommunications-3, CECommunications-2, CECommunications-4, CECommunications-0] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 16:30:35,724] careengine.CEKafkaProducer - Topic name is: CECommunications
main  INFO [2017-10-25 16:30:35,761] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 16:30:36,166] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:36,169] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:36,170] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T16:30:35.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:36,170] kerberos.KerberosLogin - TGT expires: 2017-10-26T16:30:35.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 16:30:36,171] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T12:03:35.268-0400
main  INFO [2017-10-25 16:30:36,187] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 16:30:36,191] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 16:30:36,191] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 16:30:50,552] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-25 16:30:50,561] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-25 17:53:15,880] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:53:15,910] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:53:16,296] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:16,299] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:16,301] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T17:53:16.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:16,301] kerberos.KerberosLogin - TGT expires: 2017-10-26T17:53:16.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:16,301] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T13:22:16.028-0400
main  INFO [2017-10-25 17:53:16,317] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:53:16,322] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 17:53:16,322] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 17:53:30,708] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-25 17:53:30,716] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-25 17:53:37,432] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:53:37,467] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 17:53:37,869] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:37,872] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:37,873] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T17:53:37.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:37,874] kerberos.KerberosLogin - TGT expires: 2017-10-26T17:53:37.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:37,875] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T14:13:17.810-0400
main  INFO [2017-10-25 17:53:37,892] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 17:53:37,923] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 17:53:37,923] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 17:53:38,544] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-25 17:53:38,546] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:53:38,547] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:53:38,568] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-25 17:53:38,571] internals.ConsumerCoordinator - Setting newly assigned partitions [MemberDataNewEvents-0, MemberDataNewEvents-1, MemberDataNewEvents-4, MemberDataNewEvents-3, MemberDataNewEvents-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:53:47,912] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:53:47,950] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:53:48,338] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:48,341] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:48,342] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T17:53:48.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:48,343] kerberos.KerberosLogin - TGT expires: 2017-10-26T17:53:48.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:53:48,343] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T14:15:02.510-0400
main  INFO [2017-10-25 17:53:48,359] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:53:48,364] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 17:53:48,364] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 17:54:02,702] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-25 17:54:02,708] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-25 17:54:29,721] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:54:29,757] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 17:54:30,430] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:30,433] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:30,435] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T17:54:30.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:30,435] kerberos.KerberosLogin - TGT expires: 2017-10-26T17:54:30.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:30,435] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T13:23:10.313-0400
main  INFO [2017-10-25 17:54:30,453] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 17:54:30,484] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 17:54:30,484] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 17:54:30,789] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-25 17:54:30,790] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:54:30,790] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:54:35,606] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:54:35,643] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:54:36,038] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:36,040] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:36,042] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T17:54:35.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:36,042] kerberos.KerberosLogin - TGT expires: 2017-10-26T17:54:35.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:54:36,043] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T13:41:18.084-0400
main  INFO [2017-10-25 17:54:36,059] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:54:36,065] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 17:54:36,065] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 17:54:50,419] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-25 17:54:50,428] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-25 17:54:55,588] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 2
main  INFO [2017-10-25 17:54:55,590] internals.ConsumerCoordinator - Setting newly assigned partitions [MemberDataNewEvents-0, MemberDataNewEvents-1, MemberDataNewEvents-4, MemberDataNewEvents-3, MemberDataNewEvents-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:55:40,150] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:55:40,187] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [vqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  WARN [2017-10-25 17:55:40,212] clients.ClientUtils - Removing server from bootstrap.servers as DNS resolution failed: vqa1kafka01.ahmcert.com:9092
main  INFO [2017-10-25 17:55:40,212] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 0 ms.
main  INFO [2017-10-25 17:56:23,210] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:56:23,245] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 17:56:23,957] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:23,960] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:23,961] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T17:56:23.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:23,962] kerberos.KerberosLogin - TGT expires: 2017-10-26T17:56:23.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:23,963] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T14:18:09.495-0400
main  INFO [2017-10-25 17:56:23,980] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-25 17:56:24,010] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 17:56:24,010] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 17:56:24,330] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-25 17:56:24,333] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:56:24,333] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-25 17:56:27,761] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 17:56:27,798] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:56:28,208] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:28,210] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:28,212] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T17:56:28.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:28,212] kerberos.KerberosLogin - TGT expires: 2017-10-26T17:56:28.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 17:56:28,212] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T14:12:45.193-0400
main  INFO [2017-10-25 17:56:28,229] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 17:56:28,233] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 17:56:28,233] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 18:00:13,695] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 18:00:13,732] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 18:00:14,140] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:00:14,142] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:00:14,144] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T18:00:13.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:00:14,144] kerberos.KerberosLogin - TGT expires: 2017-10-26T18:00:13.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:00:14,144] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T14:08:14.762-0400
main  INFO [2017-10-25 18:00:14,161] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 18:00:14,165] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 18:00:14,165] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 18:01:51,103] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 18:01:51,139] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 20000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 18:01:51,608] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:01:51,611] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:01:51,613] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T18:01:51.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:01:51,613] kerberos.KerberosLogin - TGT expires: 2017-10-26T18:01:51.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:01:51,614] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T13:18:42.220-0400
main  INFO [2017-10-25 18:01:51,630] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 20000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 18:01:51,634] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 18:01:51,634] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-25 18:02:35,895] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-25 18:02:35,932] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 18:02:37,928] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:02:37,931] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:02:37,932] kerberos.KerberosLogin - TGT valid starting at: 2017-10-25T18:02:37.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:02:37,933] kerberos.KerberosLogin - TGT expires: 2017-10-26T18:02:37.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-25 18:02:37,933] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-26T13:49:16.381-0400
main  INFO [2017-10-25 18:02:37,949] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9090]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 2000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-25 18:02:37,953] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-25 18:02:37,953] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-26 09:52:49,907] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-26 09:52:49,942] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-26 09:52:50,327] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:52:50,329] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:52:50,330] kerberos.KerberosLogin - TGT valid starting at: 2017-10-26T09:52:50.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:52:50,331] kerberos.KerberosLogin - TGT expires: 2017-10-27T09:52:50.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:52:50,331] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-27T05:17:22.015-0400
main  INFO [2017-10-26 09:52:50,349] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-26 09:52:50,380] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-26 09:52:50,380] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-26 09:52:50,682] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-26 09:52:50,685] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 09:52:50,686] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 09:52:50,704] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-26 09:52:50,705] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 09:53:18,913] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-26 09:53:18,950] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 09:53:19,340] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:53:19,343] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:53:19,345] kerberos.KerberosLogin - TGT valid starting at: 2017-10-26T09:53:19.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:53:19,345] kerberos.KerberosLogin - TGT expires: 2017-10-27T09:53:19.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:53:19,345] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-27T05:34:02.544-0400
main  INFO [2017-10-26 09:53:19,362] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 09:53:19,366] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-26 09:53:19,366] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-26 09:53:33,711] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-26 09:53:33,719] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-26 09:55:05,475] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-26 09:55:05,513] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 09:55:05,901] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:55:05,904] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:55:05,906] kerberos.KerberosLogin - TGT valid starting at: 2017-10-26T09:55:05.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:55:05,906] kerberos.KerberosLogin - TGT expires: 2017-10-27T09:55:05.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 09:55:05,906] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-27T06:04:43.051-0400
main  INFO [2017-10-26 09:55:05,923] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 09:55:05,927] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-26 09:55:05,927] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-26 09:55:20,264] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-26 09:55:20,273] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-26 10:22:42,610] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-26 10:22:42,647] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 10:22:43,035] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-26 10:22:43,037] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-26 10:22:43,039] kerberos.KerberosLogin - TGT valid starting at: 2017-10-26T10:22:42.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 10:22:43,040] kerberos.KerberosLogin - TGT expires: 2017-10-27T10:22:42.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 10:22:43,040] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-27T06:23:07.286-0400
main  INFO [2017-10-26 10:22:43,056] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 10:22:43,060] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-26 10:22:43,060] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-26 10:22:50,388] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-26 10:22:50,397] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-10-26 11:17:06,945] careengine.CEKafkaProducer - Topic name is: MemberDataNewEvents
main  INFO [2017-10-26 11:17:06,981] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 11:17:07,366] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-26 11:17:07,369] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-26 11:17:07,370] kerberos.KerberosLogin - TGT valid starting at: 2017-10-26T11:17:07.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 11:17:07,371] kerberos.KerberosLogin - TGT expires: 2017-10-27T11:17:07.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 11:17:07,371] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-27T06:41:54.956-0400
main  INFO [2017-10-26 11:17:07,387] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-10-26 11:17:07,393] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-26 11:17:07,393] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-26 11:17:14,723] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-10-26 11:17:14,732] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main ERROR [2017-10-26 11:29:12,198] internals.ConsumerCoordinator - Group nycupdevceapp02.activehealth.locTD failed to commit partition CEMarkers-4 at offset 30365: This server does not host this topic-partition.
main  WARN [2017-10-26 11:29:12,198] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Unexpected error in commit: This server does not host this topic-partition.
main ERROR [2017-10-26 11:29:12,499] internals.ConsumerCoordinator - Group nycupdevceapp02.activehealth.locTD failed to commit partition CEMarkers-4 at offset 30365: This server does not host this topic-partition.
main  WARN [2017-10-26 11:29:12,499] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Unexpected error in commit: This server does not host this topic-partition.
main  WARN [2017-10-26 11:29:12,502] clients.NetworkClient - Error while fetching metadata with correlation id 25095 : {CEMarkers=UNKNOWN_TOPIC_OR_PARTITION}
main ERROR [2017-10-26 11:29:12,504] internals.ConsumerCoordinator - Group nycupdevceapp02.activehealth.locTD failed to commit partition CEMarkers-4 at offset 30365: This server does not host this topic-partition.
main  WARN [2017-10-26 11:29:12,504] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Unexpected error in commit: This server does not host this topic-partition.
main  INFO [2017-10-26 11:29:12,505] internals.ConsumerCoordinator - Revoking previously assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 11:29:12,506] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 11:29:12,511] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 2
main  INFO [2017-10-26 11:29:12,511] internals.ConsumerCoordinator - Setting newly assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 11:34:12,503] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 11:34:12,504] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 11:34:12,508] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 3
main  INFO [2017-10-26 11:34:12,508] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 11:34:12,512] internals.Fetcher - Fetch offset 30365 is out of range for partition CEMarkers-4, resetting offset
main  INFO [2017-10-26 11:34:12,512] internals.Fetcher - Fetch offset 30420 is out of range for partition CEMarkers-3, resetting offset
main  INFO [2017-10-26 11:34:12,512] internals.Fetcher - Fetch offset 30397 is out of range for partition CEMarkers-1, resetting offset
main  INFO [2017-10-26 11:34:12,513] internals.Fetcher - Fetch offset 30391 is out of range for partition CEMarkers-0, resetting offset
main  INFO [2017-10-26 11:34:12,513] internals.Fetcher - Fetch offset 30366 is out of range for partition CEMarkers-2, resetting offset
main  INFO [2017-10-26 12:42:36,577] careengine.CEKafkaProducer - Topic name is: CEMarkers
main  INFO [2017-10-26 12:42:36,612] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-26 12:42:37,027] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-10-26 12:42:37,030] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-10-26 12:42:37,032] kerberos.KerberosLogin - TGT valid starting at: 2017-10-26T12:42:36.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 12:42:37,032] kerberos.KerberosLogin - TGT expires: 2017-10-27T12:42:36.000-0400
kafka-kerberos-refresh-thread  INFO [2017-10-26 12:42:37,033] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-10-27T07:58:05.907-0400
main  INFO [2017-10-26 12:42:37,051] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvqa1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-10-26 12:42:37,080] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-10-26 12:42:37,080] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-10-26 12:42:37,388] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-26 12:42:37,390] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 12:42:37,390] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 12:42:37,404] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-10-26 12:42:37,405] internals.ConsumerCoordinator - Setting newly assigned partitions [CEMarkers-4, CEMarkers-3, CEMarkers-1, CEMarkers-0, CEMarkers-2] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-10-26 13:53:12,246] internals.AbstractCoordinator - Marking the coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) dead for group nycupdevceapp02.activehealth.locTD
main  WARN [2017-10-26 13:53:42,204] clients.NetworkClient - Error while fetching metadata with correlation id 18424 : {CEMarkers=UNKNOWN_TOPIC_OR_PARTITION}
main  WARN [2017-10-26 13:53:42,360] clients.NetworkClient - Error while fetching metadata with correlation id 18425 : {CEMarkers=UNKNOWN_TOPIC_OR_PARTITION}
main  WARN [2017-10-26 13:53:42,463] clients.NetworkClient - Error while fetching metadata with correlation id 18426 : {CEMarkers=UNKNOWN_TOPIC_OR_PARTITION}
main  WARN [2017-10-26 13:53:42,576] clients.NetworkClient - Error while fetching metadata with correlation id 18427 : {CEMarkers=UNKNOWN_TOPIC_OR_PARTITION}
main  INFO [2017-10-26 13:53:42,795] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-26 13:53:43,063] internals.AbstractCoordinator - Marking the coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) dead for group nycupdevceapp02.activehealth.locTD
main  WARN [2017-10-26 13:53:43,064] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Commit offsets failed with retriable exception. You should retry committing offsets.
main  WARN [2017-10-26 13:53:43,091] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Commit offsets failed with retriable exception. You should retry committing offsets.
main  INFO [2017-10-26 13:53:43,116] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-26 13:53:43,801] internals.AbstractCoordinator - Marking the coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) dead for group nycupdevceapp02.activehealth.locTD
main  WARN [2017-10-26 13:53:43,801] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Commit offsets failed with retriable exception. You should retry committing offsets.
main  INFO [2017-10-26 13:53:43,810] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-26 13:53:43,875] internals.AbstractCoordinator - Marking the coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) dead for group nycupdevceapp02.activehealth.locTD
main  WARN [2017-10-26 13:53:43,875] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Commit offsets failed with retriable exception. You should retry committing offsets.
main  INFO [2017-10-26 13:53:43,886] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-10-26 13:53:44,802] internals.AbstractCoordinator - Marking the coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) dead for group nycupdevceapp02.activehealth.locTD
main  WARN [2017-10-26 13:53:44,802] internals.ConsumerCoordinator - Auto offset commit failed for group nycupdevceapp02.activehealth.locTD: Commit offsets failed with retriable exception. You should retry committing offsets.
main  INFO [2017-10-26 13:53:44,959] internals.AbstractCoordinator - Discovered coordinator nycuvqa1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-11-02 12:52:04,229] careengine.CEKafkaProducer - Topic name is: CEmemberRun
main  INFO [2017-11-02 12:52:04,265] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvig1kafka01.ahmcert.com:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-11-02 12:52:04,647] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:04,649] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:04,651] kerberos.KerberosLogin - TGT valid starting at: 2017-11-02T12:52:04.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:04,651] kerberos.KerberosLogin - TGT expires: 2017-11-03T12:52:04.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:04,652] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-11-03T09:09:55.934-0400
main  INFO [2017-11-02 12:52:04,670] consumer.ConsumerConfig - ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [nycuvig1kafka01.ahmcert.com:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = nycupdevceapp02.activehealth.locTD
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

main  INFO [2017-11-02 12:52:04,701] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-11-02 12:52:04,701] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-11-02 12:52:05,009] internals.AbstractCoordinator - Discovered coordinator nycuvig1kafka01.ahmcert.com:9092 (id: 2147483647 rack: null) for group nycupdevceapp02.activehealth.locTD.
main  INFO [2017-11-02 12:52:05,011] internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-11-02 12:52:05,011] internals.AbstractCoordinator - (Re-)joining group nycupdevceapp02.activehealth.locTD
main  INFO [2017-11-02 12:52:05,041] internals.AbstractCoordinator - Successfully joined group nycupdevceapp02.activehealth.locTD with generation 1
main  INFO [2017-11-02 12:52:05,042] internals.ConsumerCoordinator - Setting newly assigned partitions [CEmemberRun-1, CEmemberRun-0] for group nycupdevceapp02.activehealth.locTD
main  INFO [2017-11-02 12:52:29,081] careengine.CEKafkaProducer - Topic name is: CEmemberRun
main  INFO [2017-11-02 12:52:29,119] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvig1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-11-02 12:52:29,508] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:29,511] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:29,513] kerberos.KerberosLogin - TGT valid starting at: 2017-11-02T12:52:29.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:29,513] kerberos.KerberosLogin - TGT expires: 2017-11-03T12:52:29.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:29,514] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-11-03T08:20:23.269-0400
main  INFO [2017-11-02 12:52:29,530] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvig1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-11-02 12:52:29,534] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-11-02 12:52:29,535] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-11-02 12:52:29,852] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-11-02 12:52:29,859] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
main  INFO [2017-11-02 12:52:48,471] careengine.CEKafkaProducer - Topic name is: CEmemberRun
main  INFO [2017-11-02 12:52:48,508] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvig1kafka01.ahmcert.com:9092]
	client.id = 
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-11-02 12:52:48,899] authenticator.AbstractLogin - Successfully logged in.
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:48,902] kerberos.KerberosLogin - TGT refresh thread started.
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:48,903] kerberos.KerberosLogin - TGT valid starting at: 2017-11-02T12:52:48.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:48,904] kerberos.KerberosLogin - TGT expires: 2017-11-03T12:52:48.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-02 12:52:48,904] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-11-03T09:09:36.331-0400
main  INFO [2017-11-02 12:52:48,920] producer.ProducerConfig - ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = kafka
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [nycuvig1kafka01.ahmcert.com:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = 1
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	metrics.sample.window.ms = 30000
	security.protocol = SASL_PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

main  INFO [2017-11-02 12:52:48,924] utils.AppInfoParser - Kafka version : 0.10.0.1
main  INFO [2017-11-02 12:52:48,924] utils.AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5
main  INFO [2017-11-02 12:52:56,260] producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
kafka-kerberos-refresh-thread  WARN [2017-11-02 12:52:56,264] kerberos.KerberosLogin - TGT renewal thread has been interrupted and will exit.
kafka-kerberos-refresh-thread  INFO [2017-11-03 09:09:55,937] kerberos.KerberosLogin - Initiating logout for careengineuser@AHMCERT.COM
kafka-kerberos-refresh-thread  INFO [2017-11-03 09:09:55,939] kerberos.KerberosLogin - Initiating re-login for careengineuser@AHMCERT.COM
kafka-kerberos-refresh-thread  INFO [2017-11-03 09:09:56,073] kerberos.KerberosLogin - TGT valid starting at: 2017-11-03T09:09:56.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-03 09:09:56,074] kerberos.KerberosLogin - TGT expires: 2017-11-04T09:09:56.000-0400
kafka-kerberos-refresh-thread  INFO [2017-11-03 09:09:56,074] kerberos.KerberosLogin - TGT refresh sleeping until: 2017-11-04T05:22:38.065-0400
